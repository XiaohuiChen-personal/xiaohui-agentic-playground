{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49711af0",
   "metadata": {},
   "source": [
    "# Different Agentic Systems - Workflow\n",
    "\n",
    "Xiaohui Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73ce9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n"
     ]
    }
   ],
   "source": [
    "# Imports and Environment Setup\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Verify API keys are loaded\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "# Initialize clients\n",
    "openai_client = OpenAI()\n",
    "anthropic_client = Anthropic()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c809d",
   "metadata": {},
   "source": [
    "## 1. Prompt Chaining Design Pattern\n",
    "\n",
    "### What is Prompt Chaining?\n",
    "\n",
    "**Prompt Chaining** is an agentic workflow pattern where a complex task is decomposed into a sequence of smaller, focused subtasks. Each step in the chain:\n",
    "- Takes input from the previous step's output\n",
    "- Performs a specific, well-defined operation\n",
    "- Produces structured output for the next step\n",
    "\n",
    "This approach offers several advantages over single-prompt solutions:\n",
    "- **Improved accuracy**: Each LLM call focuses on one thing, reducing cognitive load\n",
    "- **Better debuggability**: You can inspect intermediate outputs to identify where things go wrong\n",
    "- **Modularity**: Individual steps can be modified or improved independently\n",
    "- **Quality gates**: You can add validation or human review between steps\n",
    "\n",
    "### Example Workflow Diagram\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                         PROMPT CHAINING WORKFLOW                            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "     â”‚          â”‚      â”‚          â”‚      â”‚          â”‚      â”‚          â”‚\n",
    "     â”‚  INPUT   â”‚ â”€â”€â”€â–¶ â”‚  STEP 1  â”‚ â”€â”€â”€â–¶ â”‚  STEP 2  â”‚ â”€â”€â”€â–¶ â”‚  STEP 3  â”‚ â”€â”€â”€â–¶ OUTPUT\n",
    "     â”‚          â”‚      â”‚          â”‚      â”‚          â”‚      â”‚          â”‚\n",
    "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â”‚                 â”‚                 â”‚\n",
    "                            â–¼                 â–¼                 â–¼\n",
    "                       Intermediate      Intermediate      Intermediate\n",
    "                        Output 1          Output 2          Output 3\n",
    "```\n",
    "\n",
    "### AG News Classification Chain\n",
    "\n",
    "For our experiment, we'll classify news articles using this 3-step chain:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚\n",
    "â”‚  STEP 1:        â”‚     â”‚  STEP 2:        â”‚     â”‚  STEP 3:        â”‚\n",
    "â”‚  Extract        â”‚ â”€â”€â–¶ â”‚  Analyze        â”‚ â”€â”€â–¶ â”‚  Classify       â”‚\n",
    "â”‚  Entities &     â”‚     â”‚  Domain         â”‚     â”‚  Final          â”‚\n",
    "â”‚  Keywords       â”‚     â”‚  Signals        â”‚     â”‚  Category       â”‚\n",
    "â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â”‚                       â”‚                       â”‚\n",
    "        â–¼                       â–¼                       â–¼\n",
    "  Named entities,         Domain indicators      World | Sports |\n",
    "  key topics,             and reasoning          Business | Sci/Tech\n",
    "  geographic refs\n",
    "```\n",
    "\n",
    "**Categories in AG News:**\n",
    "- ğŸŒ **World** - International news and events\n",
    "- âš½ **Sports** - Athletic events, teams, players\n",
    "- ğŸ’¼ **Business** - Companies, markets, economy\n",
    "- ğŸ”¬ **Sci/Tech** - Science and technology news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1d0d11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011845a53fbb4160985217087728d024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb41179b5234a918eea830369eab348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f31686466e42f5972d8ab9ac215bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45583169cb6f4856a042952ff4da6cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9416a37ad1f4408bf1cf3ba4c014205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AG NEWS DATASET ANALYSIS\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Dataset Splits:\n",
      "  - train: 120,000 rows\n",
      "  - test: 7,600 rows\n",
      "\n",
      "ğŸ“ˆ Total rows: 127,600\n",
      "\n",
      "ğŸ“‹ Columns:\n",
      "  - Number of columns: 2\n",
      "  - 'text': Value('string')\n",
      "  - 'label': ClassLabel(names=['World', 'Sports', 'Business', 'Sci/Tech'])\n",
      "\n",
      "ğŸ·ï¸ Label Column: 'label'\n",
      "  This is the target column for classification!\n",
      "\n",
      "  Label Mapping:\n",
      "    0 â†’ World\n",
      "    1 â†’ Sports\n",
      "    2 â†’ Business\n",
      "    3 â†’ Sci/Tech\n",
      "\n",
      "ğŸ“ Sample Data (first 3 rows from train):\n",
      "\n",
      "  [0] Label: 2 (Business)\n",
      "      Text: Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\b...\n",
      "\n",
      "  [1] Label: 2 (Business)\n",
      "      Text: Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,...\n",
      "\n",
      "  [2] Label: 2 (Business)\n",
      "      Text: Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about th...\n"
     ]
    }
   ],
   "source": [
    "# Load the AG News dataset from HuggingFace\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "ag_news = load_dataset(\"ag_news\")\n",
    "\n",
    "# Display dataset structure\n",
    "print(\"=\" * 60)\n",
    "print(\"AG NEWS DATASET ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dataset splits\n",
    "print(\"\\nğŸ“Š Dataset Splits:\")\n",
    "for split_name, split_data in ag_news.items():\n",
    "    print(f\"  - {split_name}: {len(split_data):,} rows\")\n",
    "\n",
    "# Total rows\n",
    "total_rows = sum(len(split) for split in ag_news.values())\n",
    "print(f\"\\nğŸ“ˆ Total rows: {total_rows:,}\")\n",
    "\n",
    "# Column information\n",
    "print(\"\\nğŸ“‹ Columns:\")\n",
    "print(f\"  - Number of columns: {len(ag_news['train'].features)}\")\n",
    "for col_name, col_type in ag_news['train'].features.items():\n",
    "    print(f\"  - '{col_name}': {col_type}\")\n",
    "\n",
    "# Label mapping\n",
    "print(\"\\nğŸ·ï¸ Label Column: 'label'\")\n",
    "print(\"  This is the target column for classification!\")\n",
    "print(\"\\n  Label Mapping:\")\n",
    "label_names = ag_news['train'].features['label'].names\n",
    "for idx, name in enumerate(label_names):\n",
    "    print(f\"    {idx} â†’ {name}\")\n",
    "\n",
    "# Sample data preview\n",
    "print(\"\\nğŸ“ Sample Data (first 3 rows from train):\")\n",
    "for i in range(3):\n",
    "    sample = ag_news['train'][i]\n",
    "    print(f\"\\n  [{i}] Label: {sample['label']} ({label_names[sample['label']]})\")\n",
    "    print(f\"      Text: {sample['text'][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db26c5",
   "metadata": {},
   "source": [
    "### Step 1: Entity & Keyword Extraction\n",
    "\n",
    "> **Note:** We will use only the **test set** (7,600 rows) for our experiments, ignoring the training data.\n",
    "\n",
    "**Objective:** Extract structured information from raw news text that will help downstream steps make better classification decisions.\n",
    "\n",
    "In this step, the LLM will analyze each news article and extract:\n",
    "- **News Source**: The wire service or publication (e.g., Reuters, AP)\n",
    "- **Named Entities**: People, organizations, teams, companies mentioned\n",
    "- **Key Topics**: Main subjects and themes discussed (2-4 topics)\n",
    "- **Geographic References**: Countries, cities, regions mentioned\n",
    "- **Domain-Specific Keywords**: Significant terms that signal the article's domain (5-10 keywords)\n",
    "\n",
    "**Why this step matters:**\n",
    "- Converts unstructured text into structured, analyzable components\n",
    "- Identifies signals that are strongly associated with specific categories\n",
    "- Reduces noise by focusing on the most informative elements\n",
    "- Creates a foundation for the domain analysis in Step 2\n",
    "\n",
    "---\n",
    "\n",
    "#### Understanding the AG News Text Format\n",
    "\n",
    "The `text` field in AG News follows a specific structure:\n",
    "\n",
    "```\n",
    "[Headline] ([Source]) [Source] - [Article Body]...\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling...\n",
    "â”‚                                        â”‚         â”‚         â”‚\n",
    "â””â”€â”€ Headline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚         â””â”€â”€ Article Body\n",
    "                                          â””â”€â”€ Source (repeated)\n",
    "```\n",
    "\n",
    "This structure means:\n",
    "- The **headline** comes first and summarizes the story\n",
    "- The **source** appears twice (in parentheses and before the dash)\n",
    "- The **article body** follows after the dash\n",
    "\n",
    "---\n",
    "\n",
    "#### System Prompt for Step 1\n",
    "\n",
    "The system prompt instructs the LLM on its role and expected output format:\n",
    "\n",
    "```\n",
    "You are an expert information extraction system specialized in analyzing news articles.\n",
    "\n",
    "Your task is to extract key information from a news article that will help classify it into one of four categories: World, Sports, Business, or Sci/Tech.\n",
    "\n",
    "The input text follows this format: [Headline] ([Source]) [Source] - [Article Body]\n",
    "\n",
    "Extract the following information and return it as a JSON object:\n",
    "\n",
    "1. \"source\": The news source/wire service (e.g., \"Reuters\", \"AP\", \"AFP\")\n",
    "2. \"headline\": The article headline (text before the source in parentheses)\n",
    "3. \"entities\": A list of named entities (people, organizations, teams, companies)\n",
    "4. \"topics\": A list of 2-4 main topics or themes discussed\n",
    "5. \"locations\": A list of geographic references (countries, cities, regions)\n",
    "6. \"keywords\": A list of 5-10 domain-specific or significant keywords\n",
    "7. \"summary\": A one-sentence summary of the article's main point\n",
    "\n",
    "Rules:\n",
    "- Be concise and precise\n",
    "- Only extract information that is explicitly stated or clearly implied\n",
    "- Return ONLY valid JSON, no additional text or explanation\n",
    "- If a field has no relevant items, return an empty list []\n",
    "\n",
    "Example output format:\n",
    "{\n",
    "    \"source\": \"Reuters\",\n",
    "    \"headline\": \"Wall St. Bears Claw Back Into the Black\",\n",
    "    \"entities\": [\"Wall Street\", \"short-sellers\"],\n",
    "    \"topics\": [\"stock market\", \"trading\"],\n",
    "    \"locations\": [\"United States\"],\n",
    "    \"keywords\": [\"stocks\", \"bears\", \"rally\", \"markets\", \"trading\", \"investors\"],\n",
    "    \"summary\": \"Short-sellers on Wall Street recover losses as market conditions shift.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Converting Raw Data to User Prompts\n",
    "\n",
    "Each news article from the test dataset needs to be formatted as a user message for the LLM.\n",
    "\n",
    "**Raw Data Format (from AG News test set):**\n",
    "```python\n",
    "{\n",
    "    \"text\": \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling...\",\n",
    "    \"label\": 2  # Ground truth: Business (used for evaluation, not shown to LLM)\n",
    "}\n",
    "```\n",
    "\n",
    "**User Prompt Format:**\n",
    "```\n",
    "Analyze the following news article and extract the requested information:\n",
    "\n",
    "---\n",
    "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling...\n",
    "---\n",
    "```\n",
    "\n",
    "**Conversion Function Pattern:**\n",
    "```python\n",
    "def create_step1_user_prompt(article_text: str) -> str:\n",
    "    return f\"\"\"Analyze the following news article and extract the requested information:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "```\n",
    "\n",
    "This wrapper:\n",
    "1. Provides clear instruction on what to do\n",
    "2. Delimits the article text with markers (`---`) for clarity\n",
    "3. Keeps the original text intact (including the headline+source+body structure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31527afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 1: Entity & Keyword Extraction\n",
      "======================================================================\n",
      "\n",
      "Processing 100 samples from test set using Claude Sonnet 4.5...\n",
      "\n",
      "  âœ“ Processed 10/100 articles (10.0%)\n",
      "  âœ“ Processed 20/100 articles (20.0%)\n",
      "  âœ“ Processed 30/100 articles (30.0%)\n",
      "  âœ“ Processed 40/100 articles (40.0%)\n",
      "  âœ“ Processed 50/100 articles (50.0%)\n",
      "  âœ“ Processed 60/100 articles (60.0%)\n",
      "  âœ“ Processed 70/100 articles (70.0%)\n",
      "  âœ“ Processed 80/100 articles (80.0%)\n",
      "  âœ“ Processed 90/100 articles (90.0%)\n",
      "  âœ“ Processed 100/100 articles (100.0%)\n",
      "======================================================================\n",
      "STEP 1 RESULTS (showing first 3 of 100)\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 1\n",
      "Ground Truth: Business\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Extracted Information:\n",
      "{\n",
      "  \"source\": \"\",\n",
      "  \"headline\": \"Fears for T N pension after talks\",\n",
      "  \"entities\": [\n",
      "    \"Turner Newall\",\n",
      "    \"Federal Mogul\",\n",
      "    \"Unions\"\n",
      "  ],\n",
      "  \"topics\": [\n",
      "    \"pension concerns\",\n",
      "    \"labor negotiations\",\n",
      "    \"corporate restructuring\"\n",
      "  ],\n",
      "  \"locations\": [],\n",
      "  \"keywords\": [\n",
      "    \"pension\",\n",
      "    \"talks\",\n",
      "    \"unions\",\n",
      "    \"workers\",\n",
      "    \"disappointed\",\n",
      "    \"stricken\",\n",
      "    \"parent firm\"\n",
      "  ],\n",
      "  \"summary\": \"Union representatives express disappointment following discussions with Federal Mogul regarding pension concerns for Turner Newall workers.\"\n",
      "}\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 2\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Extracted Information:\n",
      "{\n",
      "  \"source\": \"SPACE.com\",\n",
      "  \"headline\": \"The Race is On: Second Private Team Sets Launch Date for Human Spaceflight\",\n",
      "  \"entities\": [\n",
      "    \"Ansari X Prize\"\n",
      "  ],\n",
      "  \"topics\": [\n",
      "    \"private spaceflight\",\n",
      "    \"space competition\",\n",
      "    \"human spaceflight\",\n",
      "    \"suborbital flight\"\n",
      "  ],\n",
      "  \"locations\": [\n",
      "    \"Toronto\",\n",
      "    \"Canada\"\n",
      "  ],\n",
      "  \"keywords\": [\n",
      "    \"spaceflight\",\n",
      "    \"rocket\",\n",
      "    \"Ansari X Prize\",\n",
      "    \"suborbital\",\n",
      "    \"manned\",\n",
      "    \"private\",\n",
      "    \"launch\",\n",
      "    \"competition\"\n",
      "  ],\n",
      "  \"summary\": \"A second private team competing for the $10 million Ansari X Prize has announced their first launch date for manned suborbital spaceflight.\"\n",
      "}\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 3\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Extracted Information:\n",
      "{\n",
      "  \"source\": \"AP\",\n",
      "  \"headline\": \"Ky. Company Wins Grant to Study Peptides\",\n",
      "  \"entities\": [\n",
      "    \"University of Louisville\"\n",
      "  ],\n",
      "  \"topics\": [\n",
      "    \"research grant\",\n",
      "    \"peptide development\",\n",
      "    \"biotechnology\",\n",
      "    \"university research\"\n",
      "  ],\n",
      "  \"locations\": [\n",
      "    \"Kentucky\",\n",
      "    \"Louisville\"\n",
      "  ],\n",
      "  \"keywords\": [\n",
      "    \"peptides\",\n",
      "    \"amino acids\",\n",
      "    \"proteins\",\n",
      "    \"chemistry\",\n",
      "    \"grant\",\n",
      "    \"research\",\n",
      "    \"building blocks\"\n",
      "  ],\n",
      "  \"summary\": \"A Kentucky company founded by a University of Louisville chemistry researcher received a grant to develop improved peptide production methods.\"\n",
      "}\n",
      "\n",
      "======================================================================\n",
      "Step 1 complete. 100 results stored in 'step1_results'\n",
      "Ready for Step 2.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 1: Entity & Keyword Extraction\n",
    "# ============================================================\n",
    "\n",
    "# System prompt for Step 1\n",
    "STEP1_SYSTEM_PROMPT = \"\"\"You are an expert information extraction system specialized in analyzing news articles.\n",
    "\n",
    "Your task is to extract key information from a news article that will help classify it into one of four categories: World, Sports, Business, or Sci/Tech.\n",
    "\n",
    "The input text follows this format: [Headline] ([Source]) [Source] - [Article Body]\n",
    "\n",
    "Extract the following information and return it as a JSON object:\n",
    "\n",
    "1. \"source\": The news source/wire service (e.g., \"Reuters\", \"AP\", \"AFP\")\n",
    "2. \"headline\": The article headline (text before the source in parentheses)\n",
    "3. \"entities\": A list of named entities (people, organizations, teams, companies)\n",
    "4. \"topics\": A list of 2-4 main topics or themes discussed\n",
    "5. \"locations\": A list of geographic references (countries, cities, regions)\n",
    "6. \"keywords\": A list of 5-10 domain-specific or significant keywords\n",
    "7. \"summary\": A one-sentence summary of the article's main point\n",
    "\n",
    "Rules:\n",
    "- Be concise and precise\n",
    "- Only extract information that is explicitly stated or clearly implied\n",
    "- Return ONLY valid JSON, no additional text or explanation\n",
    "- If a field has no relevant items, return an empty list []\n",
    "\n",
    "Example output format:\n",
    "{\n",
    "    \"source\": \"Reuters\",\n",
    "    \"headline\": \"Wall St. Bears Claw Back Into the Black\",\n",
    "    \"entities\": [\"Wall Street\", \"short-sellers\"],\n",
    "    \"topics\": [\"stock market\", \"trading\"],\n",
    "    \"locations\": [\"United States\"],\n",
    "    \"keywords\": [\"stocks\", \"bears\", \"rally\", \"markets\", \"trading\", \"investors\"],\n",
    "    \"summary\": \"Short-sellers on Wall Street recover losses as market conditions shift.\"\n",
    "}\"\"\"\n",
    "\n",
    "def create_step1_user_prompt(article_text: str) -> str:\n",
    "    \"\"\"Convert raw article text to Step 1 user prompt.\"\"\"\n",
    "    return f\"\"\"Analyze the following news article and extract the requested information:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "\n",
    "def run_step1_extraction(article_text: str) -> dict:\n",
    "    \"\"\"Run Step 1 extraction using Claude Sonnet 4.\"\"\"\n",
    "    user_prompt = create_step1_user_prompt(article_text)\n",
    "    \n",
    "    # Expected output is ~300-500 tokens (JSON with 7 fields)\n",
    "    # Setting to 2048 for safety margin on longer articles\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=2048,\n",
    "        system=STEP1_SYSTEM_PROMPT,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    response_text = response.content[0].text\n",
    "    try:\n",
    "        extracted_data = json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        # If parsing fails, return the raw text for debugging\n",
    "        extracted_data = {\"error\": \"Failed to parse JSON\", \"raw_response\": response_text}\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "# ============================================================\n",
    "# Process Test Data (100 samples) - SEQUENTIAL EXECUTION\n",
    "# ============================================================\n",
    "\n",
    "# Get the test dataset\n",
    "test_data = ag_news['test']\n",
    "label_names = ag_news['test'].features['label'].names\n",
    "\n",
    "# Sample size for experiment (using subset for faster iteration)\n",
    "NUM_SAMPLES = 100  # Using 100 samples (full test set has 7,600 rows)\n",
    "\n",
    "# Number of results to print (for display)\n",
    "NUM_TO_PRINT = 3\n",
    "\n",
    "# Store results in order (index aligned with test_data)\n",
    "step1_results = []\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 1: Entity & Keyword Extraction\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nProcessing {NUM_SAMPLES} samples from test set using Claude Sonnet 4.5...\\n\")\n",
    "\n",
    "# Progress tracking\n",
    "PROGRESS_INTERVAL = 10\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample = test_data[i]\n",
    "    article_text = sample['text']\n",
    "    ground_truth_label = sample['label']\n",
    "    \n",
    "    # Run Step 1 extraction\n",
    "    extraction_result = run_step1_extraction(article_text)\n",
    "    \n",
    "    # Store result with metadata\n",
    "    step1_results.append({\n",
    "        \"index\": i,\n",
    "        \"original_text\": article_text,\n",
    "        \"ground_truth_label\": ground_truth_label,\n",
    "        \"ground_truth_name\": label_names[ground_truth_label],\n",
    "        \"step1_extraction\": extraction_result\n",
    "    })\n",
    "    \n",
    "    # Print progress every PROGRESS_INTERVAL articles\n",
    "    if (i + 1) % PROGRESS_INTERVAL == 0 or (i + 1) == NUM_SAMPLES:\n",
    "        print(f\"  âœ“ Processed {i + 1}/{NUM_SAMPLES} articles ({(i + 1) / NUM_SAMPLES * 100:.1f}%)\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"STEP 1 RESULTS (showing first {NUM_TO_PRINT} of {len(step1_results)})\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Display results for first NUM_TO_PRINT articles only\n",
    "for result in step1_results[:NUM_TO_PRINT]:\n",
    "    print(f\"\\n{'â”€' * 70}\")\n",
    "    print(f\"Article {result['index'] + 1}\")\n",
    "    print(f\"Ground Truth: {result['ground_truth_name']}\")\n",
    "    print(f\"{'â”€' * 70}\")\n",
    "    print(\"\\nExtracted Information:\")\n",
    "    print(json.dumps(result['step1_extraction'], indent=2))\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Step 1 complete. {len(step1_results)} results stored in 'step1_results'\")\n",
    "print(f\"Ready for Step 2.\")\n",
    "print(f\"{'=' * 70}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7765c",
   "metadata": {},
   "source": [
    "### Step 2: Domain Signal Analysis\n",
    "\n",
    "**Objective:** Analyze the extracted information from Step 1 to identify domain-specific signals and reasoning that point towards each of the four categories.\n",
    "\n",
    "In this step, the LLM will:\n",
    "- **Analyze entities** for domain associations (e.g., \"Federal Reserve\" â†’ Business, \"FIFA\" â†’ Sports)\n",
    "- **Evaluate topics** for category alignment\n",
    "- **Consider geographic context** (international locations often signal World news)\n",
    "- **Examine keywords** for domain-specific terminology\n",
    "- **Provide reasoning** for why certain signals suggest specific categories\n",
    "\n",
    "**Why this step matters:**\n",
    "- Bridges the gap between raw extraction and final classification\n",
    "- Makes the classification reasoning explicit and inspectable\n",
    "- Allows the model to weigh different signals before making a final decision\n",
    "- Creates an audit trail of the decision-making process\n",
    "\n",
    "---\n",
    "\n",
    "#### How Step 2 Works\n",
    "\n",
    "Step 2 receives the **structured output from Step 1** and analyzes it to produce domain signals:\n",
    "\n",
    "```\n",
    "Step 1 Output (Input to Step 2)          Step 2 Output\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ {                           â”‚          â”‚ {                           â”‚\n",
    "â”‚   \"source\": \"Reuters\",      â”‚          â”‚   \"domain_signals\": {       â”‚\n",
    "â”‚   \"headline\": \"...\",        â”‚   â”€â”€â”€â–¶   â”‚     \"world\": [...],         â”‚\n",
    "â”‚   \"entities\": [...],        â”‚          â”‚     \"sports\": [...],        â”‚\n",
    "â”‚   \"topics\": [...],          â”‚          â”‚     \"business\": [...],      â”‚\n",
    "â”‚   \"locations\": [...],       â”‚          â”‚     \"sci_tech\": [...]       â”‚\n",
    "â”‚   \"keywords\": [...],        â”‚          â”‚   },                        â”‚\n",
    "â”‚   \"summary\": \"...\"          â”‚          â”‚   \"strongest_signals\": \"...\",â”‚\n",
    "â”‚ }                           â”‚          â”‚   \"reasoning\": \"...\"        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### System Prompt for Step 2\n",
    "\n",
    "```\n",
    "You are an expert news analyst specializing in categorizing news articles into four categories: World, Sports, Business, and Sci/Tech.\n",
    "\n",
    "You will receive extracted information from a news article including:\n",
    "- Source (news agency)\n",
    "- Headline\n",
    "- Named entities (people, organizations, companies)\n",
    "- Topics discussed\n",
    "- Geographic locations mentioned\n",
    "- Keywords\n",
    "- Summary\n",
    "\n",
    "Your task is to analyze this information and identify signals that suggest which category the article belongs to.\n",
    "\n",
    "For each category, identify relevant signals from the extracted data:\n",
    "- **World**: International affairs, politics, government, diplomacy, conflicts, humanitarian issues\n",
    "- **Sports**: Athletic events, teams, players, competitions, leagues, scores, tournaments\n",
    "- **Business**: Companies, markets, economy, finance, stocks, trade, corporate news\n",
    "- **Sci/Tech**: Science, technology, software, hardware, research, innovation, digital products\n",
    "\n",
    "Return your analysis as a JSON object with:\n",
    "\n",
    "1. \"domain_signals\": An object with four keys (world, sports, business, sci_tech), each containing a list of relevant signals found\n",
    "2. \"signal_strength\": An object rating the strength of signals for each category as \"none\", \"weak\", \"moderate\", or \"strong\"\n",
    "3. \"strongest_category\": The category with the strongest signals\n",
    "4. \"reasoning\": A brief explanation (1-2 sentences) of why the strongest category is most likely\n",
    "\n",
    "Rules:\n",
    "- Be objective and base your analysis only on the provided information\n",
    "- A signal can only support ONE category (don't double-count)\n",
    "- Return ONLY valid JSON, no additional text\n",
    "- If no signals exist for a category, use an empty list []\n",
    "\n",
    "Example output format:\n",
    "{\n",
    "    \"domain_signals\": {\n",
    "        \"world\": [\"United Nations mentioned\", \"diplomatic talks topic\"],\n",
    "        \"sports\": [],\n",
    "        \"business\": [\"stock market keywords\"],\n",
    "        \"sci_tech\": []\n",
    "    },\n",
    "    \"signal_strength\": {\n",
    "        \"world\": \"strong\",\n",
    "        \"sports\": \"none\",\n",
    "        \"business\": \"weak\",\n",
    "        \"sci_tech\": \"none\"\n",
    "    },\n",
    "    \"strongest_category\": \"world\",\n",
    "    \"reasoning\": \"The article discusses UN diplomatic negotiations, with strong international affairs signals and only peripheral business context.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Converting Step 1 Output to Step 2 User Prompts\n",
    "\n",
    "Each Step 1 result contains the `step1_extraction` field with the extracted JSON. This needs to be formatted as input for Step 2.\n",
    "\n",
    "**Step 1 Output (stored in `step1_results`):**\n",
    "```python\n",
    "{\n",
    "    \"index\": 0,\n",
    "    \"original_text\": \"...\",\n",
    "    \"ground_truth_label\": 2,\n",
    "    \"ground_truth_name\": \"Business\",\n",
    "    \"step1_extraction\": {\n",
    "        \"source\": \"Reuters\",\n",
    "        \"headline\": \"Wall St. Bears Claw Back Into the Black\",\n",
    "        \"entities\": [\"Wall Street\", \"short-sellers\"],\n",
    "        \"topics\": [\"stock market\", \"trading\"],\n",
    "        \"locations\": [\"United States\"],\n",
    "        \"keywords\": [\"stocks\", \"bears\", \"rally\", \"markets\"],\n",
    "        \"summary\": \"Short-sellers recover losses as market conditions shift.\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Step 2 User Prompt Format:**\n",
    "```\n",
    "Analyze the following extracted information from a news article and identify domain signals for classification:\n",
    "\n",
    "---\n",
    "{\n",
    "    \"source\": \"Reuters\",\n",
    "    \"headline\": \"Wall St. Bears Claw Back Into the Black\",\n",
    "    \"entities\": [\"Wall Street\", \"short-sellers\"],\n",
    "    \"topics\": [\"stock market\", \"trading\"],\n",
    "    \"locations\": [\"United States\"],\n",
    "    \"keywords\": [\"stocks\", \"bears\", \"rally\", \"markets\"],\n",
    "    \"summary\": \"Short-sellers recover losses as market conditions shift.\"\n",
    "}\n",
    "---\n",
    "```\n",
    "\n",
    "**Conversion Function Pattern:**\n",
    "```python\n",
    "def create_step2_user_prompt(step1_extraction: dict) -> str:\n",
    "    extraction_json = json.dumps(step1_extraction, indent=2)\n",
    "    return f\"\"\"Analyze the following extracted information from a news article and identify domain signals for classification:\n",
    "\n",
    "---\n",
    "{extraction_json}\n",
    "---\"\"\"\n",
    "```\n",
    "\n",
    "This conversion:\n",
    "1. Takes the `step1_extraction` dictionary from Step 1 results\n",
    "2. Serializes it to formatted JSON for readability\n",
    "3. Wraps it with clear instructions and delimiters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cd45adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 2: Domain Signal Analysis\n",
      "======================================================================\n",
      "\n",
      "Processing 100 samples using GPT-5.1...\n",
      "\n",
      "  âœ“ Processed 10/100 articles (10.0%)\n",
      "  âœ“ Processed 20/100 articles (20.0%)\n",
      "  âœ“ Processed 30/100 articles (30.0%)\n",
      "  âœ“ Processed 40/100 articles (40.0%)\n",
      "  âœ“ Processed 50/100 articles (50.0%)\n",
      "  âœ“ Processed 60/100 articles (60.0%)\n",
      "  âœ“ Processed 70/100 articles (70.0%)\n",
      "  âœ“ Processed 80/100 articles (80.0%)\n",
      "  âœ“ Processed 90/100 articles (90.0%)\n",
      "  âœ“ Processed 100/100 articles (100.0%)\n",
      "======================================================================\n",
      "STEP 2 RESULTS (showing first 3 of 100)\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 1\n",
      "Ground Truth: Business\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Step 2 Analysis (Domain Signals):\n",
      "{\n",
      "  \"domain_signals\": {\n",
      "    \"world\": [],\n",
      "    \"sports\": [],\n",
      "    \"business\": [\n",
      "      \"Corporate entities mentioned: Turner Newall and its parent firm Federal Mogul\",\n",
      "      \"Topics include pension concerns linked to a company and corporate restructuring\",\n",
      "      \"Keywords such as \\\"parent firm\\\" and \\\"stricken\\\" indicate corporate/financial distress context\",\n",
      "      \"Labor negotiations between unions and a corporation over worker pensions\"\n",
      "    ],\n",
      "    \"sci_tech\": []\n",
      "  },\n",
      "  \"signal_strength\": {\n",
      "    \"world\": \"none\",\n",
      "    \"sports\": \"none\",\n",
      "    \"business\": \"strong\",\n",
      "    \"sci_tech\": \"none\"\n",
      "  },\n",
      "  \"strongest_category\": \"business\",\n",
      "  \"reasoning\": \"The article centers on union talks with a parent company over worker pensions and corporate restructuring, which are core business and corporate finance issues.\"\n",
      "}\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 2\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Step 2 Analysis (Domain Signals):\n",
      "{\n",
      "  \"domain_signals\": {\n",
      "    \"world\": [],\n",
      "    \"sports\": [],\n",
      "    \"business\": [],\n",
      "    \"sci_tech\": [\n",
      "      \"Focus on private spaceflight and human spaceflight technology\",\n",
      "      \"Mention of rockets and suborbital flight as aerospace engineering topics\",\n",
      "      \"Coverage by SPACE.com, a science/space-focused outlet\",\n",
      "      \"Technological competition (Ansari X Prize) around developing manned suborbital vehicles\"\n",
      "    ]\n",
      "  },\n",
      "  \"signal_strength\": {\n",
      "    \"world\": \"none\",\n",
      "    \"sports\": \"none\",\n",
      "    \"business\": \"none\",\n",
      "    \"sci_tech\": \"strong\"\n",
      "  },\n",
      "  \"strongest_category\": \"sci_tech\",\n",
      "  \"reasoning\": \"The article centers on private human spaceflight, rockets, and suborbital launch technology in the context of the Ansari X Prize, which are all core science and technology themes with no substantial political, athletic, or market/financial focus.\"\n",
      "}\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 3\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Step 2 Analysis (Domain Signals):\n",
      "{\n",
      "  \"domain_signals\": {\n",
      "    \"world\": [],\n",
      "    \"sports\": [],\n",
      "    \"business\": [\n",
      "      \"Company received a grant\",\n",
      "      \"Headline refers to 'Company Wins Grant'\",\n",
      "      \"Corporate context (a company founded by a researcher)\"\n",
      "    ],\n",
      "    \"sci_tech\": [\n",
      "      \"Peptide development and biotechnology mentioned\",\n",
      "      \"Keywords include peptides, amino acids, proteins, chemistry\",\n",
      "      \"Research focus on improved peptide production methods\",\n",
      "      \"University research involvement (University of Louisville)\"\n",
      "    ]\n",
      "  },\n",
      "  \"signal_strength\": {\n",
      "    \"world\": \"none\",\n",
      "    \"sports\": \"none\",\n",
      "    \"business\": \"moderate\",\n",
      "    \"sci_tech\": \"strong\"\n",
      "  },\n",
      "  \"strongest_category\": \"sci_tech\",\n",
      "  \"reasoning\": \"The article centers on scientific research in biotechnology and peptide chemistry, with technical research keywords and academic involvement dominating over the secondary business aspect of receiving a grant.\"\n",
      "}\n",
      "\n",
      "======================================================================\n",
      "Step 2 complete. 100 results stored in 'step2_results'\n",
      "Ready for Step 3.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 2: Domain Signal Analysis\n",
    "# ============================================================\n",
    "\n",
    "# System prompt for Step 2\n",
    "STEP2_SYSTEM_PROMPT = \"\"\"You are an expert news analyst specializing in categorizing news articles into four categories: World, Sports, Business, and Sci/Tech.\n",
    "\n",
    "You will receive extracted information from a news article including:\n",
    "- Source (news agency)\n",
    "- Headline\n",
    "- Named entities (people, organizations, companies)\n",
    "- Topics discussed\n",
    "- Geographic locations mentioned\n",
    "- Keywords\n",
    "- Summary\n",
    "\n",
    "Your task is to analyze this information and identify signals that suggest which category the article belongs to.\n",
    "\n",
    "For each category, identify relevant signals from the extracted data:\n",
    "- **World**: International affairs, politics, government, diplomacy, conflicts, humanitarian issues\n",
    "- **Sports**: Athletic events, teams, players, competitions, leagues, scores, tournaments\n",
    "- **Business**: Companies, markets, economy, finance, stocks, trade, corporate news\n",
    "- **Sci/Tech**: Science, technology, software, hardware, research, innovation, digital products\n",
    "\n",
    "Return your analysis as a JSON object with:\n",
    "\n",
    "1. \"domain_signals\": An object with four keys (world, sports, business, sci_tech), each containing a list of relevant signals found\n",
    "2. \"signal_strength\": An object rating the strength of signals for each category as \"none\", \"weak\", \"moderate\", or \"strong\"\n",
    "3. \"strongest_category\": The category with the strongest signals\n",
    "4. \"reasoning\": A brief explanation (1-2 sentences) of why the strongest category is most likely\n",
    "\n",
    "Rules:\n",
    "- Be objective and base your analysis only on the provided information\n",
    "- A signal can only support ONE category (don't double-count)\n",
    "- Return ONLY valid JSON, no additional text\n",
    "- If no signals exist for a category, use an empty list []\n",
    "\n",
    "Example output format:\n",
    "{\n",
    "    \"domain_signals\": {\n",
    "        \"world\": [\"United Nations mentioned\", \"diplomatic talks topic\"],\n",
    "        \"sports\": [],\n",
    "        \"business\": [\"stock market keywords\"],\n",
    "        \"sci_tech\": []\n",
    "    },\n",
    "    \"signal_strength\": {\n",
    "        \"world\": \"strong\",\n",
    "        \"sports\": \"none\",\n",
    "        \"business\": \"weak\",\n",
    "        \"sci_tech\": \"none\"\n",
    "    },\n",
    "    \"strongest_category\": \"world\",\n",
    "    \"reasoning\": \"The article discusses UN diplomatic negotiations, with strong international affairs signals and only peripheral business context.\"\n",
    "}\"\"\"\n",
    "\n",
    "def create_step2_user_prompt(step1_extraction: dict) -> str:\n",
    "    \"\"\"Convert Step 1 extraction output to Step 2 user prompt.\"\"\"\n",
    "    extraction_json = json.dumps(step1_extraction, indent=2)\n",
    "    return f\"\"\"Analyze the following extracted information from a news article and identify domain signals for classification:\n",
    "\n",
    "---\n",
    "{extraction_json}\n",
    "---\"\"\"\n",
    "\n",
    "def run_step2_analysis(step1_extraction: dict) -> dict:\n",
    "    \"\"\"Run Step 2 domain signal analysis using GPT-5.1.\"\"\"\n",
    "    user_prompt = create_step2_user_prompt(step1_extraction)\n",
    "    \n",
    "    # Note: Newer OpenAI models use 'max_completion_tokens' instead of 'max_tokens'\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-5.1\",\n",
    "        max_completion_tokens=2048,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": STEP2_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    response_text = response.choices[0].message.content\n",
    "    try:\n",
    "        analysis_result = json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        # If parsing fails, return the raw text for debugging\n",
    "        analysis_result = {\"error\": \"Failed to parse JSON\", \"raw_response\": response_text}\n",
    "    \n",
    "    return analysis_result\n",
    "\n",
    "# ============================================================\n",
    "# Process All Step 1 Results\n",
    "# ============================================================\n",
    "\n",
    "# Store Step 2 results (same order as step1_results)\n",
    "step2_results = []\n",
    "\n",
    "# Number of results to print (for display)\n",
    "NUM_TO_PRINT = 3\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 2: Domain Signal Analysis\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nProcessing {len(step1_results)} samples using GPT-5.1...\\n\")\n",
    "\n",
    "# Progress tracking\n",
    "PROGRESS_INTERVAL = 10\n",
    "\n",
    "for i, step1_result in enumerate(step1_results):\n",
    "    # Get the Step 1 extraction output\n",
    "    step1_extraction = step1_result['step1_extraction']\n",
    "    \n",
    "    # Run Step 2 analysis\n",
    "    analysis_result = run_step2_analysis(step1_extraction)\n",
    "    \n",
    "    # Store result with metadata (carry forward from Step 1)\n",
    "    step2_results.append({\n",
    "        \"index\": step1_result['index'],\n",
    "        \"original_text\": step1_result['original_text'],\n",
    "        \"ground_truth_label\": step1_result['ground_truth_label'],\n",
    "        \"ground_truth_name\": step1_result['ground_truth_name'],\n",
    "        \"step1_extraction\": step1_extraction,\n",
    "        \"step2_analysis\": analysis_result\n",
    "    })\n",
    "    \n",
    "    # Print progress every PROGRESS_INTERVAL articles\n",
    "    if (i + 1) % PROGRESS_INTERVAL == 0 or (i + 1) == len(step1_results):\n",
    "        print(f\"  âœ“ Processed {i + 1}/{len(step1_results)} articles ({(i + 1) / len(step1_results) * 100:.1f}%)\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"STEP 2 RESULTS (showing first {NUM_TO_PRINT} of {len(step2_results)})\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Display results for first NUM_TO_PRINT articles only\n",
    "for result in step2_results[:NUM_TO_PRINT]:\n",
    "    print(f\"\\n{'â”€' * 70}\")\n",
    "    print(f\"Article {result['index'] + 1}\")\n",
    "    print(f\"Ground Truth: {result['ground_truth_name']}\")\n",
    "    print(f\"{'â”€' * 70}\")\n",
    "    print(\"\\nStep 2 Analysis (Domain Signals):\")\n",
    "    print(json.dumps(result['step2_analysis'], indent=2))\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Step 2 complete. {len(step2_results)} results stored in 'step2_results'\")\n",
    "print(f\"Ready for Step 3.\")\n",
    "print(f\"{'=' * 70}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e97fb0e",
   "metadata": {},
   "source": [
    "### Step 3: Final Classification\n",
    "\n",
    "**Objective:** Make the final classification decision based on the domain signal analysis from Step 2, outputting one of the four categories: World, Sports, Business, or Sci/Tech.\n",
    "\n",
    "This is the final step in our prompt chain where all the accumulated analysis converges into a single classification decision.\n",
    "\n",
    "In this step, the LLM will:\n",
    "- **Review the domain signals** identified for each category\n",
    "- **Consider signal strengths** (none, weak, moderate, strong)\n",
    "- **Evaluate the reasoning** from Step 2\n",
    "- **Make the final decision** with confidence level\n",
    "- **Provide justification** for the classification\n",
    "\n",
    "**Why this step matters:**\n",
    "- Synthesizes all previous analysis into an actionable output\n",
    "- Adds a layer of deliberation before final decision\n",
    "- Provides confidence scores for downstream use\n",
    "- Creates complete traceability from raw text â†’ extraction â†’ signals â†’ classification\n",
    "\n",
    "---\n",
    "\n",
    "#### How Step 3 Works\n",
    "\n",
    "Step 3 receives the **domain signal analysis from Step 2** and produces the final classification:\n",
    "\n",
    "```\n",
    "Step 2 Output (Input to Step 3)          Step 3 Output (Final)\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ {                           â”‚          â”‚ {                           â”‚\n",
    "â”‚   \"domain_signals\": {...},  â”‚          â”‚   \"classification\": \"...\",  â”‚\n",
    "â”‚   \"signal_strength\": {...}, â”‚   â”€â”€â”€â–¶   â”‚   \"confidence\": \"...\",      â”‚\n",
    "â”‚   \"strongest_category\": \".\",â”‚          â”‚   \"justification\": \"...\"    â”‚\n",
    "â”‚   \"reasoning\": \"...\"        â”‚          â”‚ }                           â”‚\n",
    "â”‚ }                           â”‚          â”‚                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### System Prompt for Step 3\n",
    "\n",
    "```\n",
    "You are a news classification system that makes final categorization decisions.\n",
    "\n",
    "You will receive a domain signal analysis for a news article, containing:\n",
    "- Domain signals identified for each category (World, Sports, Business, Sci/Tech)\n",
    "- Signal strength ratings for each category\n",
    "- The strongest category identified\n",
    "- Reasoning from the analysis\n",
    "\n",
    "Your task is to make the FINAL classification decision.\n",
    "\n",
    "The four categories are:\n",
    "- **World**: International news, politics, government, diplomacy, conflicts, global events\n",
    "- **Sports**: Athletic competitions, teams, players, leagues, tournaments, scores\n",
    "- **Business**: Companies, markets, finance, economy, stocks, corporate news, trade\n",
    "- **Sci/Tech**: Technology, science, software, hardware, research, innovation, internet\n",
    "\n",
    "Return your decision as a JSON object with:\n",
    "\n",
    "1. \"classification\": The final category (must be exactly one of: \"World\", \"Sports\", \"Business\", \"Sci/Tech\")\n",
    "2. \"confidence\": Your confidence level (\"high\", \"medium\", or \"low\")\n",
    "3. \"justification\": A brief explanation (1-2 sentences) of why you chose this category\n",
    "\n",
    "Rules:\n",
    "- You MUST choose exactly ONE category\n",
    "- Base your decision on the signal analysis provided\n",
    "- If signals are ambiguous, use the strongest_category as a tiebreaker\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Example output format:\n",
    "{\n",
    "    \"classification\": \"Business\",\n",
    "    \"confidence\": \"high\",\n",
    "    \"justification\": \"Strong business signals including stock market keywords and corporate entities, with no competing signals from other categories.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Converting Step 2 Output to Step 3 User Prompts\n",
    "\n",
    "Each Step 2 result contains the `step2_analysis` field with the domain signal analysis. This needs to be formatted as input for Step 3.\n",
    "\n",
    "**Step 2 Output (stored in `step2_results`):**\n",
    "```python\n",
    "{\n",
    "    \"index\": 0,\n",
    "    \"original_text\": \"...\",\n",
    "    \"ground_truth_label\": 2,\n",
    "    \"ground_truth_name\": \"Business\",\n",
    "    \"step1_extraction\": {...},\n",
    "    \"step2_analysis\": {\n",
    "        \"domain_signals\": {\n",
    "            \"world\": [],\n",
    "            \"sports\": [],\n",
    "            \"business\": [\"Wall Street entity\", \"stock market topic\", \"trading keywords\"],\n",
    "            \"sci_tech\": []\n",
    "        },\n",
    "        \"signal_strength\": {\n",
    "            \"world\": \"none\",\n",
    "            \"sports\": \"none\",\n",
    "            \"business\": \"strong\",\n",
    "            \"sci_tech\": \"none\"\n",
    "        },\n",
    "        \"strongest_category\": \"business\",\n",
    "        \"reasoning\": \"Clear business signals with stock market and trading terminology.\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Step 3 User Prompt Format:**\n",
    "```\n",
    "Based on the following domain signal analysis, make the final classification decision:\n",
    "\n",
    "---\n",
    "{\n",
    "    \"domain_signals\": {\n",
    "        \"world\": [],\n",
    "        \"sports\": [],\n",
    "        \"business\": [\"Wall Street entity\", \"stock market topic\", \"trading keywords\"],\n",
    "        \"sci_tech\": []\n",
    "    },\n",
    "    \"signal_strength\": {\n",
    "        \"world\": \"none\",\n",
    "        \"sports\": \"none\",\n",
    "        \"business\": \"strong\",\n",
    "        \"sci_tech\": \"none\"\n",
    "    },\n",
    "    \"strongest_category\": \"business\",\n",
    "    \"reasoning\": \"Clear business signals with stock market and trading terminology.\"\n",
    "}\n",
    "---\n",
    "```\n",
    "\n",
    "**Conversion Function Pattern:**\n",
    "```python\n",
    "def create_step3_user_prompt(step2_analysis: dict) -> str:\n",
    "    analysis_json = json.dumps(step2_analysis, indent=2)\n",
    "    return f\"\"\"Based on the following domain signal analysis, make the final classification decision:\n",
    "\n",
    "---\n",
    "{analysis_json}\n",
    "---\"\"\"\n",
    "```\n",
    "\n",
    "This conversion:\n",
    "1. Takes the `step2_analysis` dictionary from Step 2 results\n",
    "2. Serializes it to formatted JSON\n",
    "3. Wraps it with clear instruction to make the final decision\n",
    "\n",
    "---\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "After Step 3, we can compare the `classification` output against the `ground_truth_name` to calculate accuracy:\n",
    "\n",
    "```python\n",
    "# Predicted: step3_result['step3_classification']['classification']\n",
    "# Actual:    step3_result['ground_truth_name']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2d8ce22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 3: Final Classification\n",
      "======================================================================\n",
      "\n",
      "Processing 100 samples using Claude Haiku 4.5...\n",
      "\n",
      "  âœ“ Processed 10/100 articles (10.0%)\n",
      "  âœ“ Processed 20/100 articles (20.0%)\n",
      "  âœ“ Processed 30/100 articles (30.0%)\n",
      "  âœ“ Processed 40/100 articles (40.0%)\n",
      "  âœ“ Processed 50/100 articles (50.0%)\n",
      "  âœ“ Processed 60/100 articles (60.0%)\n",
      "  âœ“ Processed 70/100 articles (70.0%)\n",
      "  âœ“ Processed 80/100 articles (80.0%)\n",
      "  âœ“ Processed 90/100 articles (90.0%)\n",
      "  âœ“ Processed 100/100 articles (100.0%)\n",
      "======================================================================\n",
      "STEP 3 RESULTS (showing first 3 of 100)\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 1\n",
      "Ground Truth: Business\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Step 3 Classification (Final Decision):\n",
      "{\n",
      "  \"classification\": \"Business\",\n",
      "  \"confidence\": \"high\",\n",
      "  \"justification\": \"Strong business signals dominate the analysis, with clear focus on corporate entities (Turner Newall and Federal Mogul), pension/labor negotiations, and corporate restructuring\\u2014all core business and corporate finance topics with no competing signals from other categories.\"\n",
      "}\n",
      "\n",
      "  Predicted: Business | Actual: Business | âœ“ CORRECT\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 2\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Step 3 Classification (Final Decision):\n",
      "{\n",
      "  \"classification\": \"Sci/Tech\",\n",
      "  \"confidence\": \"high\",\n",
      "  \"justification\": \"The article focuses on private spaceflight technology, rockets, and suborbital aerospace engineering in the context of the Ansari X Prize competition, with coverage from SPACE.com\\u2014all clear indicators of science and technology content with no competing signals from other categories.\"\n",
      "}\n",
      "\n",
      "  Predicted: Sci/Tech | Actual: Sci/Tech | âœ“ CORRECT\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 3\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Step 3 Classification (Final Decision):\n",
      "{\n",
      "  \"classification\": \"Sci/Tech\",\n",
      "  \"confidence\": \"high\",\n",
      "  \"justification\": \"The article primarily focuses on scientific research in biotechnology and peptide development with strong technical keywords and university research involvement, while the grant award is a secondary business element supporting the research rather than the main news focus.\"\n",
      "}\n",
      "\n",
      "  Predicted: Sci/Tech | Actual: Sci/Tech | âœ“ CORRECT\n",
      "\n",
      "======================================================================\n",
      "Step 3 complete. 100 results stored in 'step3_results'\n",
      "Ready for evaluation.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 3: Final Classification\n",
    "# ============================================================\n",
    "\n",
    "# System prompt for Step 3\n",
    "STEP3_SYSTEM_PROMPT = \"\"\"You are a news classification system that makes final categorization decisions.\n",
    "\n",
    "You will receive a domain signal analysis for a news article, containing:\n",
    "- Domain signals identified for each category (World, Sports, Business, Sci/Tech)\n",
    "- Signal strength ratings for each category\n",
    "- The strongest category identified\n",
    "- Reasoning from the analysis\n",
    "\n",
    "Your task is to make the FINAL classification decision.\n",
    "\n",
    "The four categories are:\n",
    "- **World**: International news, politics, government, diplomacy, conflicts, global events\n",
    "- **Sports**: Athletic competitions, teams, players, leagues, tournaments, scores\n",
    "- **Business**: Companies, markets, finance, economy, stocks, corporate news, trade\n",
    "- **Sci/Tech**: Technology, science, software, hardware, research, innovation, internet\n",
    "\n",
    "Return your decision as a JSON object with:\n",
    "\n",
    "1. \"classification\": The final category (must be exactly one of: \"World\", \"Sports\", \"Business\", \"Sci/Tech\")\n",
    "2. \"confidence\": Your confidence level (\"high\", \"medium\", or \"low\")\n",
    "3. \"justification\": A brief explanation (1-2 sentences) of why you chose this category\n",
    "\n",
    "Rules:\n",
    "- You MUST choose exactly ONE category\n",
    "- Base your decision on the signal analysis provided\n",
    "- If signals are ambiguous, use the strongest_category as a tiebreaker\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Example output format:\n",
    "{\n",
    "    \"classification\": \"Business\",\n",
    "    \"confidence\": \"high\",\n",
    "    \"justification\": \"Strong business signals including stock market keywords and corporate entities, with no competing signals from other categories.\"\n",
    "}\"\"\"\n",
    "\n",
    "def create_step3_user_prompt(step2_analysis: dict) -> str:\n",
    "    \"\"\"Convert Step 2 analysis output to Step 3 user prompt.\"\"\"\n",
    "    analysis_json = json.dumps(step2_analysis, indent=2)\n",
    "    return f\"\"\"Based on the following domain signal analysis, make the final classification decision:\n",
    "\n",
    "---\n",
    "{analysis_json}\n",
    "---\"\"\"\n",
    "\n",
    "def run_step3_classification(step2_analysis: dict) -> dict:\n",
    "    \"\"\"Run Step 3 final classification using Claude Haiku 4.5.\"\"\"\n",
    "    user_prompt = create_step3_user_prompt(step2_analysis)\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        max_tokens=1024,\n",
    "        system=STEP3_SYSTEM_PROMPT,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    response_text = response.content[0].text\n",
    "    \n",
    "    # Strip markdown code blocks if present (```json ... ``` or ``` ... ```)\n",
    "    cleaned_text = response_text.strip()\n",
    "    if cleaned_text.startswith(\"```\"):\n",
    "        # Remove opening ``` or ```json\n",
    "        lines = cleaned_text.split(\"\\n\")\n",
    "        # Remove first line (```json or ```)\n",
    "        lines = lines[1:]\n",
    "        # Remove last line (```)\n",
    "        if lines and lines[-1].strip() == \"```\":\n",
    "            lines = lines[:-1]\n",
    "        cleaned_text = \"\\n\".join(lines)\n",
    "    \n",
    "    try:\n",
    "        classification_result = json.loads(cleaned_text)\n",
    "    except json.JSONDecodeError:\n",
    "        # If parsing fails, return the raw text for debugging\n",
    "        classification_result = {\"error\": \"Failed to parse JSON\", \"raw_response\": response_text}\n",
    "    \n",
    "    return classification_result\n",
    "\n",
    "# ============================================================\n",
    "# Process All Step 2 Results\n",
    "# ============================================================\n",
    "\n",
    "# Store Step 3 results (same order as step2_results)\n",
    "step3_results = []\n",
    "\n",
    "# Number of results to print (for display)\n",
    "NUM_TO_PRINT = 3\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 3: Final Classification\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nProcessing {len(step2_results)} samples using Claude Haiku 4.5...\\n\")\n",
    "\n",
    "# Progress tracking\n",
    "PROGRESS_INTERVAL = 10\n",
    "\n",
    "for i, step2_result in enumerate(step2_results):\n",
    "    # Get the Step 2 analysis output\n",
    "    step2_analysis = step2_result['step2_analysis']\n",
    "    \n",
    "    # Run Step 3 classification\n",
    "    classification_result = run_step3_classification(step2_analysis)\n",
    "    \n",
    "    # Store result with all metadata (carry forward from previous steps)\n",
    "    step3_results.append({\n",
    "        \"index\": step2_result['index'],\n",
    "        \"original_text\": step2_result['original_text'],\n",
    "        \"ground_truth_label\": step2_result['ground_truth_label'],\n",
    "        \"ground_truth_name\": step2_result['ground_truth_name'],\n",
    "        \"step1_extraction\": step2_result['step1_extraction'],\n",
    "        \"step2_analysis\": step2_analysis,\n",
    "        \"step3_classification\": classification_result\n",
    "    })\n",
    "    \n",
    "    # Print progress every PROGRESS_INTERVAL articles\n",
    "    if (i + 1) % PROGRESS_INTERVAL == 0 or (i + 1) == len(step2_results):\n",
    "        print(f\"  âœ“ Processed {i + 1}/{len(step2_results)} articles ({(i + 1) / len(step2_results) * 100:.1f}%)\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"STEP 3 RESULTS (showing first {NUM_TO_PRINT} of {len(step3_results)})\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Display results for first NUM_TO_PRINT articles only\n",
    "for result in step3_results[:NUM_TO_PRINT]:\n",
    "    print(f\"\\n{'â”€' * 70}\")\n",
    "    print(f\"Article {result['index'] + 1}\")\n",
    "    print(f\"Ground Truth: {result['ground_truth_name']}\")\n",
    "    print(f\"{'â”€' * 70}\")\n",
    "    print(\"\\nStep 3 Classification (Final Decision):\")\n",
    "    print(json.dumps(result['step3_classification'], indent=2))\n",
    "    \n",
    "    # Quick comparison\n",
    "    predicted = result['step3_classification'].get('classification', 'N/A')\n",
    "    actual = result['ground_truth_name']\n",
    "    match = \"âœ“ CORRECT\" if predicted == actual else \"âœ— INCORRECT\"\n",
    "    print(f\"\\n  Predicted: {predicted} | Actual: {actual} | {match}\")\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Step 3 complete. {len(step3_results)} results stored in 'step3_results'\")\n",
    "print(f\"Ready for evaluation.\")\n",
    "print(f\"{'=' * 70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af409512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PROMPT CHAINING CLASSIFICATION - EVALUATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "OVERALL METRICS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Total Samples:     100\n",
      "  Valid Predictions: 100\n",
      "  Error Rate:        0.0%\n",
      "\n",
      "  ğŸ“Š Accuracy:        0.8300  (83.0%)\n",
      "\n",
      "  Macro Averages (treats all classes equally):\n",
      "     Precision:      0.8274\n",
      "     Recall:         0.8788\n",
      "     F1 Score:       0.8224\n",
      "\n",
      "  Weighted Averages (accounts for class imbalance):\n",
      "     Precision:      0.8907\n",
      "     Recall:         0.8300\n",
      "     F1 Score:       0.8360\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "PER-CLASS METRICS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.90      0.87      0.88        30\n",
      "      Sports       0.91      1.00      0.95        21\n",
      "    Business       0.50      1.00      0.67        12\n",
      "    Sci/Tech       1.00      0.65      0.79        37\n",
      "\n",
      "    accuracy                           0.83       100\n",
      "   macro avg       0.83      0.88      0.82       100\n",
      "weighted avg       0.89      0.83      0.84       100\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CONFUSION MATRIX\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Predicted â†’     World    Sports  Business  Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Actual â†“\n",
      "          World        26         2         2         0\n",
      "         Sports         0        21         0         0\n",
      "       Business         0         0        12         0\n",
      "       Sci/Tech         3         0        10        24\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DISTRIBUTION ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Category        Ground Truth       Predicted   Difference\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "World                     30              29           -1\n",
      "Sports                    21              23           +2\n",
      "Business                  12              24          +12\n",
      "Sci/Tech                  37              24          -13\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CONFIDENCE ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Confidence        Count     Accuracy\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "high                 97       82.5%\n",
      "medium                3      100.0%\n",
      "low                   0          N/A\n",
      "\n",
      "======================================================================\n",
      "EVALUATION COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EVALUATION: Performance Metrics\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from collections import Counter\n",
    "\n",
    "# Define the category labels\n",
    "CATEGORIES = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "\n",
    "# Extract predictions and ground truth\n",
    "predictions = []\n",
    "ground_truths = []\n",
    "errors = []\n",
    "\n",
    "for result in step3_results:\n",
    "    ground_truth = result['ground_truth_name']\n",
    "    ground_truths.append(ground_truth)\n",
    "    \n",
    "    # Get prediction from step3_classification\n",
    "    step3_output = result['step3_classification']\n",
    "    \n",
    "    if 'classification' in step3_output:\n",
    "        predicted = step3_output['classification']\n",
    "        predictions.append(predicted)\n",
    "    else:\n",
    "        # Handle parsing errors - mark as error\n",
    "        predictions.append(\"ERROR\")\n",
    "        errors.append(result['index'])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PROMPT CHAINING CLASSIFICATION - EVALUATION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for errors\n",
    "if errors:\n",
    "    print(f\"\\nâš ï¸  Warning: {len(errors)} samples had parsing errors (indices: {errors[:10]}{'...' if len(errors) > 10 else ''})\")\n",
    "    print(f\"   These are excluded from metrics calculation.\\n\")\n",
    "    \n",
    "    # Filter out errors for metric calculation\n",
    "    valid_predictions = [p for p in predictions if p != \"ERROR\"]\n",
    "    valid_ground_truths = [g for p, g in zip(predictions, ground_truths) if p != \"ERROR\"]\n",
    "else:\n",
    "    valid_predictions = predictions\n",
    "    valid_ground_truths = ground_truths\n",
    "\n",
    "# ============================================================\n",
    "# Basic Metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"OVERALL METRICS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "accuracy = accuracy_score(valid_ground_truths, valid_predictions)\n",
    "precision_macro = precision_score(valid_ground_truths, valid_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "recall_macro = recall_score(valid_ground_truths, valid_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "f1_macro = f1_score(valid_ground_truths, valid_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "\n",
    "precision_weighted = precision_score(valid_ground_truths, valid_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "recall_weighted = recall_score(valid_ground_truths, valid_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "f1_weighted = f1_score(valid_ground_truths, valid_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\n  Total Samples:     {len(step3_results)}\")\n",
    "print(f\"  Valid Predictions: {len(valid_predictions)}\")\n",
    "print(f\"  Error Rate:        {len(errors) / len(step3_results) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n  ğŸ“Š Accuracy:        {accuracy:.4f}  ({accuracy * 100:.1f}%)\")\n",
    "print(f\"\\n  Macro Averages (treats all classes equally):\")\n",
    "print(f\"     Precision:      {precision_macro:.4f}\")\n",
    "print(f\"     Recall:         {recall_macro:.4f}\")\n",
    "print(f\"     F1 Score:       {f1_macro:.4f}\")\n",
    "\n",
    "print(f\"\\n  Weighted Averages (accounts for class imbalance):\")\n",
    "print(f\"     Precision:      {precision_weighted:.4f}\")\n",
    "print(f\"     Recall:         {recall_weighted:.4f}\")\n",
    "print(f\"     F1 Score:       {f1_weighted:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Per-Class Metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"PER-CLASS METRICS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "print(\"\\n\" + classification_report(valid_ground_truths, valid_predictions, labels=CATEGORIES, zero_division=0))\n",
    "\n",
    "# ============================================================\n",
    "# Confusion Matrix\n",
    "# ============================================================\n",
    "\n",
    "print(\"â”€\" * 70)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "cm = confusion_matrix(valid_ground_truths, valid_predictions, labels=CATEGORIES)\n",
    "\n",
    "# Print header\n",
    "print(f\"\\n{'Predicted â†’':>15}\", end=\"\")\n",
    "for cat in CATEGORIES:\n",
    "    print(f\"{cat:>10}\", end=\"\")\n",
    "print(\"\\n\" + \"â”€\" * 55)\n",
    "\n",
    "# Print rows\n",
    "print(\"Actual â†“\")\n",
    "for i, cat in enumerate(CATEGORIES):\n",
    "    print(f\"{cat:>15}\", end=\"\")\n",
    "    for j in range(len(CATEGORIES)):\n",
    "        print(f\"{cm[i][j]:>10}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "# ============================================================\n",
    "# Distribution Analysis\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"DISTRIBUTION ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "gt_dist = Counter(valid_ground_truths)\n",
    "pred_dist = Counter(valid_predictions)\n",
    "\n",
    "print(f\"\\n{'Category':<12} {'Ground Truth':>15} {'Predicted':>15} {'Difference':>12}\")\n",
    "print(\"â”€\" * 55)\n",
    "for cat in CATEGORIES:\n",
    "    gt_count = gt_dist.get(cat, 0)\n",
    "    pred_count = pred_dist.get(cat, 0)\n",
    "    diff = pred_count - gt_count\n",
    "    diff_str = f\"+{diff}\" if diff > 0 else str(diff)\n",
    "    print(f\"{cat:<12} {gt_count:>15} {pred_count:>15} {diff_str:>12}\")\n",
    "\n",
    "# ============================================================\n",
    "# Confidence Analysis\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"CONFIDENCE ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "confidence_counts = Counter()\n",
    "confidence_accuracy = {\"high\": [0, 0], \"medium\": [0, 0], \"low\": [0, 0]}  # [correct, total]\n",
    "\n",
    "for result in step3_results:\n",
    "    step3_output = result['step3_classification']\n",
    "    if 'confidence' in step3_output and 'classification' in step3_output:\n",
    "        conf = step3_output['confidence'].lower()\n",
    "        confidence_counts[conf] += 1\n",
    "        \n",
    "        is_correct = step3_output['classification'] == result['ground_truth_name']\n",
    "        confidence_accuracy[conf][1] += 1\n",
    "        if is_correct:\n",
    "            confidence_accuracy[conf][0] += 1\n",
    "\n",
    "print(f\"\\n{'Confidence':<12} {'Count':>10} {'Accuracy':>12}\")\n",
    "print(\"â”€\" * 35)\n",
    "for conf in [\"high\", \"medium\", \"low\"]:\n",
    "    count = confidence_counts.get(conf, 0)\n",
    "    if confidence_accuracy[conf][1] > 0:\n",
    "        acc = confidence_accuracy[conf][0] / confidence_accuracy[conf][1]\n",
    "        print(f\"{conf:<12} {count:>10} {acc:>11.1%}\")\n",
    "    else:\n",
    "        print(f\"{conf:<12} {count:>10} {'N/A':>12}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd390c4",
   "metadata": {},
   "source": [
    "## 2. Routing Design Pattern\n",
    "\n",
    "### What is Routing?\n",
    "\n",
    "**Routing** is an agentic workflow pattern where an intelligent router analyzes the input and directs it to the most appropriate specialized sub-agent for processing. Unlike prompt chaining where every input follows the same sequential path, routing allows different inputs to take different paths based on their characteristics.\n",
    "\n",
    "This pattern is particularly useful when:\n",
    "- Different inputs require fundamentally different expertise or processing approaches\n",
    "- Specialized agents can outperform a generalist for specific types of tasks\n",
    "- You want to optimize for speed by using lightweight agents for simple cases\n",
    "- The problem naturally decomposes into distinct domains\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Router (Orchestrator)**: Analyzes input and decides which sub-agent should handle it\n",
    "2. **Specialized Sub-Agents**: Domain experts that process the routed input\n",
    "3. **Output Aggregation**: Collecting results from whichever agent was selected\n",
    "\n",
    "### Advantages over Single-Agent Approaches\n",
    "\n",
    "| Aspect | Single Agent | Routing Pattern |\n",
    "|--------|--------------|-----------------|\n",
    "| **Specialization** | Jack of all trades | Domain experts |\n",
    "| **Prompt Size** | Large, covers everything | Focused, domain-specific |\n",
    "| **Latency** | One large call | Router + one specialized call |\n",
    "| **Scalability** | Modify one prompt | Add new specialized agents |\n",
    "| **Debugging** | Hard to isolate issues | Clear responsibility boundaries |\n",
    "\n",
    "---\n",
    "\n",
    "### Generic Routing Workflow Diagram\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                           ROUTING DESIGN PATTERN                            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                              â”Œâ”€â”€â”€â”€â–¶â”‚   SUB-AGENT A       â”‚â”€â”€â”€â”€â”\n",
    "                              â”‚     â”‚   (Specialist)      â”‚    â”‚\n",
    "                              â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "                              â”‚                                â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚          â”‚    â”‚         â”‚   â”‚     â”‚   SUB-AGENT B       â”‚    â”‚    â”‚          â”‚\n",
    "â”‚  INPUT   â”‚â”€â”€â”€â–¶â”‚ ROUTER  â”‚â”€â”€â”€â”¼â”€â”€â”€â”€â–¶â”‚   (Specialist)      â”‚â”€â”€â”€â”€â”¼â”€â”€â”€â–¶â”‚  OUTPUT  â”‚\n",
    "â”‚          â”‚    â”‚         â”‚   â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                                â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     â”‚        â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "                     â”‚        â””â”€â”€â”€â”€â–¶â”‚   SUB-AGENT C       â”‚â”€â”€â”€â”€â”˜\n",
    "                     â”‚              â”‚   (Specialist)      â”‚\n",
    "                     â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     â”‚\n",
    "                     â–¼\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚ Routing     â”‚\n",
    "              â”‚ Decision:   â”‚\n",
    "              â”‚ \"Which      â”‚\n",
    "              â”‚ agent?\"     â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Note:** Only ONE sub-agent is called per input (not all three).\n",
    "\n",
    "---\n",
    "\n",
    "### Routing vs. Prompt Chaining\n",
    "\n",
    "```\n",
    "PROMPT CHAINING (Sequential):\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Input â”‚â”€â”€â”€â–¶â”‚ Step 1  â”‚â”€â”€â”€â–¶â”‚ Step 2  â”‚â”€â”€â”€â–¶â”‚ Step 3  â”‚â”€â”€â”€â–¶â”‚ Output â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                 â”‚               â”‚               â”‚\n",
    "                 â–¼               â–¼               â–¼\n",
    "             All inputs follow the same path (3 LLM calls)\n",
    "\n",
    "\n",
    "ROUTING (Selective):\n",
    "                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                        â”Œâ”€â”€â”€â”€â–¶â”‚ Agent A â”‚â”€â”€â”€â”€â”\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Input â”‚â”€â”€â”€â–¶â”‚ Router â”‚â”€â”¼â”€â”€â”€â”€â–¶â”‚ Agent B â”‚â”€â”€â”€â”€â”¼â”€â”€â”€â”€â–¶â”‚ Output â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â””â”€â”€â”€â”€â–¶â”‚ Agent C â”‚â”€â”€â”€â”€â”˜\n",
    "                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                 â”‚\n",
    "                 â–¼\n",
    "         Each input takes ONE path (2 LLM calls: router + agent)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Common Routing Strategies\n",
    "\n",
    "1. **Domain-Based Routing**: Route based on subject matter expertise needed\n",
    "2. **Complexity-Based Routing**: Route simple vs. complex queries to different agents\n",
    "3. **Intent-Based Routing**: Route based on what the user wants to accomplish\n",
    "4. **Format-Based Routing**: Route based on input type (text, code, data, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "### Our Implementation: Domain Expertise Routing for AG News\n",
    "\n",
    "For our AG News classification task, we'll implement **domain-based routing** with 3 specialized agents:\n",
    "\n",
    "```\n",
    "                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                              â”Œâ”€â”€â”€â”€â–¶â”‚  ğŸ† SPORTS EXPERT       â”‚â”€â”€â”€â”€â”\n",
    "                              â”‚     â”‚  Teams, players,        â”‚    â”‚\n",
    "                              â”‚     â”‚  leagues, competitions  â”‚    â”‚\n",
    "                              â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "                              â”‚                                    â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              â”‚  â”‚        â”‚  â”‚     â”‚  ğŸ’¼ BUSINESS EXPERT     â”‚    â”‚  â”‚            â”‚\n",
    "â”‚  News        â”‚â”€â–¶â”‚ ROUTER â”‚â”€â”€â”¼â”€â”€â”€â”€â–¶â”‚  Markets, finance,      â”‚â”€â”€â”€â”€â”¼â”€â–¶â”‚ Category:  â”‚\n",
    "â”‚  Article     â”‚  â”‚        â”‚  â”‚     â”‚  corporate, economy     â”‚    â”‚  â”‚ World |    â”‚\n",
    "â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚ Sports |   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚      â”‚                                    â”‚  â”‚ Business | â”‚\n",
    "                       â”‚      â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚ Sci/Tech   â”‚\n",
    "                       â”‚      â””â”€â”€â”€â”€â–¶â”‚  ğŸ”¬ SCIENCE & WORLD     â”‚â”€â”€â”€â”€â”˜  â”‚            â”‚\n",
    "                       â”‚            â”‚  EXPERT                 â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                       â”‚            â”‚  Tech, research,        â”‚\n",
    "                       â”‚            â”‚  politics, diplomacy    â”‚\n",
    "                       â–¼            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                 â”‚ Analyzes â”‚\n",
    "                 â”‚ domain   â”‚\n",
    "                 â”‚ keywords â”‚\n",
    "                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Key Design Decision:** Each agent can output ANY of the 4 categories, not just their specialty. This prevents the router from pre-determining the classification.\n",
    "\n",
    "For example:\n",
    "- Sports Expert receives \"FIFA corruption scandal\" â†’ Outputs \"World\" (not Sports)\n",
    "- Business Expert receives \"Apple's new iPhone\" â†’ Outputs \"Sci/Tech\" (not Business)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd851501",
   "metadata": {},
   "source": [
    "### Router Agent\n",
    "\n",
    "**Model:** `gpt-5-mini` (OpenAI)\n",
    "\n",
    "**Role:** Analyze the news article and determine which domain expert should handle the classification.\n",
    "\n",
    "---\n",
    "\n",
    "#### System Prompt for Router\n",
    "\n",
    "```\n",
    "You are an intelligent routing system for news article classification.\n",
    "\n",
    "Your task is to analyze a news article and determine which domain expert should handle its classification. You must route to exactly ONE of these three experts:\n",
    "\n",
    "1. \"sports\" - Route here if the article primarily contains:\n",
    "   - Athletic events, games, matches, tournaments\n",
    "   - Sports teams, players, coaches, athletes\n",
    "   - Leagues, championships, scores, standings\n",
    "   - Sports business (trades, contracts, team ownership)\n",
    "\n",
    "2. \"business\" - Route here if the article primarily contains:\n",
    "   - Financial markets, stocks, trading, investments\n",
    "   - Companies, corporations, CEOs, executives\n",
    "   - Economy, GDP, inflation, employment\n",
    "   - Mergers, acquisitions, earnings, revenue\n",
    "\n",
    "3. \"science_world\" - Route here if the article primarily contains:\n",
    "   - Technology, software, hardware, internet\n",
    "   - Scientific research, discoveries, innovations\n",
    "   - International politics, diplomacy, conflicts\n",
    "   - Government policies, elections, world events\n",
    "\n",
    "Analyze the article and return your routing decision as a JSON object.\n",
    "\n",
    "Rules:\n",
    "- Choose the SINGLE most relevant expert based on the PRIMARY focus of the article\n",
    "- If the article spans multiple domains, choose based on the dominant theme\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"route_to\": \"sports\" | \"business\" | \"science_world\",\n",
    "    \"reasoning\": \"Brief explanation of why this expert was chosen\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Input & User Prompt Conversion\n",
    "\n",
    "**Input:** Raw news article text (same as prompt chaining Step 1)\n",
    "\n",
    "**User Prompt Format:**\n",
    "```\n",
    "Analyze the following news article and determine which domain expert should handle its classification:\n",
    "\n",
    "---\n",
    "[Article text from test_data]\n",
    "---\n",
    "```\n",
    "\n",
    "**Conversion Function:**\n",
    "```python\n",
    "def create_router_user_prompt(article_text: str) -> str:\n",
    "    return f\"\"\"Analyze the following news article and determine which domain expert should handle its classification:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Output Format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"route_to\": \"business\",\n",
    "    \"reasoning\": \"Article discusses stock market performance, Wall Street trading, and investor behavior - clear financial/business focus.\"\n",
    "}\n",
    "```\n",
    "\n",
    "The `route_to` field determines which sub-agent receives the article next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f611ea",
   "metadata": {},
   "source": [
    "### Sports Expert Agent ğŸ†\n",
    "\n",
    "**Model:** `claude-haiku-4-5-20251001` (Anthropic Claude Haiku 4.5)\n",
    "\n",
    "**Role:** Specialized agent with deep knowledge of sports, athletics, and competitive events. Classifies articles into one of the four categories.\n",
    "\n",
    "---\n",
    "\n",
    "#### System Prompt for Sports Expert\n",
    "\n",
    "```\n",
    "You are a SPORTS DOMAIN EXPERT specializing in athletics, competitive events, and sports-related news.\n",
    "\n",
    "You have deep knowledge of:\n",
    "- Major sports leagues (NFL, NBA, MLB, NHL, Premier League, La Liga, etc.)\n",
    "- Olympic sports and international competitions\n",
    "- Professional athletes, coaches, and team management\n",
    "- Sports statistics, records, and historical context\n",
    "- Sports business (contracts, trades, team ownership)\n",
    "\n",
    "Your task is to classify a news article into ONE of these four categories:\n",
    "- \"World\": International affairs, politics, government, diplomacy, conflicts\n",
    "- \"Sports\": Athletic events, teams, players, competitions, leagues\n",
    "- \"Business\": Companies, markets, economy, finance, corporate news\n",
    "- \"Sci/Tech\": Technology, science, software, research, innovation\n",
    "\n",
    "IMPORTANT: Even though you are a sports expert, you must objectively classify the article. \n",
    "- A sports corruption scandal might be \"World\" news (politics/crime)\n",
    "- A team's stock performance might be \"Business\" news\n",
    "- A sports technology innovation might be \"Sci/Tech\" news\n",
    "\n",
    "Return your classification as a JSON object.\n",
    "\n",
    "Rules:\n",
    "- Be objective - classify based on the article's PRIMARY focus\n",
    "- Use your sports expertise to understand context, but don't bias toward \"Sports\"\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"classification\": \"World\" | \"Sports\" | \"Business\" | \"Sci/Tech\",\n",
    "    \"confidence\": \"high\" | \"medium\" | \"low\",\n",
    "    \"justification\": \"Brief explanation of your classification decision\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Input & User Prompt Conversion\n",
    "\n",
    "**Input:** Raw news article text (received from Router)\n",
    "\n",
    "**User Prompt Format:**\n",
    "```\n",
    "As a sports domain expert, classify the following news article:\n",
    "\n",
    "---\n",
    "[Article text routed from Router]\n",
    "---\n",
    "```\n",
    "\n",
    "**Conversion Function:**\n",
    "```python\n",
    "def create_sports_agent_prompt(article_text: str) -> str:\n",
    "    return f\"\"\"As a sports domain expert, classify the following news article:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Output Format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"classification\": \"Sports\",\n",
    "    \"confidence\": \"high\",\n",
    "    \"justification\": \"Article covers NBA playoff game results between Lakers and Celtics, discussing player performances and game statistics.\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59aef5",
   "metadata": {},
   "source": [
    "### Business Expert Agent ğŸ’¼\n",
    "\n",
    "**Model:** `claude-sonnet-4-20250514` (Anthropic Claude Sonnet 4)\n",
    "\n",
    "**Role:** Specialized agent with deep knowledge of finance, markets, and corporate affairs. Classifies articles into one of the four categories.\n",
    "\n",
    "---\n",
    "\n",
    "#### System Prompt for Business Expert\n",
    "\n",
    "```\n",
    "You are a BUSINESS & FINANCE DOMAIN EXPERT specializing in markets, corporate affairs, and economic news.\n",
    "\n",
    "You have deep knowledge of:\n",
    "- Stock markets, trading, investments, and financial instruments\n",
    "- Major corporations, executives, and business leaders\n",
    "- Economic indicators (GDP, inflation, employment, interest rates)\n",
    "- Mergers & acquisitions, IPOs, and corporate restructuring\n",
    "- Industry sectors (tech, healthcare, energy, retail, etc.)\n",
    "- International trade and economic policy\n",
    "\n",
    "Your task is to classify a news article into ONE of these four categories:\n",
    "- \"World\": International affairs, politics, government, diplomacy, conflicts\n",
    "- \"Sports\": Athletic events, teams, players, competitions, leagues\n",
    "- \"Business\": Companies, markets, economy, finance, corporate news\n",
    "- \"Sci/Tech\": Technology, science, software, research, innovation\n",
    "\n",
    "IMPORTANT: Even though you are a business expert, you must objectively classify the article.\n",
    "- A tech company's product launch might be \"Sci/Tech\" news (technology focus)\n",
    "- Economic sanctions might be \"World\" news (international politics)\n",
    "- A sports team's financial troubles might be \"Sports\" news (sports focus)\n",
    "\n",
    "Return your classification as a JSON object.\n",
    "\n",
    "Rules:\n",
    "- Be objective - classify based on the article's PRIMARY focus\n",
    "- Use your business expertise to understand context, but don't bias toward \"Business\"\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"classification\": \"World\" | \"Sports\" | \"Business\" | \"Sci/Tech\",\n",
    "    \"confidence\": \"high\" | \"medium\" | \"low\",\n",
    "    \"justification\": \"Brief explanation of your classification decision\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Input & User Prompt Conversion\n",
    "\n",
    "**Input:** Raw news article text (received from Router)\n",
    "\n",
    "**User Prompt Format:**\n",
    "```\n",
    "As a business and finance domain expert, classify the following news article:\n",
    "\n",
    "---\n",
    "[Article text routed from Router]\n",
    "---\n",
    "```\n",
    "\n",
    "**Conversion Function:**\n",
    "```python\n",
    "def create_business_agent_prompt(article_text: str) -> str:\n",
    "    return f\"\"\"As a business and finance domain expert, classify the following news article:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Output Format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"classification\": \"Business\",\n",
    "    \"confidence\": \"high\",\n",
    "    \"justification\": \"Article discusses quarterly earnings report from major corporation, stock price movements, and analyst expectations - clear business/finance focus.\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4eb7b5",
   "metadata": {},
   "source": [
    "### Science & World Expert Agent ğŸ”¬ğŸŒ\n",
    "\n",
    "**Model:** `claude-sonnet-4-5-20250929` (Anthropic Claude Sonnet 4.5)\n",
    "\n",
    "**Role:** Specialized agent with deep knowledge of technology, science, and international affairs. Handles the combined Sci/Tech and World domains. Classifies articles into one of the four categories.\n",
    "\n",
    "---\n",
    "\n",
    "#### System Prompt for Science & World Expert\n",
    "\n",
    "```\n",
    "You are a SCIENCE, TECHNOLOGY & WORLD AFFAIRS EXPERT specializing in tech innovation, scientific research, and international news.\n",
    "\n",
    "You have deep knowledge of:\n",
    "\n",
    "SCIENCE & TECHNOLOGY:\n",
    "- Software, hardware, internet, and digital products\n",
    "- AI, machine learning, and emerging technologies\n",
    "- Scientific research, discoveries, and academic publications\n",
    "- Space exploration, biotechnology, and medical advances\n",
    "- Tech companies and their products (Apple, Google, Microsoft, etc.)\n",
    "\n",
    "WORLD AFFAIRS:\n",
    "- International politics and diplomacy\n",
    "- Government policies and elections\n",
    "- Military conflicts and peacekeeping\n",
    "- Humanitarian issues and global crises\n",
    "- International organizations (UN, NATO, EU, etc.)\n",
    "\n",
    "Your task is to classify a news article into ONE of these four categories:\n",
    "- \"World\": International affairs, politics, government, diplomacy, conflicts\n",
    "- \"Sports\": Athletic events, teams, players, competitions, leagues\n",
    "- \"Business\": Companies, markets, economy, finance, corporate news\n",
    "- \"Sci/Tech\": Technology, science, software, research, innovation\n",
    "\n",
    "IMPORTANT: You must carefully distinguish between:\n",
    "- \"Sci/Tech\": Focus on TECHNOLOGY or SCIENCE itself (products, research, innovation)\n",
    "- \"World\": Focus on POLITICS, DIPLOMACY, or INTERNATIONAL EVENTS\n",
    "- \"Business\": Focus on FINANCIAL aspects of tech/world (stock prices, revenue)\n",
    "\n",
    "Examples:\n",
    "- \"Apple releases new iPhone with AI features\" â†’ Sci/Tech (product/technology focus)\n",
    "- \"Apple's stock rises 5% after earnings\" â†’ Business (financial focus)\n",
    "- \"EU regulates Apple over antitrust concerns\" â†’ World (government/policy focus)\n",
    "\n",
    "Return your classification as a JSON object.\n",
    "\n",
    "Rules:\n",
    "- Be objective - classify based on the article's PRIMARY focus\n",
    "- Carefully distinguish between Sci/Tech vs World vs Business\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"classification\": \"World\" | \"Sports\" | \"Business\" | \"Sci/Tech\",\n",
    "    \"confidence\": \"high\" | \"medium\" | \"low\",\n",
    "    \"justification\": \"Brief explanation of your classification decision\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Input & User Prompt Conversion\n",
    "\n",
    "**Input:** Raw news article text (received from Router)\n",
    "\n",
    "**User Prompt Format:**\n",
    "```\n",
    "As a science, technology, and world affairs expert, classify the following news article:\n",
    "\n",
    "---\n",
    "[Article text routed from Router]\n",
    "---\n",
    "```\n",
    "\n",
    "**Conversion Function:**\n",
    "```python\n",
    "def create_science_world_agent_prompt(article_text: str) -> str:\n",
    "    return f\"\"\"As a science, technology, and world affairs expert, classify the following news article:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Output Format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"classification\": \"Sci/Tech\",\n",
    "    \"confidence\": \"high\",\n",
    "    \"justification\": \"Article focuses on a new software update and its technical features, including AI capabilities and performance improvements - clear technology focus.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Agent Summary Table\n",
    "\n",
    "| Agent | Model | Expertise | Handles |\n",
    "|-------|-------|-----------|---------|\n",
    "| **Router** | `gpt-5-mini` | Task routing | Determines which expert to use |\n",
    "| **Sports Expert** | `claude-haiku-4-5-20251001` | Athletics, competitions | Sports-related articles |\n",
    "| **Business Expert** | `claude-sonnet-4-20250514` | Finance, markets | Business-related articles |\n",
    "| **Sci/World Expert** | `claude-sonnet-4-5-20250929` | Tech, science, politics | Sci/Tech & World articles |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aea6510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ROUTING DESIGN PATTERN - Classification\n",
      "======================================================================\n",
      "\n",
      "Processing 100 samples using Router + Specialized Experts...\n",
      "\n",
      "  âœ“ Processed 10/100 articles (10.0%)\n",
      "  âœ“ Processed 20/100 articles (20.0%)\n",
      "  âœ“ Processed 30/100 articles (30.0%)\n",
      "  âœ“ Processed 40/100 articles (40.0%)\n",
      "  âœ“ Processed 50/100 articles (50.0%)\n",
      "  âœ“ Processed 60/100 articles (60.0%)\n",
      "  âœ“ Processed 70/100 articles (70.0%)\n",
      "  âœ“ Processed 80/100 articles (80.0%)\n",
      "  âœ“ Processed 90/100 articles (90.0%)\n",
      "  âœ“ Processed 100/100 articles (100.0%)\n",
      "\n",
      "======================================================================\n",
      "ROUTING RESULTS (showing first 3 of 100)\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 1\n",
      "Ground Truth: Business\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“ Routing Decision:\n",
      "   Route to: business\n",
      "   Reasoning: Article concerns corporate/financial issues â€” unions negotiating over Turner Newall pensions with its parent firm Federal Mogul â€” which falls under company/employee/financial matters.\n",
      "   Expert Used: business_expert\n",
      "\n",
      "ğŸ“‹ Classification Result:\n",
      "   Classification: Business\n",
      "   Confidence: high\n",
      "   Justification: This article focuses on corporate pension issues involving Turner Newall and its parent company Federal Mogul, along with union negotiations. The primary concern is employee pension security in the context of corporate financial distress, which is fundamentally a business and finance matter.\n",
      "\n",
      "   Result: âœ“ CORRECT\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 2\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“ Routing Decision:\n",
      "   Route to: science_world\n",
      "   Reasoning: The article is about private human spaceflight, the Ansari X Prize and a manned rocket launch dateâ€”topics relating to space technology and scientific/technical developments.\n",
      "   Expert Used: science_world_expert\n",
      "\n",
      "ğŸ“‹ Classification Result:\n",
      "   Classification: Sci/Tech\n",
      "   Confidence: high\n",
      "   Justification: This article's primary focus is on technological innovation in space exploration - specifically, a private team's manned rocket launch for the Ansari X Prize competition. While it mentions a financial prize, the core content is about spaceflight technology, rocket engineering, and space exploration advancement, which are quintessential Sci/Tech topics. This is about the technological achievement and scientific endeavor itself, not about government/international space policy (World) or the business/financial aspects of the companies involved (Business).\n",
      "\n",
      "   Result: âœ“ CORRECT\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 3\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“ Routing Decision:\n",
      "   Route to: science_world\n",
      "   Reasoning: The article focuses on scientific research and innovationâ€”development of methods to produce peptidesâ€”and funding for that research, fitting the science/technology domain rather than sports or general business.\n",
      "   Expert Used: science_world_expert\n",
      "\n",
      "ğŸ“‹ Classification Result:\n",
      "   Classification: Sci/Tech\n",
      "   Confidence: high\n",
      "   Justification: This article focuses on scientific research and development of a biochemical method for producing peptides. The primary subject is the scientific/technical work itself (peptide production methodology) rather than business aspects (grant amount, company valuation) or world affairs (government policy). While it mentions a grant award, the core content is about advancing scientific capability in biochemistry and protein research.\n",
      "\n",
      "   Result: âœ“ CORRECT\n",
      "\n",
      "======================================================================\n",
      "Routing complete. 100 results stored in 'routing_results'\n",
      "Ready for evaluation.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ROUTING DESIGN PATTERN IMPLEMENTATION\n",
    "# ============================================================\n",
    "\n",
    "# Helper function to clean JSON from markdown code blocks\n",
    "def clean_json_response(response_text: str) -> str:\n",
    "    \"\"\"Strip markdown code blocks from LLM response if present.\"\"\"\n",
    "    cleaned = response_text.strip()\n",
    "    if cleaned.startswith(\"```\"):\n",
    "        lines = cleaned.split(\"\\n\")\n",
    "        lines = lines[1:]  # Remove opening ```json or ```\n",
    "        if lines and lines[-1].strip() == \"```\":\n",
    "            lines = lines[:-1]  # Remove closing ```\n",
    "        cleaned = \"\\n\".join(lines)\n",
    "    return cleaned\n",
    "\n",
    "# ============================================================\n",
    "# ROUTER AGENT (GPT-5-mini)\n",
    "# ============================================================\n",
    "\n",
    "ROUTER_SYSTEM_PROMPT = \"\"\"You are an intelligent routing system for news article classification.\n",
    "\n",
    "Your task is to analyze a news article and determine which domain expert should handle its classification. You must route to exactly ONE of these three experts:\n",
    "\n",
    "1. \"sports\" - Route here if the article primarily contains:\n",
    "   - Athletic events, games, matches, tournaments\n",
    "   - Sports teams, players, coaches, athletes\n",
    "   - Leagues, championships, scores, standings\n",
    "   - Sports business (trades, contracts, team ownership)\n",
    "\n",
    "2. \"business\" - Route here if the article primarily contains:\n",
    "   - Financial markets, stocks, trading, investments\n",
    "   - Companies, corporations, CEOs, executives\n",
    "   - Economy, GDP, inflation, employment\n",
    "   - Mergers, acquisitions, earnings, revenue\n",
    "\n",
    "3. \"science_world\" - Route here if the article primarily contains:\n",
    "   - Technology, software, hardware, internet\n",
    "   - Scientific research, discoveries, innovations\n",
    "   - International politics, diplomacy, conflicts\n",
    "   - Government policies, elections, world events\n",
    "\n",
    "Analyze the article and return your routing decision as a JSON object.\n",
    "\n",
    "Rules:\n",
    "- Choose the SINGLE most relevant expert based on the PRIMARY focus of the article\n",
    "- If the article spans multiple domains, choose based on the dominant theme\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"route_to\": \"sports\" | \"business\" | \"science_world\",\n",
    "    \"reasoning\": \"Brief explanation of why this expert was chosen\"\n",
    "}\"\"\"\n",
    "\n",
    "def create_router_prompt(article_text: str) -> str:\n",
    "    return f\"\"\"Analyze the following news article and determine which domain expert should handle its classification:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "\n",
    "def run_router(article_text: str) -> dict:\n",
    "    \"\"\"Route article to appropriate expert using GPT-5-mini.\"\"\"\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        max_completion_tokens=512,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": ROUTER_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": create_router_prompt(article_text)}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    response_text = response.choices[0].message.content\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Failed to parse JSON\", \"raw_response\": response_text, \"route_to\": \"science_world\"}\n",
    "\n",
    "# ============================================================\n",
    "# SPORTS EXPERT AGENT (Claude Haiku 4.5)\n",
    "# ============================================================\n",
    "\n",
    "SPORTS_EXPERT_SYSTEM_PROMPT = \"\"\"You are a SPORTS DOMAIN EXPERT specializing in athletics, competitive events, and sports-related news.\n",
    "\n",
    "You have deep knowledge of:\n",
    "- Major sports leagues (NFL, NBA, MLB, NHL, Premier League, La Liga, etc.)\n",
    "- Olympic sports and international competitions\n",
    "- Professional athletes, coaches, and team management\n",
    "- Sports statistics, records, and historical context\n",
    "- Sports business (contracts, trades, team ownership)\n",
    "\n",
    "Your task is to classify a news article into ONE of these four categories:\n",
    "- \"World\": International affairs, politics, government, diplomacy, conflicts\n",
    "- \"Sports\": Athletic events, teams, players, competitions, leagues\n",
    "- \"Business\": Companies, markets, economy, finance, corporate news\n",
    "- \"Sci/Tech\": Technology, science, software, research, innovation\n",
    "\n",
    "IMPORTANT: Even though you are a sports expert, you must objectively classify the article. \n",
    "- A sports corruption scandal might be \"World\" news (politics/crime)\n",
    "- A team's stock performance might be \"Business\" news\n",
    "- A sports technology innovation might be \"Sci/Tech\" news\n",
    "\n",
    "Return your classification as a JSON object.\n",
    "\n",
    "Rules:\n",
    "- Be objective - classify based on the article's PRIMARY focus\n",
    "- Use your sports expertise to understand context, but don't bias toward \"Sports\"\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"classification\": \"World\" | \"Sports\" | \"Business\" | \"Sci/Tech\",\n",
    "    \"confidence\": \"high\" | \"medium\" | \"low\",\n",
    "    \"justification\": \"Brief explanation of your classification decision\"\n",
    "}\"\"\"\n",
    "\n",
    "def create_sports_agent_prompt(article_text: str) -> str:\n",
    "    return f\"\"\"As a sports domain expert, classify the following news article:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "\n",
    "def run_sports_expert(article_text: str) -> dict:\n",
    "    \"\"\"Classify article using Sports Expert (Claude Haiku 4.5).\"\"\"\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        max_tokens=1024,\n",
    "        system=SPORTS_EXPERT_SYSTEM_PROMPT,\n",
    "        messages=[{\"role\": \"user\", \"content\": create_sports_agent_prompt(article_text)}]\n",
    "    )\n",
    "    \n",
    "    response_text = response.content[0].text\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Failed to parse JSON\", \"raw_response\": response_text}\n",
    "\n",
    "# ============================================================\n",
    "# BUSINESS EXPERT AGENT (Claude Sonnet 4)\n",
    "# ============================================================\n",
    "\n",
    "BUSINESS_EXPERT_SYSTEM_PROMPT = \"\"\"You are a BUSINESS & FINANCE DOMAIN EXPERT specializing in markets, corporate affairs, and economic news.\n",
    "\n",
    "You have deep knowledge of:\n",
    "- Stock markets, trading, investments, and financial instruments\n",
    "- Major corporations, executives, and business leaders\n",
    "- Economic indicators (GDP, inflation, employment, interest rates)\n",
    "- Mergers & acquisitions, IPOs, and corporate restructuring\n",
    "- Industry sectors (tech, healthcare, energy, retail, etc.)\n",
    "- International trade and economic policy\n",
    "\n",
    "Your task is to classify a news article into ONE of these four categories:\n",
    "- \"World\": International affairs, politics, government, diplomacy, conflicts\n",
    "- \"Sports\": Athletic events, teams, players, competitions, leagues\n",
    "- \"Business\": Companies, markets, economy, finance, corporate news\n",
    "- \"Sci/Tech\": Technology, science, software, research, innovation\n",
    "\n",
    "IMPORTANT: Even though you are a business expert, you must objectively classify the article.\n",
    "- A tech company's product launch might be \"Sci/Tech\" news (technology focus)\n",
    "- Economic sanctions might be \"World\" news (international politics)\n",
    "- A sports team's financial troubles might be \"Sports\" news (sports focus)\n",
    "\n",
    "Return your classification as a JSON object.\n",
    "\n",
    "Rules:\n",
    "- Be objective - classify based on the article's PRIMARY focus\n",
    "- Use your business expertise to understand context, but don't bias toward \"Business\"\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"classification\": \"World\" | \"Sports\" | \"Business\" | \"Sci/Tech\",\n",
    "    \"confidence\": \"high\" | \"medium\" | \"low\",\n",
    "    \"justification\": \"Brief explanation of your classification decision\"\n",
    "}\"\"\"\n",
    "\n",
    "def create_business_agent_prompt(article_text: str) -> str:\n",
    "    return f\"\"\"As a business and finance domain expert, classify the following news article:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "\n",
    "def run_business_expert(article_text: str) -> dict:\n",
    "    \"\"\"Classify article using Business Expert (Claude Sonnet 4).\"\"\"\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=1024,\n",
    "        system=BUSINESS_EXPERT_SYSTEM_PROMPT,\n",
    "        messages=[{\"role\": \"user\", \"content\": create_business_agent_prompt(article_text)}]\n",
    "    )\n",
    "    \n",
    "    response_text = response.content[0].text\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Failed to parse JSON\", \"raw_response\": response_text}\n",
    "\n",
    "# ============================================================\n",
    "# SCIENCE & WORLD EXPERT AGENT (Claude Sonnet 4.5)\n",
    "# ============================================================\n",
    "\n",
    "SCIENCE_WORLD_EXPERT_SYSTEM_PROMPT = \"\"\"You are a SCIENCE, TECHNOLOGY & WORLD AFFAIRS EXPERT specializing in tech innovation, scientific research, and international news.\n",
    "\n",
    "You have deep knowledge of:\n",
    "\n",
    "SCIENCE & TECHNOLOGY:\n",
    "- Software, hardware, internet, and digital products\n",
    "- AI, machine learning, and emerging technologies\n",
    "- Scientific research, discoveries, and academic publications\n",
    "- Space exploration, biotechnology, and medical advances\n",
    "- Tech companies and their products (Apple, Google, Microsoft, etc.)\n",
    "\n",
    "WORLD AFFAIRS:\n",
    "- International politics and diplomacy\n",
    "- Government policies and elections\n",
    "- Military conflicts and peacekeeping\n",
    "- Humanitarian issues and global crises\n",
    "- International organizations (UN, NATO, EU, etc.)\n",
    "\n",
    "Your task is to classify a news article into ONE of these four categories:\n",
    "- \"World\": International affairs, politics, government, diplomacy, conflicts\n",
    "- \"Sports\": Athletic events, teams, players, competitions, leagues\n",
    "- \"Business\": Companies, markets, economy, finance, corporate news\n",
    "- \"Sci/Tech\": Technology, science, software, research, innovation\n",
    "\n",
    "IMPORTANT: You must carefully distinguish between:\n",
    "- \"Sci/Tech\": Focus on TECHNOLOGY or SCIENCE itself (products, research, innovation)\n",
    "- \"World\": Focus on POLITICS, DIPLOMACY, or INTERNATIONAL EVENTS\n",
    "- \"Business\": Focus on FINANCIAL aspects of tech/world (stock prices, revenue)\n",
    "\n",
    "Examples:\n",
    "- \"Apple releases new iPhone with AI features\" â†’ Sci/Tech (product/technology focus)\n",
    "- \"Apple's stock rises 5% after earnings\" â†’ Business (financial focus)\n",
    "- \"EU regulates Apple over antitrust concerns\" â†’ World (government/policy focus)\n",
    "\n",
    "Return your classification as a JSON object.\n",
    "\n",
    "Rules:\n",
    "- Be objective - classify based on the article's PRIMARY focus\n",
    "- Carefully distinguish between Sci/Tech vs World vs Business\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"classification\": \"World\" | \"Sports\" | \"Business\" | \"Sci/Tech\",\n",
    "    \"confidence\": \"high\" | \"medium\" | \"low\",\n",
    "    \"justification\": \"Brief explanation of your classification decision\"\n",
    "}\"\"\"\n",
    "\n",
    "def create_science_world_agent_prompt(article_text: str) -> str:\n",
    "    return f\"\"\"As a science, technology, and world affairs expert, classify the following news article:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "\n",
    "def run_science_world_expert(article_text: str) -> dict:\n",
    "    \"\"\"Classify article using Science & World Expert (Claude Sonnet 4.5).\"\"\"\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-sonnet-4-5-20250929\",\n",
    "        max_tokens=1024,\n",
    "        system=SCIENCE_WORLD_EXPERT_SYSTEM_PROMPT,\n",
    "        messages=[{\"role\": \"user\", \"content\": create_science_world_agent_prompt(article_text)}]\n",
    "    )\n",
    "    \n",
    "    response_text = response.content[0].text\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Failed to parse JSON\", \"raw_response\": response_text}\n",
    "\n",
    "# ============================================================\n",
    "# ROUTING ORCHESTRATOR\n",
    "# ============================================================\n",
    "\n",
    "def route_and_classify(article_text: str) -> dict:\n",
    "    \"\"\"Main orchestrator: Route article to expert and get classification.\"\"\"\n",
    "    \n",
    "    # Step 1: Router decides which expert to use\n",
    "    routing_decision = run_router(article_text)\n",
    "    route_to = routing_decision.get(\"route_to\", \"science_world\")\n",
    "    \n",
    "    # Step 2: Call the appropriate expert\n",
    "    if route_to == \"sports\":\n",
    "        expert_result = run_sports_expert(article_text)\n",
    "        expert_used = \"sports_expert\"\n",
    "    elif route_to == \"business\":\n",
    "        expert_result = run_business_expert(article_text)\n",
    "        expert_used = \"business_expert\"\n",
    "    else:  # science_world or fallback\n",
    "        expert_result = run_science_world_expert(article_text)\n",
    "        expert_used = \"science_world_expert\"\n",
    "    \n",
    "    return {\n",
    "        \"routing_decision\": routing_decision,\n",
    "        \"expert_used\": expert_used,\n",
    "        \"classification_result\": expert_result\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# PROCESS ALL TEST DATA\n",
    "# ============================================================\n",
    "\n",
    "# Use the same test data as prompt chaining (100 samples)\n",
    "routing_results = []\n",
    "\n",
    "# Number of results to print\n",
    "NUM_TO_PRINT = 3\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ROUTING DESIGN PATTERN - Classification\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nProcessing {NUM_SAMPLES} samples using Router + Specialized Experts...\\n\")\n",
    "\n",
    "# Progress tracking\n",
    "PROGRESS_INTERVAL = 10\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample = test_data[i]\n",
    "    article_text = sample['text']\n",
    "    ground_truth_label = sample['label']\n",
    "    \n",
    "    # Run the routing pipeline\n",
    "    result = route_and_classify(article_text)\n",
    "    \n",
    "    # Store result with metadata\n",
    "    routing_results.append({\n",
    "        \"index\": i,\n",
    "        \"original_text\": article_text,\n",
    "        \"ground_truth_label\": ground_truth_label,\n",
    "        \"ground_truth_name\": label_names[ground_truth_label],\n",
    "        \"routing_decision\": result[\"routing_decision\"],\n",
    "        \"expert_used\": result[\"expert_used\"],\n",
    "        \"classification_result\": result[\"classification_result\"]\n",
    "    })\n",
    "    \n",
    "    # Print progress\n",
    "    if (i + 1) % PROGRESS_INTERVAL == 0 or (i + 1) == NUM_SAMPLES:\n",
    "        print(f\"  âœ“ Processed {i + 1}/{NUM_SAMPLES} articles ({(i + 1) / NUM_SAMPLES * 100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"ROUTING RESULTS (showing first {NUM_TO_PRINT} of {len(routing_results)})\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Display results\n",
    "for result in routing_results[:NUM_TO_PRINT]:\n",
    "    print(f\"\\n{'â”€' * 70}\")\n",
    "    print(f\"Article {result['index'] + 1}\")\n",
    "    print(f\"Ground Truth: {result['ground_truth_name']}\")\n",
    "    print(f\"{'â”€' * 70}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ Routing Decision:\")\n",
    "    print(f\"   Route to: {result['routing_decision'].get('route_to', 'N/A')}\")\n",
    "    print(f\"   Reasoning: {result['routing_decision'].get('reasoning', 'N/A')}\")\n",
    "    print(f\"   Expert Used: {result['expert_used']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Classification Result:\")\n",
    "    classification = result['classification_result']\n",
    "    print(f\"   Classification: {classification.get('classification', 'N/A')}\")\n",
    "    print(f\"   Confidence: {classification.get('confidence', 'N/A')}\")\n",
    "    print(f\"   Justification: {classification.get('justification', 'N/A')}\")\n",
    "    \n",
    "    # Quick comparison\n",
    "    predicted = classification.get('classification', 'N/A')\n",
    "    actual = result['ground_truth_name']\n",
    "    match = \"âœ“ CORRECT\" if predicted == actual else \"âœ— INCORRECT\"\n",
    "    print(f\"\\n   Result: {match}\")\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Routing complete. {len(routing_results)} results stored in 'routing_results'\")\n",
    "print(f\"Ready for evaluation.\")\n",
    "print(f\"{'=' * 70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65dd7e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ROUTING DESIGN PATTERN - EVALUATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "OVERALL METRICS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Total Samples:     100\n",
      "  Valid Predictions: 100\n",
      "  Error Rate:        0.0%\n",
      "\n",
      "  ğŸ“Š Accuracy:        0.8200  (82.0%)\n",
      "\n",
      "  Macro Averages (treats all classes equally):\n",
      "     Precision:      0.8085\n",
      "     Recall:         0.8441\n",
      "     F1 Score:       0.8057\n",
      "\n",
      "  Weighted Averages (accounts for class imbalance):\n",
      "     Precision:      0.8666\n",
      "     Recall:         0.8200\n",
      "     F1 Score:       0.8282\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "PER-CLASS METRICS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.87      0.90      0.89        30\n",
      "      Sports       0.90      0.86      0.88        21\n",
      "    Business       0.50      0.92      0.65        12\n",
      "    Sci/Tech       0.96      0.70      0.81        37\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.81      0.84      0.81       100\n",
      "weighted avg       0.87      0.82      0.83       100\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CONFUSION MATRIX\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Predicted â†’     World    Sports  Business  Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Actual â†“\n",
      "          World        27         2         1         0\n",
      "         Sports         3        18         0         0\n",
      "       Business         0         0        11         1\n",
      "       Sci/Tech         1         0        10        26\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DISTRIBUTION ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Category        Ground Truth       Predicted   Difference\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "World                     30              31           +1\n",
      "Sports                    21              20           -1\n",
      "Business                  12              22          +10\n",
      "Sci/Tech                  37              27          -10\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ROUTING ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Expert Usage Distribution:\n",
      "  Expert                         Count   Percentage\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  sports_expert                     23        23.0%\n",
      "  business_expert                   22        22.0%\n",
      "  science_world_expert              55        55.0%\n",
      "\n",
      "  Router Decisions:\n",
      "  Route To                       Count   Percentage\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  sports                            23        23.0%\n",
      "  business                          22        22.0%\n",
      "  science_world                     55        55.0%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "PER-EXPERT ACCURACY\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Expert                       Correct      Total     Accuracy\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  sports_expert                     18         23       78.3%\n",
      "  business_expert                   11         22       50.0%\n",
      "  science_world_expert              53         55       96.4%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CONFIDENCE ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Confidence        Count     Accuracy\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "high                 99       81.8%\n",
      "medium                1      100.0%\n",
      "low                   0          N/A\n",
      "\n",
      "======================================================================\n",
      "ROUTING PATTERN EVALUATION COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EVALUATION: Routing Design Pattern Performance\n",
    "# ============================================================\n",
    "\n",
    "# Extract predictions and ground truth from routing results\n",
    "routing_predictions = []\n",
    "routing_ground_truths = []\n",
    "routing_errors = []\n",
    "\n",
    "for result in routing_results:\n",
    "    ground_truth = result['ground_truth_name']\n",
    "    routing_ground_truths.append(ground_truth)\n",
    "    \n",
    "    # Get prediction from classification_result\n",
    "    classification_output = result['classification_result']\n",
    "    \n",
    "    if 'classification' in classification_output:\n",
    "        predicted = classification_output['classification']\n",
    "        routing_predictions.append(predicted)\n",
    "    else:\n",
    "        # Handle parsing errors\n",
    "        routing_predictions.append(\"ERROR\")\n",
    "        routing_errors.append(result['index'])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ROUTING DESIGN PATTERN - EVALUATION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for errors\n",
    "if routing_errors:\n",
    "    print(f\"\\nâš ï¸  Warning: {len(routing_errors)} samples had parsing errors (indices: {routing_errors[:10]}{'...' if len(routing_errors) > 10 else ''})\")\n",
    "    print(f\"   These are excluded from metrics calculation.\\n\")\n",
    "    \n",
    "    # Filter out errors\n",
    "    valid_routing_predictions = [p for p in routing_predictions if p != \"ERROR\"]\n",
    "    valid_routing_ground_truths = [g for p, g in zip(routing_predictions, routing_ground_truths) if p != \"ERROR\"]\n",
    "else:\n",
    "    valid_routing_predictions = routing_predictions\n",
    "    valid_routing_ground_truths = routing_ground_truths\n",
    "\n",
    "# ============================================================\n",
    "# Basic Metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"OVERALL METRICS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "routing_accuracy = accuracy_score(valid_routing_ground_truths, valid_routing_predictions)\n",
    "routing_precision_macro = precision_score(valid_routing_ground_truths, valid_routing_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "routing_recall_macro = recall_score(valid_routing_ground_truths, valid_routing_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "routing_f1_macro = f1_score(valid_routing_ground_truths, valid_routing_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "\n",
    "routing_precision_weighted = precision_score(valid_routing_ground_truths, valid_routing_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "routing_recall_weighted = recall_score(valid_routing_ground_truths, valid_routing_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "routing_f1_weighted = f1_score(valid_routing_ground_truths, valid_routing_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\n  Total Samples:     {len(routing_results)}\")\n",
    "print(f\"  Valid Predictions: {len(valid_routing_predictions)}\")\n",
    "print(f\"  Error Rate:        {len(routing_errors) / len(routing_results) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n  ğŸ“Š Accuracy:        {routing_accuracy:.4f}  ({routing_accuracy * 100:.1f}%)\")\n",
    "print(f\"\\n  Macro Averages (treats all classes equally):\")\n",
    "print(f\"     Precision:      {routing_precision_macro:.4f}\")\n",
    "print(f\"     Recall:         {routing_recall_macro:.4f}\")\n",
    "print(f\"     F1 Score:       {routing_f1_macro:.4f}\")\n",
    "\n",
    "print(f\"\\n  Weighted Averages (accounts for class imbalance):\")\n",
    "print(f\"     Precision:      {routing_precision_weighted:.4f}\")\n",
    "print(f\"     Recall:         {routing_recall_weighted:.4f}\")\n",
    "print(f\"     F1 Score:       {routing_f1_weighted:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Per-Class Metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"PER-CLASS METRICS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "print(\"\\n\" + classification_report(valid_routing_ground_truths, valid_routing_predictions, labels=CATEGORIES, zero_division=0))\n",
    "\n",
    "# ============================================================\n",
    "# Confusion Matrix\n",
    "# ============================================================\n",
    "\n",
    "print(\"â”€\" * 70)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "routing_cm = confusion_matrix(valid_routing_ground_truths, valid_routing_predictions, labels=CATEGORIES)\n",
    "\n",
    "print(f\"\\n{'Predicted â†’':>15}\", end=\"\")\n",
    "for cat in CATEGORIES:\n",
    "    print(f\"{cat:>10}\", end=\"\")\n",
    "print(\"\\n\" + \"â”€\" * 55)\n",
    "\n",
    "print(\"Actual â†“\")\n",
    "for i, cat in enumerate(CATEGORIES):\n",
    "    print(f\"{cat:>15}\", end=\"\")\n",
    "    for j in range(len(CATEGORIES)):\n",
    "        print(f\"{routing_cm[i][j]:>10}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "# ============================================================\n",
    "# Distribution Analysis\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"DISTRIBUTION ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "routing_gt_dist = Counter(valid_routing_ground_truths)\n",
    "routing_pred_dist = Counter(valid_routing_predictions)\n",
    "\n",
    "print(f\"\\n{'Category':<12} {'Ground Truth':>15} {'Predicted':>15} {'Difference':>12}\")\n",
    "print(\"â”€\" * 55)\n",
    "for cat in CATEGORIES:\n",
    "    gt_count = routing_gt_dist.get(cat, 0)\n",
    "    pred_count = routing_pred_dist.get(cat, 0)\n",
    "    diff = pred_count - gt_count\n",
    "    diff_str = f\"+{diff}\" if diff > 0 else str(diff)\n",
    "    print(f\"{cat:<12} {gt_count:>15} {pred_count:>15} {diff_str:>12}\")\n",
    "\n",
    "# ============================================================\n",
    "# Routing Analysis (Unique to Routing Pattern)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"ROUTING ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Count how many times each expert was used\n",
    "expert_usage = Counter()\n",
    "route_decisions = Counter()\n",
    "\n",
    "for result in routing_results:\n",
    "    expert_usage[result['expert_used']] += 1\n",
    "    route_to = result['routing_decision'].get('route_to', 'unknown')\n",
    "    route_decisions[route_to] += 1\n",
    "\n",
    "print(f\"\\n  Expert Usage Distribution:\")\n",
    "print(f\"  {'Expert':<25} {'Count':>10} {'Percentage':>12}\")\n",
    "print(\"  \" + \"â”€\" * 47)\n",
    "for expert in ['sports_expert', 'business_expert', 'science_world_expert']:\n",
    "    count = expert_usage.get(expert, 0)\n",
    "    pct = count / len(routing_results) * 100\n",
    "    print(f\"  {expert:<25} {count:>10} {pct:>11.1f}%\")\n",
    "\n",
    "print(f\"\\n  Router Decisions:\")\n",
    "print(f\"  {'Route To':<25} {'Count':>10} {'Percentage':>12}\")\n",
    "print(\"  \" + \"â”€\" * 47)\n",
    "for route in ['sports', 'business', 'science_world']:\n",
    "    count = route_decisions.get(route, 0)\n",
    "    pct = count / len(routing_results) * 100\n",
    "    print(f\"  {route:<25} {count:>10} {pct:>11.1f}%\")\n",
    "\n",
    "# ============================================================\n",
    "# Per-Expert Accuracy\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"PER-EXPERT ACCURACY\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "expert_accuracy = {}\n",
    "for expert in ['sports_expert', 'business_expert', 'science_world_expert']:\n",
    "    expert_correct = 0\n",
    "    expert_total = 0\n",
    "    for result in routing_results:\n",
    "        if result['expert_used'] == expert:\n",
    "            expert_total += 1\n",
    "            predicted = result['classification_result'].get('classification', 'N/A')\n",
    "            actual = result['ground_truth_name']\n",
    "            if predicted == actual:\n",
    "                expert_correct += 1\n",
    "    if expert_total > 0:\n",
    "        expert_accuracy[expert] = expert_correct / expert_total\n",
    "    else:\n",
    "        expert_accuracy[expert] = 0\n",
    "\n",
    "print(f\"\\n  {'Expert':<25} {'Correct':>10} {'Total':>10} {'Accuracy':>12}\")\n",
    "print(\"  \" + \"â”€\" * 57)\n",
    "for expert in ['sports_expert', 'business_expert', 'science_world_expert']:\n",
    "    correct = sum(1 for r in routing_results if r['expert_used'] == expert and r['classification_result'].get('classification') == r['ground_truth_name'])\n",
    "    total = expert_usage.get(expert, 0)\n",
    "    acc = expert_accuracy.get(expert, 0)\n",
    "    print(f\"  {expert:<25} {correct:>10} {total:>10} {acc:>11.1%}\")\n",
    "\n",
    "# ============================================================\n",
    "# Confidence Analysis\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"CONFIDENCE ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "routing_confidence_counts = Counter()\n",
    "routing_confidence_accuracy = {\"high\": [0, 0], \"medium\": [0, 0], \"low\": [0, 0]}\n",
    "\n",
    "for result in routing_results:\n",
    "    classification_output = result['classification_result']\n",
    "    if 'confidence' in classification_output and 'classification' in classification_output:\n",
    "        conf = classification_output['confidence'].lower()\n",
    "        routing_confidence_counts[conf] += 1\n",
    "        \n",
    "        is_correct = classification_output['classification'] == result['ground_truth_name']\n",
    "        routing_confidence_accuracy[conf][1] += 1\n",
    "        if is_correct:\n",
    "            routing_confidence_accuracy[conf][0] += 1\n",
    "\n",
    "print(f\"\\n{'Confidence':<12} {'Count':>10} {'Accuracy':>12}\")\n",
    "print(\"â”€\" * 35)\n",
    "for conf in [\"high\", \"medium\", \"low\"]:\n",
    "    count = routing_confidence_counts.get(conf, 0)\n",
    "    if routing_confidence_accuracy[conf][1] > 0:\n",
    "        acc = routing_confidence_accuracy[conf][0] / routing_confidence_accuracy[conf][1]\n",
    "        print(f\"{conf:<12} {count:>10} {acc:>11.1%}\")\n",
    "    else:\n",
    "        print(f\"{conf:<12} {count:>10} {'N/A':>12}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ROUTING PATTERN EVALUATION COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76358303",
   "metadata": {},
   "source": [
    "## 3. Parallelization Design Pattern\n",
    "\n",
    "### What is Parallelization?\n",
    "\n",
    "**Parallelization** is an agentic workflow pattern where multiple LLM agents work on the same input simultaneously, and their results are combined by an aggregator. Unlike prompt chaining (sequential) or routing (selective), parallelization leverages concurrency to reduce latency and gather multiple perspectives.\n",
    "\n",
    "This pattern is particularly useful when:\n",
    "- Multiple independent analyses can be performed on the same input\n",
    "- Speed is critical and you want to minimize total latency\n",
    "- You want diverse perspectives or ensemble-style decisions\n",
    "- The aggregation logic can be implemented in code (no LLM needed)\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Coordinator (Code)**: Dispatches the input to multiple agents simultaneously\n",
    "2. **Parallel Agents (LLMs)**: Each performs its task independently and concurrently\n",
    "3. **Aggregator (Code)**: Combines results from all agents into a final output\n",
    "\n",
    "### Advantages of Parallelization\n",
    "\n",
    "| Aspect | Benefit |\n",
    "|--------|---------|\n",
    "| **Speed** | All agents run concurrently â†’ total time â‰ˆ slowest agent |\n",
    "| **Diversity** | Multiple perspectives on the same input |\n",
    "| **Robustness** | One agent's error can be compensated by others |\n",
    "| **Scalability** | Easy to add more parallel agents |\n",
    "| **Deterministic Aggregation** | Code-based combining is consistent and fast |\n",
    "\n",
    "---\n",
    "\n",
    "### Generic Parallelization Workflow Diagram\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                       PARALLELIZATION DESIGN PATTERN                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                        â”Œâ”€â”€â”€â”€â–¶â”‚    AGENT A        â”‚â”€â”€â”€â”€â”\n",
    "                        â”‚     â”‚    (LLM)          â”‚    â”‚\n",
    "                        â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "                        â”‚                              â”‚\n",
    "                        â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚     â”‚    AGENT B        â”‚    â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              â”‚        â”œâ”€â”€â”€â”€â–¶â”‚    (LLM)          â”‚â”€â”€â”€â”€â”¤      â”‚              â”‚\n",
    "â”‚  COORDINATOR â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”œâ”€â”€â”€â”€â”€â–¶â”‚  AGGREGATOR  â”‚â”€â”€â–¶ OUTPUT\n",
    "â”‚    (Code)    â”‚        â”‚                              â”‚      â”‚    (Code)    â”‚\n",
    "â”‚              â”‚        â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚      â”‚              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”œâ”€â”€â”€â”€â–¶â”‚    AGENT C        â”‚â”€â”€â”€â”€â”¤      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â”‚     â”‚    (LLM)          â”‚    â”‚\n",
    "                        â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "                        â”‚                              â”‚\n",
    "                        â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "                        â””â”€â”€â”€â”€â–¶â”‚    AGENT D        â”‚â”€â”€â”€â”€â”˜\n",
    "                              â”‚    (LLM)          â”‚\n",
    "                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "                         â–²                              â–²\n",
    "                         â”‚                              â”‚\n",
    "                    All agents                    All results\n",
    "                    start at the                  collected and\n",
    "                    SAME TIME                     combined\n",
    "```\n",
    "\n",
    "**Key Insight:** Unlike routing where only ONE agent runs, in parallelization ALL agents run concurrently.\n",
    "\n",
    "---\n",
    "\n",
    "### Parallelization vs. Other Patterns\n",
    "\n",
    "```\n",
    "PROMPT CHAINING (Sequential):\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Input â”‚â”€â”€â”€â–¶â”‚ Step 1  â”‚â”€â”€â”€â–¶â”‚ Step 2  â”‚â”€â”€â”€â–¶â”‚ Step 3  â”‚â”€â”€â”€â–¶â”‚ Output â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "             Time: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
    "             Total latency = Sum of all steps\n",
    "\n",
    "\n",
    "ROUTING (Selective):\n",
    "                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                        â”Œâ”€â”€â”€â”€â–¶â”‚ Agent A â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Input â”‚â”€â”€â”€â–¶â”‚ Router â”‚â”€â”¼â”€â”€â”€â”€â–¶â”‚ Agent B â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Output â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â””â”€â”€â”€â”€â–¶â”‚ Agent C â”‚\n",
    "                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "             Time: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
    "             Total latency = Router + 1 Agent\n",
    "\n",
    "\n",
    "PARALLELIZATION (Concurrent):\n",
    "                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                        â”Œâ”€â”€â”€â”€â–¶â”‚ Agent A â”‚â”€â”€â”€â”€â”\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Input â”‚â”€â”€â”€â–¶â”‚  Coord â”‚â”€â”¼â”€â”€â”€â”€â–¶â”‚ Agent B â”‚â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â–¶â”‚ Aggreg â”‚â”€â”€â–¶ Output\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â””â”€â”€â”€â”€â–¶â”‚ Agent C â”‚â”€â”€â”€â”€â”˜\n",
    "                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "             Time: â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘\n",
    "             Total latency â‰ˆ Max(Agent A, Agent B, Agent C)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Common Aggregation Strategies\n",
    "\n",
    "1. **Majority Voting**: Pick the most common answer among agents\n",
    "2. **Highest Confidence**: Pick the answer with highest confidence score\n",
    "3. **Weighted Voting**: Weight each agent's vote by confidence or reliability\n",
    "4. **Union/Intersection**: Combine lists (e.g., entity extraction)\n",
    "5. **Averaging**: Average numeric outputs (e.g., sentiment scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a514079a",
   "metadata": {},
   "source": [
    "### Our Implementation: Multi-Perspective Parallel Detection for AG News\n",
    "\n",
    "For our AG News classification task, we'll implement parallelization with **4 category detector agents** running concurrently. Each agent determines if the article belongs to their specific category.\n",
    "\n",
    "---\n",
    "\n",
    "#### Architecture Diagram\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚            PARALLELIZATION FOR AG NEWS CLASSIFICATION                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                        â”Œâ”€â”€â”€â”€â–¶â”‚  ğŸŒ WORLD DETECTOR      â”‚â”€â”€â”€â”€â”\n",
    "                        â”‚     â”‚  claude-haiku-4-5       â”‚    â”‚\n",
    "                        â”‚     â”‚                         â”‚    â”‚\n",
    "                        â”‚     â”‚  Output:                â”‚    â”‚\n",
    "                        â”‚     â”‚  {belongs, confidence}  â”‚    â”‚\n",
    "                        â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "                        â”‚                                    â”‚\n",
    "                        â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "                        â”‚     â”‚  âš½ SPORTS DETECTOR     â”‚    â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚     â”‚  claude-haiku-4-5       â”‚    â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              â”‚        â”œâ”€â”€â”€â”€â–¶â”‚                         â”‚â”€â”€â”€â”€â”¤      â”‚                  â”‚\n",
    "â”‚  COORDINATOR â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚  Output:                â”‚    â”œâ”€â”€â”€â”€â”€â–¶â”‚   AGGREGATOR     â”‚\n",
    "â”‚  (Python     â”‚        â”‚     â”‚  {belongs, confidence}  â”‚    â”‚      â”‚   (Python Code)  â”‚\n",
    "â”‚   Code)      â”‚        â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚      â”‚                  â”‚\n",
    "â”‚              â”‚        â”‚                                    â”‚      â”‚  Strategy B:     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚      â”‚  Confidence      â”‚\n",
    "       â”‚                â”‚     â”‚  ğŸ’¼ BUSINESS DETECTOR   â”‚    â”‚      â”‚  Voting          â”‚\n",
    "       â”‚                â”œâ”€â”€â”€â”€â–¶â”‚  claude-haiku-4-5       â”‚â”€â”€â”€â”€â”¤      â”‚                  â”‚\n",
    "       â”‚                â”‚     â”‚                         â”‚    â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚                â”‚     â”‚  Output:                â”‚    â”‚               â”‚\n",
    "       â”‚                â”‚     â”‚  {belongs, confidence}  â”‚    â”‚               â”‚\n",
    "       â”‚                â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚               â–¼\n",
    "       â”‚                â”‚                                    â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "       â”‚                â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚        â”‚              â”‚\n",
    "       â”‚                â””â”€â”€â”€â”€â–¶â”‚  ğŸ”¬ SCI/TECH DETECTOR   â”‚â”€â”€â”€â”€â”˜        â”‚   FINAL      â”‚\n",
    "       â”‚                      â”‚  claude-haiku-4-5       â”‚             â”‚   CATEGORY   â”‚\n",
    "       â”‚                      â”‚                         â”‚             â”‚              â”‚\n",
    "       â”‚                      â”‚  Output:                â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚                      â”‚  {belongs, confidence}  â”‚\n",
    "       â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚\n",
    "       â–¼\n",
    "  Uses ThreadPoolExecutor\n",
    "  to run all 4 agents\n",
    "  SIMULTANEOUSLY\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Models Used\n",
    "\n",
    "| Agent | Model | Rationale |\n",
    "|-------|-------|-----------|\n",
    "| World Detector | `claude-haiku-4-5-20251001` | Fast, cost-effective for binary detection |\n",
    "| Sports Detector | `claude-haiku-4-5-20251001` | Fast, cost-effective for binary detection |\n",
    "| Business Detector | `claude-haiku-4-5-20251001` | Fast, cost-effective for binary detection |\n",
    "| Sci/Tech Detector | `claude-haiku-4-5-20251001` | Fast, cost-effective for binary detection |\n",
    "\n",
    "Using the same fast model ensures **balanced latency** - total time â‰ˆ single Haiku call since all run in parallel.\n",
    "\n",
    "---\n",
    "\n",
    "### World Detector Agent ğŸŒ\n",
    "\n",
    "#### System Prompt\n",
    "```\n",
    "You are a WORLD NEWS DETECTOR specializing in identifying international affairs and political news.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"World\" category.\n",
    "\n",
    "The \"World\" category includes:\n",
    "- International politics and diplomacy\n",
    "- Government policies, elections, and political events\n",
    "- Military conflicts, wars, and peacekeeping\n",
    "- Humanitarian crises and global health issues\n",
    "- International organizations (UN, NATO, EU, WHO, etc.)\n",
    "- Cross-border crime, terrorism, and security\n",
    "- Immigration and refugee issues\n",
    "\n",
    "The \"World\" category does NOT include:\n",
    "- Sports events (even international ones like Olympics, World Cup)\n",
    "- Business/financial news (even about international trade)\n",
    "- Technology/science news (even about global tech companies)\n",
    "\n",
    "Analyze the article and return your assessment as JSON.\n",
    "\n",
    "Rules:\n",
    "- Focus ONLY on whether this is World/political news\n",
    "- Return a confidence score from 0.0 to 1.0\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Brief explanation\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### User Prompt Format\n",
    "```\n",
    "Determine if the following news article belongs to the WORLD category:\n",
    "\n",
    "---\n",
    "[Article text]\n",
    "---\n",
    "```\n",
    "\n",
    "#### Output Format\n",
    "```json\n",
    "{\n",
    "    \"belongs_to_category\": true,\n",
    "    \"confidence\": 0.85,\n",
    "    \"reasoning\": \"Article discusses UN peacekeeping efforts in Sudan - clear international politics focus.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Sports Detector Agent âš½\n",
    "\n",
    "#### System Prompt\n",
    "```\n",
    "You are a SPORTS NEWS DETECTOR specializing in identifying athletic and competitive sports news.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"Sports\" category.\n",
    "\n",
    "The \"Sports\" category includes:\n",
    "- Professional and amateur athletic competitions\n",
    "- Sports teams, players, coaches, and athletes\n",
    "- Game results, scores, standings, and statistics\n",
    "- Sports leagues (NFL, NBA, MLB, NHL, FIFA, etc.)\n",
    "- Olympic games and international sports competitions\n",
    "- Sports trades, contracts, and team management\n",
    "- Sports injuries and player updates\n",
    "\n",
    "The \"Sports\" category does NOT include:\n",
    "- Sports team stock prices or business deals (that's Business)\n",
    "- Sports technology innovations (that's Sci/Tech)\n",
    "- Sports-related politics or scandals (that's World)\n",
    "\n",
    "Analyze the article and return your assessment as JSON.\n",
    "\n",
    "Rules:\n",
    "- Focus ONLY on whether this is Sports news\n",
    "- Return a confidence score from 0.0 to 1.0\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Brief explanation\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### User Prompt Format\n",
    "```\n",
    "Determine if the following news article belongs to the SPORTS category:\n",
    "\n",
    "---\n",
    "[Article text]\n",
    "---\n",
    "```\n",
    "\n",
    "#### Output Format\n",
    "```json\n",
    "{\n",
    "    \"belongs_to_category\": true,\n",
    "    \"confidence\": 0.95,\n",
    "    \"reasoning\": \"Article covers Lakers vs Celtics NBA playoff game with scores and player stats.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Business Detector Agent ğŸ’¼\n",
    "\n",
    "#### System Prompt\n",
    "```\n",
    "You are a BUSINESS NEWS DETECTOR specializing in identifying financial and corporate news.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"Business\" category.\n",
    "\n",
    "The \"Business\" category includes:\n",
    "- Stock markets, trading, and investments\n",
    "- Company earnings, revenue, and financial reports\n",
    "- Mergers, acquisitions, and corporate restructuring\n",
    "- Economic indicators (GDP, inflation, employment)\n",
    "- Corporate leadership and executive changes\n",
    "- Industry analysis and market trends\n",
    "- Banking, finance, and monetary policy\n",
    "\n",
    "The \"Business\" category does NOT include:\n",
    "- Tech product launches or innovations (that's Sci/Tech)\n",
    "- Government economic policy debates (that's World)\n",
    "- Sports team finances (that's Sports)\n",
    "\n",
    "Analyze the article and return your assessment as JSON.\n",
    "\n",
    "Rules:\n",
    "- Focus ONLY on whether this is Business/financial news\n",
    "- Return a confidence score from 0.0 to 1.0\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Brief explanation\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### User Prompt Format\n",
    "```\n",
    "Determine if the following news article belongs to the BUSINESS category:\n",
    "\n",
    "---\n",
    "[Article text]\n",
    "---\n",
    "```\n",
    "\n",
    "#### Output Format\n",
    "```json\n",
    "{\n",
    "    \"belongs_to_category\": true,\n",
    "    \"confidence\": 0.90,\n",
    "    \"reasoning\": \"Article discusses quarterly earnings report and stock price movement for major corporation.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Sci/Tech Detector Agent ğŸ”¬\n",
    "\n",
    "#### System Prompt\n",
    "```\n",
    "You are a SCIENCE & TECHNOLOGY NEWS DETECTOR specializing in identifying tech and scientific news.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"Sci/Tech\" category.\n",
    "\n",
    "The \"Sci/Tech\" category includes:\n",
    "- Technology products, software, and hardware\n",
    "- Scientific research and discoveries\n",
    "- Internet, social media, and digital platforms\n",
    "- AI, machine learning, and emerging technologies\n",
    "- Space exploration and astronomy\n",
    "- Medical and health research breakthroughs\n",
    "- Environmental science and climate research\n",
    "- Consumer electronics and gadgets\n",
    "\n",
    "The \"Sci/Tech\" category does NOT include:\n",
    "- Tech company stock prices or financials (that's Business)\n",
    "- Tech regulation and government policy (that's World)\n",
    "- Sports technology like stadium upgrades (that's Sports)\n",
    "\n",
    "Analyze the article and return your assessment as JSON.\n",
    "\n",
    "Rules:\n",
    "- Focus ONLY on whether this is Science/Technology news\n",
    "- Return a confidence score from 0.0 to 1.0\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Brief explanation\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### User Prompt Format\n",
    "```\n",
    "Determine if the following news article belongs to the SCI/TECH category:\n",
    "\n",
    "---\n",
    "[Article text]\n",
    "---\n",
    "```\n",
    "\n",
    "#### Output Format\n",
    "```json\n",
    "{\n",
    "    \"belongs_to_category\": true,\n",
    "    \"confidence\": 0.92,\n",
    "    \"reasoning\": \"Article covers new smartphone features and AI capabilities - clear technology focus.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Aggregator: Confidence Voting\n",
    "\n",
    "The aggregator receives results from all 4 detectors and uses **confidence voting** to determine the final classification.\n",
    "\n",
    "#### Aggregation Logic\n",
    "\n",
    "```python\n",
    "def aggregate_results(world_result, sports_result, business_result, scitech_result):\n",
    "    # Build confidence scores for each category\n",
    "    # If belongs=True, use confidence; if belongs=False, use 0\n",
    "    scores = {\n",
    "        \"World\": world_result['confidence'] if world_result['belongs_to_category'] else 0,\n",
    "        \"Sports\": sports_result['confidence'] if sports_result['belongs_to_category'] else 0,\n",
    "        \"Business\": business_result['confidence'] if business_result['belongs_to_category'] else 0,\n",
    "        \"Sci/Tech\": scitech_result['confidence'] if scitech_result['belongs_to_category'] else 0\n",
    "    }\n",
    "    \n",
    "    # Pick category with highest confidence score\n",
    "    final_category = max(scores, key=scores.get)\n",
    "    final_confidence = scores[final_category]\n",
    "    \n",
    "    return {\n",
    "        \"classification\": final_category,\n",
    "        \"confidence\": final_confidence,\n",
    "        \"all_scores\": scores\n",
    "    }\n",
    "```\n",
    "\n",
    "#### Example Aggregation\n",
    "\n",
    "| Detector | belongs_to_category | confidence | Score Used |\n",
    "|----------|---------------------|------------|------------|\n",
    "| World | False | 0.20 | **0** |\n",
    "| Sports | False | 0.15 | **0** |\n",
    "| Business | True | 0.85 | **0.85** |\n",
    "| Sci/Tech | True | 0.45 | **0.45** |\n",
    "\n",
    "**Result:** Business wins with confidence 0.85\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "| Component | Implementation | Technology |\n",
    "|-----------|----------------|------------|\n",
    "| Coordinator | `ThreadPoolExecutor` | Python |\n",
    "| World Detector | Binary classifier | Claude Haiku 4.5 |\n",
    "| Sports Detector | Binary classifier | Claude Haiku 4.5 |\n",
    "| Business Detector | Binary classifier | Claude Haiku 4.5 |\n",
    "| Sci/Tech Detector | Binary classifier | Claude Haiku 4.5 |\n",
    "| Aggregator | Confidence voting | Python |\n",
    "\n",
    "**Total LLM Calls per Article:** 4 (running in parallel)\n",
    "**Expected Latency:** ~1 Haiku call (since all run concurrently)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fd0ad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PARALLELIZATION DESIGN PATTERN - Classification\n",
      "======================================================================\n",
      "\n",
      "Processing 100 samples using 4 parallel detectors...\n",
      "Each article runs through World, Sports, Business, and Sci/Tech detectors simultaneously.\n",
      "âš ï¸  Rate limiting enabled: ~5.3s delay between articles to stay under API limits.\n",
      "\n",
      "  âœ“ Processed 10/100 articles (10.0%)\n",
      "  âœ“ Processed 20/100 articles (20.0%)\n",
      "  âœ“ Processed 30/100 articles (30.0%)\n",
      "  âœ“ Processed 40/100 articles (40.0%)\n",
      "  âœ“ Processed 50/100 articles (50.0%)\n",
      "  âœ“ Processed 60/100 articles (60.0%)\n",
      "  âœ“ Processed 70/100 articles (70.0%)\n",
      "  âœ“ Processed 80/100 articles (80.0%)\n",
      "  âœ“ Processed 90/100 articles (90.0%)\n",
      "  âœ“ Processed 100/100 articles (100.0%)\n",
      "\n",
      "======================================================================\n",
      "PARALLELIZATION RESULTS (showing first 3 of 100)\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 1\n",
      "Ground Truth: Business\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“Š Detector Results:\n",
      "   BUSINESS   â”‚ âœ“ belongs: True  â”‚ confidence: 0.85\n",
      "   WORLD      â”‚ âœ— belongs: False â”‚ confidence: 0.85\n",
      "   SPORTS     â”‚ âœ— belongs: False â”‚ confidence: 0.95\n",
      "   SCITECH    â”‚ âœ— belongs: False â”‚ confidence: 0.95\n",
      "\n",
      "ğŸ“‹ Aggregated Scores (Strategy B):\n",
      "   World      â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚ 0.00\n",
      "   Sports     â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚ 0.00\n",
      "   Business   â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ â”‚ 0.85\n",
      "   Sci/Tech   â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚ 0.00\n",
      "\n",
      "ğŸ¯ Final Classification: Business\n",
      "   Confidence: 0.85\n",
      "\n",
      "   Result: âœ“ CORRECT\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 2\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“Š Detector Results:\n",
      "   SCITECH    â”‚ âœ“ belongs: True  â”‚ confidence: 0.95\n",
      "   SPORTS     â”‚ âœ— belongs: False â”‚ confidence: 0.95\n",
      "   BUSINESS   â”‚ âœ— belongs: False â”‚ confidence: 0.85\n",
      "   WORLD      â”‚ âœ— belongs: False â”‚ confidence: 0.95\n",
      "\n",
      "ğŸ“‹ Aggregated Scores (Strategy B):\n",
      "   World      â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚ 0.00\n",
      "   Sports     â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚ 0.00\n",
      "   Business   â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚ 0.00\n",
      "   Sci/Tech   â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ â”‚ 0.95\n",
      "\n",
      "ğŸ¯ Final Classification: Sci/Tech\n",
      "   Confidence: 0.95\n",
      "\n",
      "   Result: âœ“ CORRECT\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 3\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“Š Detector Results:\n",
      "   BUSINESS   â”‚ âœ— belongs: False â”‚ confidence: 0.85\n",
      "   WORLD      â”‚ âœ— belongs: False â”‚ confidence: 0.95\n",
      "   SPORTS     â”‚ âœ— belongs: False â”‚ confidence: 0.98\n",
      "   SCITECH    â”‚ âœ“ belongs: True  â”‚ confidence: 0.95\n",
      "\n",
      "ğŸ“‹ Aggregated Scores (Strategy B):\n",
      "   World      â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚ 0.00\n",
      "   Sports     â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚ 0.00\n",
      "   Business   â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚ 0.00\n",
      "   Sci/Tech   â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ â”‚ 0.95\n",
      "\n",
      "ğŸ¯ Final Classification: Sci/Tech\n",
      "   Confidence: 0.95\n",
      "\n",
      "   Result: âœ“ CORRECT\n",
      "\n",
      "======================================================================\n",
      "Parallelization complete. 100 results stored in 'parallel_results'\n",
      "Ready for evaluation.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PARALLELIZATION DESIGN PATTERN IMPLEMENTATION\n",
    "# ============================================================\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# Rate limiting: Anthropic has 50 requests/minute limit\n",
    "# With 4 parallel requests per article, we can process ~12 articles/minute\n",
    "# Adding delay to stay under limit\n",
    "REQUESTS_PER_ARTICLE = 4\n",
    "RATE_LIMIT_PER_MINUTE = 50\n",
    "MIN_SECONDS_PER_ARTICLE = (REQUESTS_PER_ARTICLE / RATE_LIMIT_PER_MINUTE) * 60 + 0.5  # ~5.3 seconds\n",
    "\n",
    "# ============================================================\n",
    "# WORLD DETECTOR AGENT\n",
    "# ============================================================\n",
    "\n",
    "WORLD_DETECTOR_SYSTEM_PROMPT = \"\"\"You are a WORLD NEWS DETECTOR specializing in identifying international affairs and political news.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"World\" category.\n",
    "\n",
    "The \"World\" category includes:\n",
    "- International politics and diplomacy\n",
    "- Government policies, elections, and political events\n",
    "- Military conflicts, wars, and peacekeeping\n",
    "- Humanitarian crises and global health issues\n",
    "- International organizations (UN, NATO, EU, WHO, etc.)\n",
    "- Cross-border crime, terrorism, and security\n",
    "- Immigration and refugee issues\n",
    "\n",
    "The \"World\" category does NOT include:\n",
    "- Sports events (even international ones like Olympics, World Cup)\n",
    "- Business/financial news (even about international trade)\n",
    "- Technology/science news (even about global tech companies)\n",
    "\n",
    "Analyze the article and return your assessment as JSON.\n",
    "\n",
    "Rules:\n",
    "- Focus ONLY on whether this is World/political news\n",
    "- Return a confidence score from 0.0 to 1.0\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Brief explanation\"\n",
    "}\"\"\"\n",
    "\n",
    "def run_world_detector(article_text: str) -> dict:\n",
    "    \"\"\"Detect if article belongs to World category.\"\"\"\n",
    "    user_prompt = f\"\"\"Determine if the following news article belongs to the WORLD category:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        max_tokens=512,\n",
    "        system=WORLD_DETECTOR_SYSTEM_PROMPT,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    \n",
    "    response_text = response.content[0].text\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(cleaned)\n",
    "        result['category'] = 'World'\n",
    "        return result\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"belongs_to_category\": False, \"confidence\": 0, \"reasoning\": \"Parse error\", \"category\": \"World\"}\n",
    "\n",
    "# ============================================================\n",
    "# SPORTS DETECTOR AGENT\n",
    "# ============================================================\n",
    "\n",
    "SPORTS_DETECTOR_SYSTEM_PROMPT = \"\"\"You are a SPORTS NEWS DETECTOR specializing in identifying athletic and competitive sports news.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"Sports\" category.\n",
    "\n",
    "The \"Sports\" category includes:\n",
    "- Professional and amateur athletic competitions\n",
    "- Sports teams, players, coaches, and athletes\n",
    "- Game results, scores, standings, and statistics\n",
    "- Sports leagues (NFL, NBA, MLB, NHL, FIFA, etc.)\n",
    "- Olympic games and international sports competitions\n",
    "- Sports trades, contracts, and team management\n",
    "- Sports injuries and player updates\n",
    "\n",
    "The \"Sports\" category does NOT include:\n",
    "- Sports team stock prices or business deals (that's Business)\n",
    "- Sports technology innovations (that's Sci/Tech)\n",
    "- Sports-related politics or scandals (that's World)\n",
    "\n",
    "Analyze the article and return your assessment as JSON.\n",
    "\n",
    "Rules:\n",
    "- Focus ONLY on whether this is Sports news\n",
    "- Return a confidence score from 0.0 to 1.0\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Brief explanation\"\n",
    "}\"\"\"\n",
    "\n",
    "def run_sports_detector(article_text: str) -> dict:\n",
    "    \"\"\"Detect if article belongs to Sports category.\"\"\"\n",
    "    user_prompt = f\"\"\"Determine if the following news article belongs to the SPORTS category:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        max_tokens=512,\n",
    "        system=SPORTS_DETECTOR_SYSTEM_PROMPT,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    \n",
    "    response_text = response.content[0].text\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(cleaned)\n",
    "        result['category'] = 'Sports'\n",
    "        return result\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"belongs_to_category\": False, \"confidence\": 0, \"reasoning\": \"Parse error\", \"category\": \"Sports\"}\n",
    "\n",
    "# ============================================================\n",
    "# BUSINESS DETECTOR AGENT\n",
    "# ============================================================\n",
    "\n",
    "BUSINESS_DETECTOR_SYSTEM_PROMPT = \"\"\"You are a BUSINESS NEWS DETECTOR specializing in identifying financial and corporate news.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"Business\" category.\n",
    "\n",
    "The \"Business\" category includes:\n",
    "- Stock markets, trading, and investments\n",
    "- Company earnings, revenue, and financial reports\n",
    "- Mergers, acquisitions, and corporate restructuring\n",
    "- Economic indicators (GDP, inflation, employment)\n",
    "- Corporate leadership and executive changes\n",
    "- Industry analysis and market trends\n",
    "- Banking, finance, and monetary policy\n",
    "\n",
    "The \"Business\" category does NOT include:\n",
    "- Tech product launches or innovations (that's Sci/Tech)\n",
    "- Government economic policy debates (that's World)\n",
    "- Sports team finances (that's Sports)\n",
    "\n",
    "Analyze the article and return your assessment as JSON.\n",
    "\n",
    "Rules:\n",
    "- Focus ONLY on whether this is Business/financial news\n",
    "- Return a confidence score from 0.0 to 1.0\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Brief explanation\"\n",
    "}\"\"\"\n",
    "\n",
    "def run_business_detector(article_text: str) -> dict:\n",
    "    \"\"\"Detect if article belongs to Business category.\"\"\"\n",
    "    user_prompt = f\"\"\"Determine if the following news article belongs to the BUSINESS category:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        max_tokens=512,\n",
    "        system=BUSINESS_DETECTOR_SYSTEM_PROMPT,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    \n",
    "    response_text = response.content[0].text\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(cleaned)\n",
    "        result['category'] = 'Business'\n",
    "        return result\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"belongs_to_category\": False, \"confidence\": 0, \"reasoning\": \"Parse error\", \"category\": \"Business\"}\n",
    "\n",
    "# ============================================================\n",
    "# SCI/TECH DETECTOR AGENT\n",
    "# ============================================================\n",
    "\n",
    "SCITECH_DETECTOR_SYSTEM_PROMPT = \"\"\"You are a SCIENCE & TECHNOLOGY NEWS DETECTOR specializing in identifying tech and scientific news.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"Sci/Tech\" category.\n",
    "\n",
    "The \"Sci/Tech\" category includes:\n",
    "- Technology products, software, and hardware\n",
    "- Scientific research and discoveries\n",
    "- Internet, social media, and digital platforms\n",
    "- AI, machine learning, and emerging technologies\n",
    "- Space exploration and astronomy\n",
    "- Medical and health research breakthroughs\n",
    "- Environmental science and climate research\n",
    "- Consumer electronics and gadgets\n",
    "\n",
    "The \"Sci/Tech\" category does NOT include:\n",
    "- Tech company stock prices or financials (that's Business)\n",
    "- Tech regulation and government policy (that's World)\n",
    "- Sports technology like stadium upgrades (that's Sports)\n",
    "\n",
    "Analyze the article and return your assessment as JSON.\n",
    "\n",
    "Rules:\n",
    "- Focus ONLY on whether this is Science/Technology news\n",
    "- Return a confidence score from 0.0 to 1.0\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Brief explanation\"\n",
    "}\"\"\"\n",
    "\n",
    "def run_scitech_detector(article_text: str) -> dict:\n",
    "    \"\"\"Detect if article belongs to Sci/Tech category.\"\"\"\n",
    "    user_prompt = f\"\"\"Determine if the following news article belongs to the SCI/TECH category:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        max_tokens=512,\n",
    "        system=SCITECH_DETECTOR_SYSTEM_PROMPT,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    \n",
    "    response_text = response.content[0].text\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(cleaned)\n",
    "        result['category'] = 'Sci/Tech'\n",
    "        return result\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"belongs_to_category\": False, \"confidence\": 0, \"reasoning\": \"Parse error\", \"category\": \"Sci/Tech\"}\n",
    "\n",
    "# ============================================================\n",
    "# AGGREGATOR (Strategy B: Confidence Voting)\n",
    "# ============================================================\n",
    "\n",
    "def aggregate_detector_results(world_result: dict, sports_result: dict, \n",
    "                                business_result: dict, scitech_result: dict) -> dict:\n",
    "    \"\"\"Aggregate results from all 4 detectors using confidence voting (Strategy B).\"\"\"\n",
    "    \n",
    "    # Build confidence scores for each category\n",
    "    # If belongs=True, use confidence; if belongs=False, use 0\n",
    "    scores = {\n",
    "        \"World\": world_result.get('confidence', 0) if world_result.get('belongs_to_category', False) else 0,\n",
    "        \"Sports\": sports_result.get('confidence', 0) if sports_result.get('belongs_to_category', False) else 0,\n",
    "        \"Business\": business_result.get('confidence', 0) if business_result.get('belongs_to_category', False) else 0,\n",
    "        \"Sci/Tech\": scitech_result.get('confidence', 0) if scitech_result.get('belongs_to_category', False) else 0\n",
    "    }\n",
    "    \n",
    "    # Handle edge case: all scores are 0 (no detector claimed the article)\n",
    "    if all(s == 0 for s in scores.values()):\n",
    "        # Fall back to highest confidence regardless of belongs_to_category\n",
    "        fallback_scores = {\n",
    "            \"World\": world_result.get('confidence', 0),\n",
    "            \"Sports\": sports_result.get('confidence', 0),\n",
    "            \"Business\": business_result.get('confidence', 0),\n",
    "            \"Sci/Tech\": scitech_result.get('confidence', 0)\n",
    "        }\n",
    "        final_category = max(fallback_scores, key=fallback_scores.get)\n",
    "        final_confidence = fallback_scores[final_category]\n",
    "        used_fallback = True\n",
    "    else:\n",
    "        # Pick category with highest confidence score\n",
    "        final_category = max(scores, key=scores.get)\n",
    "        final_confidence = scores[final_category]\n",
    "        used_fallback = False\n",
    "    \n",
    "    return {\n",
    "        \"classification\": final_category,\n",
    "        \"confidence\": final_confidence,\n",
    "        \"all_scores\": scores,\n",
    "        \"used_fallback\": used_fallback\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# COORDINATOR (Parallel Execution)\n",
    "# ============================================================\n",
    "\n",
    "def parallel_classify(article_text: str) -> dict:\n",
    "    \"\"\"Coordinator: Run all 4 detectors in parallel and aggregate results.\"\"\"\n",
    "    \n",
    "    # Define the detector functions\n",
    "    detectors = [\n",
    "        (\"world\", run_world_detector),\n",
    "        (\"sports\", run_sports_detector),\n",
    "        (\"business\", run_business_detector),\n",
    "        (\"scitech\", run_scitech_detector)\n",
    "    ]\n",
    "    \n",
    "    # Run all detectors in parallel\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_detector = {\n",
    "            executor.submit(func, article_text): name \n",
    "            for name, func in detectors\n",
    "        }\n",
    "        \n",
    "        # Collect results\n",
    "        for future in as_completed(future_to_detector):\n",
    "            detector_name = future_to_detector[future]\n",
    "            results[detector_name] = future.result()\n",
    "    \n",
    "    # Aggregate results\n",
    "    aggregated = aggregate_detector_results(\n",
    "        results['world'],\n",
    "        results['sports'],\n",
    "        results['business'],\n",
    "        results['scitech']\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"detector_results\": results,\n",
    "        \"aggregated_result\": aggregated\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# PROCESS ALL TEST DATA\n",
    "# ============================================================\n",
    "\n",
    "# Store parallelization results\n",
    "parallel_results = []\n",
    "\n",
    "# Number of results to print\n",
    "NUM_TO_PRINT = 3\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PARALLELIZATION DESIGN PATTERN - Classification\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nProcessing {NUM_SAMPLES} samples using 4 parallel detectors...\")\n",
    "print(f\"Each article runs through World, Sports, Business, and Sci/Tech detectors simultaneously.\")\n",
    "print(f\"âš ï¸  Rate limiting enabled: ~{MIN_SECONDS_PER_ARTICLE:.1f}s delay between articles to stay under API limits.\\n\")\n",
    "\n",
    "# Progress tracking\n",
    "PROGRESS_INTERVAL = 10\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sample = test_data[i]\n",
    "    article_text = sample['text']\n",
    "    ground_truth_label = sample['label']\n",
    "    \n",
    "    # Run the parallel classification pipeline\n",
    "    result = parallel_classify(article_text)\n",
    "    \n",
    "    # Store result with metadata\n",
    "    parallel_results.append({\n",
    "        \"index\": i,\n",
    "        \"original_text\": article_text,\n",
    "        \"ground_truth_label\": ground_truth_label,\n",
    "        \"ground_truth_name\": label_names[ground_truth_label],\n",
    "        \"detector_results\": result[\"detector_results\"],\n",
    "        \"aggregated_result\": result[\"aggregated_result\"]\n",
    "    })\n",
    "    \n",
    "    # Print progress\n",
    "    if (i + 1) % PROGRESS_INTERVAL == 0 or (i + 1) == NUM_SAMPLES:\n",
    "        print(f\"  âœ“ Processed {i + 1}/{NUM_SAMPLES} articles ({(i + 1) / NUM_SAMPLES * 100:.1f}%)\")\n",
    "    \n",
    "    # Rate limiting: ensure minimum time between articles\n",
    "    elapsed = time.time() - start_time\n",
    "    if elapsed < MIN_SECONDS_PER_ARTICLE and i < NUM_SAMPLES - 1:\n",
    "        sleep_time = MIN_SECONDS_PER_ARTICLE - elapsed\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"PARALLELIZATION RESULTS (showing first {NUM_TO_PRINT} of {len(parallel_results)})\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Display results\n",
    "for result in parallel_results[:NUM_TO_PRINT]:\n",
    "    print(f\"\\n{'â”€' * 70}\")\n",
    "    print(f\"Article {result['index'] + 1}\")\n",
    "    print(f\"Ground Truth: {result['ground_truth_name']}\")\n",
    "    print(f\"{'â”€' * 70}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Detector Results:\")\n",
    "    for detector_name, detector_result in result['detector_results'].items():\n",
    "        belongs = detector_result.get('belongs_to_category', False)\n",
    "        conf = detector_result.get('confidence', 0)\n",
    "        symbol = \"âœ“\" if belongs else \"âœ—\"\n",
    "        print(f\"   {detector_name.upper():10} â”‚ {symbol} belongs: {str(belongs):5} â”‚ confidence: {conf:.2f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Aggregated Scores (Strategy B):\")\n",
    "    scores = result['aggregated_result']['all_scores']\n",
    "    for cat, score in scores.items():\n",
    "        bar = \"â–ˆ\" * int(score * 20) + \"â–‘\" * (20 - int(score * 20))\n",
    "        print(f\"   {cat:10} â”‚ {bar} â”‚ {score:.2f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Final Classification: {result['aggregated_result']['classification']}\")\n",
    "    print(f\"   Confidence: {result['aggregated_result']['confidence']:.2f}\")\n",
    "    if result['aggregated_result']['used_fallback']:\n",
    "        print(f\"   (Used fallback - no detector claimed the article)\")\n",
    "    \n",
    "    # Quick comparison\n",
    "    predicted = result['aggregated_result']['classification']\n",
    "    actual = result['ground_truth_name']\n",
    "    match = \"âœ“ CORRECT\" if predicted == actual else \"âœ— INCORRECT\"\n",
    "    print(f\"\\n   Result: {match}\")\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Parallelization complete. {len(parallel_results)} results stored in 'parallel_results'\")\n",
    "print(f\"Ready for evaluation.\")\n",
    "print(f\"{'=' * 70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e094388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PARALLELIZATION DESIGN PATTERN - EVALUATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "OVERALL METRICS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Total Samples:     100\n",
      "  Valid Predictions: 100\n",
      "  Error Rate:        0.0%\n",
      "\n",
      "  ğŸ“Š Accuracy:        0.7200  (72.0%)\n",
      "\n",
      "  Macro Averages (treats all classes equally):\n",
      "     Precision:      0.7180\n",
      "     Recall:         0.7722\n",
      "     F1 Score:       0.7167\n",
      "\n",
      "  Weighted Averages (accounts for class imbalance):\n",
      "     Precision:      0.7692\n",
      "     Recall:         0.7200\n",
      "     F1 Score:       0.7204\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "PER-CLASS METRICS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.88      0.70      0.78        30\n",
      "      Sports       0.63      0.90      0.75        21\n",
      "    Business       0.52      0.92      0.67        12\n",
      "    Sci/Tech       0.84      0.57      0.68        37\n",
      "\n",
      "    accuracy                           0.72       100\n",
      "   macro avg       0.72      0.77      0.72       100\n",
      "weighted avg       0.77      0.72      0.72       100\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CONFUSION MATRIX\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Predicted â†’     World    Sports  Business  Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Actual â†“\n",
      "          World        21         6         1         2\n",
      "         Sports         1        19         0         1\n",
      "       Business         0         0        11         1\n",
      "       Sci/Tech         2         5         9        21\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DISTRIBUTION ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Category        Ground Truth       Predicted   Difference\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "World                     30              24           -6\n",
      "Sports                    21              30           +9\n",
      "Business                  12              21           +9\n",
      "Sci/Tech                  37              25          -12\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DETECTOR ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Number of Detectors Claiming Article:\n",
      "      Claims      Count   Percentage\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "           0         15        15.0%\n",
      "           1         83        83.0%\n",
      "           2          2         2.0%\n",
      "\n",
      "  Fallback Used (no detector claimed): 15 (15.0%)\n",
      "\n",
      "  Per-Detector Claim Statistics:\n",
      "  Detector        Claimed    Correct     Accuracy\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  WORLD                21         21      100.0%\n",
      "  SPORTS               21         19       90.5%\n",
      "  BUSINESS             22         11       50.0%\n",
      "  SCITECH              23         22       95.7%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CONFIDENCE ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Confidence                Count     Accuracy\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "high (0.8-1.0)               99       71.7%\n",
      "medium (0.5-0.8)              1      100.0%\n",
      "low (0-0.5)                   0          N/A\n",
      "\n",
      "  Average Confidence: 0.938\n",
      "\n",
      "======================================================================\n",
      "PARALLELIZATION PATTERN EVALUATION COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EVALUATION: Parallelization Design Pattern Performance\n",
    "# ============================================================\n",
    "\n",
    "# Extract predictions and ground truth from parallelization results\n",
    "parallel_predictions = []\n",
    "parallel_ground_truths = []\n",
    "parallel_errors = []\n",
    "\n",
    "for result in parallel_results:\n",
    "    ground_truth = result['ground_truth_name']\n",
    "    parallel_ground_truths.append(ground_truth)\n",
    "    \n",
    "    # Get prediction from aggregated_result\n",
    "    aggregated = result['aggregated_result']\n",
    "    \n",
    "    if 'classification' in aggregated:\n",
    "        predicted = aggregated['classification']\n",
    "        parallel_predictions.append(predicted)\n",
    "    else:\n",
    "        # Handle errors\n",
    "        parallel_predictions.append(\"ERROR\")\n",
    "        parallel_errors.append(result['index'])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PARALLELIZATION DESIGN PATTERN - EVALUATION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for errors\n",
    "if parallel_errors:\n",
    "    print(f\"\\nâš ï¸  Warning: {len(parallel_errors)} samples had errors (indices: {parallel_errors[:10]}{'...' if len(parallel_errors) > 10 else ''})\")\n",
    "    print(f\"   These are excluded from metrics calculation.\\n\")\n",
    "    \n",
    "    valid_parallel_predictions = [p for p in parallel_predictions if p != \"ERROR\"]\n",
    "    valid_parallel_ground_truths = [g for p, g in zip(parallel_predictions, parallel_ground_truths) if p != \"ERROR\"]\n",
    "else:\n",
    "    valid_parallel_predictions = parallel_predictions\n",
    "    valid_parallel_ground_truths = parallel_ground_truths\n",
    "\n",
    "# ============================================================\n",
    "# Basic Metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"OVERALL METRICS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "parallel_accuracy = accuracy_score(valid_parallel_ground_truths, valid_parallel_predictions)\n",
    "parallel_precision_macro = precision_score(valid_parallel_ground_truths, valid_parallel_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "parallel_recall_macro = recall_score(valid_parallel_ground_truths, valid_parallel_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "parallel_f1_macro = f1_score(valid_parallel_ground_truths, valid_parallel_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "\n",
    "parallel_precision_weighted = precision_score(valid_parallel_ground_truths, valid_parallel_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "parallel_recall_weighted = recall_score(valid_parallel_ground_truths, valid_parallel_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "parallel_f1_weighted = f1_score(valid_parallel_ground_truths, valid_parallel_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\n  Total Samples:     {len(parallel_results)}\")\n",
    "print(f\"  Valid Predictions: {len(valid_parallel_predictions)}\")\n",
    "print(f\"  Error Rate:        {len(parallel_errors) / len(parallel_results) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n  ğŸ“Š Accuracy:        {parallel_accuracy:.4f}  ({parallel_accuracy * 100:.1f}%)\")\n",
    "print(f\"\\n  Macro Averages (treats all classes equally):\")\n",
    "print(f\"     Precision:      {parallel_precision_macro:.4f}\")\n",
    "print(f\"     Recall:         {parallel_recall_macro:.4f}\")\n",
    "print(f\"     F1 Score:       {parallel_f1_macro:.4f}\")\n",
    "\n",
    "print(f\"\\n  Weighted Averages (accounts for class imbalance):\")\n",
    "print(f\"     Precision:      {parallel_precision_weighted:.4f}\")\n",
    "print(f\"     Recall:         {parallel_recall_weighted:.4f}\")\n",
    "print(f\"     F1 Score:       {parallel_f1_weighted:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Per-Class Metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"PER-CLASS METRICS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "print(\"\\n\" + classification_report(valid_parallel_ground_truths, valid_parallel_predictions, labels=CATEGORIES, zero_division=0))\n",
    "\n",
    "# ============================================================\n",
    "# Confusion Matrix\n",
    "# ============================================================\n",
    "\n",
    "print(\"â”€\" * 70)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "parallel_cm = confusion_matrix(valid_parallel_ground_truths, valid_parallel_predictions, labels=CATEGORIES)\n",
    "\n",
    "print(f\"\\n{'Predicted â†’':>15}\", end=\"\")\n",
    "for cat in CATEGORIES:\n",
    "    print(f\"{cat:>10}\", end=\"\")\n",
    "print(\"\\n\" + \"â”€\" * 55)\n",
    "\n",
    "print(\"Actual â†“\")\n",
    "for i, cat in enumerate(CATEGORIES):\n",
    "    print(f\"{cat:>15}\", end=\"\")\n",
    "    for j in range(len(CATEGORIES)):\n",
    "        print(f\"{parallel_cm[i][j]:>10}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "# ============================================================\n",
    "# Distribution Analysis\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"DISTRIBUTION ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "parallel_gt_dist = Counter(valid_parallel_ground_truths)\n",
    "parallel_pred_dist = Counter(valid_parallel_predictions)\n",
    "\n",
    "print(f\"\\n{'Category':<12} {'Ground Truth':>15} {'Predicted':>15} {'Difference':>12}\")\n",
    "print(\"â”€\" * 55)\n",
    "for cat in CATEGORIES:\n",
    "    gt_count = parallel_gt_dist.get(cat, 0)\n",
    "    pred_count = parallel_pred_dist.get(cat, 0)\n",
    "    diff = pred_count - gt_count\n",
    "    diff_str = f\"+{diff}\" if diff > 0 else str(diff)\n",
    "    print(f\"{cat:<12} {gt_count:>15} {pred_count:>15} {diff_str:>12}\")\n",
    "\n",
    "# ============================================================\n",
    "# Detector Analysis (Unique to Parallelization)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"DETECTOR ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Count how many detectors claimed each article\n",
    "detector_claim_counts = Counter()\n",
    "for result in parallel_results:\n",
    "    claims = sum(1 for det_result in result['detector_results'].values() \n",
    "                 if det_result.get('belongs_to_category', False))\n",
    "    detector_claim_counts[claims] += 1\n",
    "\n",
    "print(f\"\\n  Number of Detectors Claiming Article:\")\n",
    "print(f\"  {'Claims':>10} {'Count':>10} {'Percentage':>12}\")\n",
    "print(\"  \" + \"â”€\" * 35)\n",
    "for num_claims in sorted(detector_claim_counts.keys()):\n",
    "    count = detector_claim_counts[num_claims]\n",
    "    pct = count / len(parallel_results) * 100\n",
    "    print(f\"  {num_claims:>10} {count:>10} {pct:>11.1f}%\")\n",
    "\n",
    "# Fallback usage\n",
    "fallback_count = sum(1 for r in parallel_results if r['aggregated_result'].get('used_fallback', False))\n",
    "print(f\"\\n  Fallback Used (no detector claimed): {fallback_count} ({fallback_count / len(parallel_results) * 100:.1f}%)\")\n",
    "\n",
    "# Per-detector accuracy (when that detector claimed and was correct)\n",
    "print(f\"\\n  Per-Detector Claim Statistics:\")\n",
    "print(f\"  {'Detector':<12} {'Claimed':>10} {'Correct':>10} {'Accuracy':>12}\")\n",
    "print(\"  \" + \"â”€\" * 47)\n",
    "\n",
    "detector_stats = {\n",
    "    'world': {'claimed': 0, 'correct': 0},\n",
    "    'sports': {'claimed': 0, 'correct': 0},\n",
    "    'business': {'claimed': 0, 'correct': 0},\n",
    "    'scitech': {'claimed': 0, 'correct': 0}\n",
    "}\n",
    "category_map = {'world': 'World', 'sports': 'Sports', 'business': 'Business', 'scitech': 'Sci/Tech'}\n",
    "\n",
    "for result in parallel_results:\n",
    "    for det_name, det_result in result['detector_results'].items():\n",
    "        if det_result.get('belongs_to_category', False):\n",
    "            detector_stats[det_name]['claimed'] += 1\n",
    "            if category_map[det_name] == result['ground_truth_name']:\n",
    "                detector_stats[det_name]['correct'] += 1\n",
    "\n",
    "for det_name in ['world', 'sports', 'business', 'scitech']:\n",
    "    claimed = detector_stats[det_name]['claimed']\n",
    "    correct = detector_stats[det_name]['correct']\n",
    "    acc = correct / claimed if claimed > 0 else 0\n",
    "    print(f\"  {det_name.upper():<12} {claimed:>10} {correct:>10} {acc:>11.1%}\")\n",
    "\n",
    "# ============================================================\n",
    "# Confidence Analysis\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"CONFIDENCE ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Bin confidence scores\n",
    "confidence_bins = {\"high (0.8-1.0)\": [0, 0], \"medium (0.5-0.8)\": [0, 0], \"low (0-0.5)\": [0, 0]}\n",
    "\n",
    "for result in parallel_results:\n",
    "    conf = result['aggregated_result'].get('confidence', 0)\n",
    "    predicted = result['aggregated_result'].get('classification', '')\n",
    "    is_correct = predicted == result['ground_truth_name']\n",
    "    \n",
    "    if conf >= 0.8:\n",
    "        bin_name = \"high (0.8-1.0)\"\n",
    "    elif conf >= 0.5:\n",
    "        bin_name = \"medium (0.5-0.8)\"\n",
    "    else:\n",
    "        bin_name = \"low (0-0.5)\"\n",
    "    \n",
    "    confidence_bins[bin_name][1] += 1\n",
    "    if is_correct:\n",
    "        confidence_bins[bin_name][0] += 1\n",
    "\n",
    "print(f\"\\n{'Confidence':<20} {'Count':>10} {'Accuracy':>12}\")\n",
    "print(\"â”€\" * 45)\n",
    "for bin_name in [\"high (0.8-1.0)\", \"medium (0.5-0.8)\", \"low (0-0.5)\"]:\n",
    "    correct, total = confidence_bins[bin_name]\n",
    "    if total > 0:\n",
    "        acc = correct / total\n",
    "        print(f\"{bin_name:<20} {total:>10} {acc:>11.1%}\")\n",
    "    else:\n",
    "        print(f\"{bin_name:<20} {total:>10} {'N/A':>12}\")\n",
    "\n",
    "# Average confidence\n",
    "avg_confidence = sum(r['aggregated_result'].get('confidence', 0) for r in parallel_results) / len(parallel_results)\n",
    "print(f\"\\n  Average Confidence: {avg_confidence:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PARALLELIZATION PATTERN EVALUATION COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0b617",
   "metadata": {},
   "source": [
    "## 4. Orchestrator-Worker Design Pattern\n",
    "\n",
    "### What is Orchestrator-Worker?\n",
    "\n",
    "**Orchestrator-Worker** is an agentic workflow pattern where an LLM orchestrator dynamically coordinates multiple LLM workers, and an LLM synthesizer combines their outputs into a final result. Unlike parallelization (which uses code for coordination and aggregation), orchestrator-worker leverages LLM reasoning at every stage.\n",
    "\n",
    "This pattern is particularly useful when:\n",
    "- Tasks require dynamic, context-aware coordination\n",
    "- Simple voting/aggregation rules are insufficient\n",
    "- Conflict resolution requires reasoning, not just math\n",
    "- Full explainability and audit trails are required\n",
    "- Edge cases and ambiguities are common\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Orchestrator (LLM)**: Analyzes the input and creates customized instructions for each worker\n",
    "2. **Workers (LLMs)**: Execute subtasks with guidance from the orchestrator\n",
    "3. **Synthesizer (LLM)**: Reasons over all worker outputs to produce the final result\n",
    "\n",
    "### How It Differs from Other Patterns\n",
    "\n",
    "| Pattern | Coordination | Workers | Aggregation |\n",
    "|---------|--------------|---------|-------------|\n",
    "| **Prompt Chaining** | Sequential code | 1 LLM per step | N/A (pipeline) |\n",
    "| **Routing** | LLM router | 1 LLM selected | N/A (single path) |\n",
    "| **Parallelization** | Code | Multiple LLMs | Code (voting) |\n",
    "| **Orchestrator-Worker** | LLM | Multiple LLMs | LLM (synthesis) |\n",
    "\n",
    "---\n",
    "\n",
    "### Generic Orchestrator-Worker Workflow Diagram\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    ORCHESTRATOR-WORKER DESIGN PATTERN                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              â”‚\n",
    "â”‚    INPUT     â”‚\n",
    "â”‚              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚\n",
    "       â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      ğŸ¯ ORCHESTRATOR (LLM)                       â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  Responsibilities:                                               â”‚\n",
    "â”‚  â€¢ Analyze the input task                                       â”‚\n",
    "â”‚  â€¢ Decompose into subtasks                                      â”‚\n",
    "â”‚  â€¢ Create CUSTOMIZED instructions for each worker               â”‚\n",
    "â”‚  â€¢ Identify potential challenges or ambiguities                 â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  Output: Task-specific guidance for each worker                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                               â”‚\n",
    "                               â”‚ Customized Instructions\n",
    "                               â”‚\n",
    "       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "       â”‚                       â”‚                       â”‚\n",
    "       â–¼                       â–¼                       â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                 â”‚   â”‚                 â”‚   â”‚                 â”‚\n",
    "â”‚   WORKER A      â”‚   â”‚   WORKER B      â”‚   â”‚   WORKER C      â”‚\n",
    "â”‚     (LLM)       â”‚   â”‚     (LLM)       â”‚   â”‚     (LLM)       â”‚\n",
    "â”‚                 â”‚   â”‚                 â”‚   â”‚                 â”‚\n",
    "â”‚  Receives:      â”‚   â”‚  Receives:      â”‚   â”‚  Receives:      â”‚\n",
    "â”‚  â€¢ Original     â”‚   â”‚  â€¢ Original     â”‚   â”‚  â€¢ Original     â”‚\n",
    "â”‚    input        â”‚   â”‚    input        â”‚   â”‚    input        â”‚\n",
    "â”‚  â€¢ Custom       â”‚   â”‚  â€¢ Custom       â”‚   â”‚  â€¢ Custom       â”‚\n",
    "â”‚    instructions â”‚   â”‚    instructions â”‚   â”‚    instructions â”‚\n",
    "â”‚                 â”‚   â”‚                 â”‚   â”‚                 â”‚\n",
    "â”‚  Returns:       â”‚   â”‚  Returns:       â”‚   â”‚  Returns:       â”‚\n",
    "â”‚  â€¢ Analysis     â”‚   â”‚  â€¢ Analysis     â”‚   â”‚  â€¢ Analysis     â”‚\n",
    "â”‚  â€¢ Reasoning    â”‚   â”‚  â€¢ Reasoning    â”‚   â”‚  â€¢ Reasoning    â”‚\n",
    "â”‚                 â”‚   â”‚                 â”‚   â”‚                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚                     â”‚                     â”‚\n",
    "         â”‚     All workers can run in PARALLEL      â”‚\n",
    "         â”‚                     â”‚                     â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                               â”‚\n",
    "                               â”‚ All Worker Outputs\n",
    "                               â”‚\n",
    "                               â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      ğŸ”® SYNTHESIZER (LLM)                        â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  Responsibilities:                                               â”‚\n",
    "â”‚  â€¢ Review ALL worker outputs                                    â”‚\n",
    "â”‚  â€¢ Analyze agreements and conflicts                             â”‚\n",
    "â”‚  â€¢ Reason through discrepancies                                 â”‚\n",
    "â”‚  â€¢ Make final decision with full explanation                    â”‚\n",
    "â”‚  â€¢ Can override workers if reasoning is flawed                  â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  Output: Final result with reasoning                            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                               â”‚\n",
    "                               â–¼\n",
    "                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                        â”‚              â”‚\n",
    "                        â”‚    OUTPUT    â”‚\n",
    "                        â”‚              â”‚\n",
    "                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Advantages of Orchestrator-Worker\n",
    "\n",
    "| Aspect | Benefit |\n",
    "|--------|---------|\n",
    "| **Adaptive Coordination** | Orchestrator tailors instructions based on input |\n",
    "| **Intelligent Synthesis** | Synthesizer can reason through conflicts |\n",
    "| **Context Awareness** | Each stage can adapt to the specific situation |\n",
    "| **Explainability** | Full reasoning trail at every step |\n",
    "| **Edge Case Handling** | LLM reasoning handles nuances better than rules |\n",
    "\n",
    "### Trade-offs\n",
    "\n",
    "| Aspect | Consideration |\n",
    "|--------|---------------|\n",
    "| **Cost** | More LLM calls = higher API costs |\n",
    "| **Latency** | Sequential stages add latency |\n",
    "| **Complexity** | More components to design and debug |\n",
    "| **Consistency** | LLM reasoning can vary between runs |\n",
    "\n",
    "---\n",
    "\n",
    "### Execution Flow\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  INPUT  â”‚â”€â”€â”€â–¶â”‚ ORCHESTRATOR â”‚â”€â”€â”€â–¶â”‚ WORKERS â”‚â”€â”€â”€â–¶â”‚ SYNTHESIZER â”‚â”€â”€â”€â–¶â”‚ OUTPUT â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Stage 1         Stage 2           Stage 3\n",
    "                  (1 LLM call)   (N parallel calls)  (1 LLM call)\n",
    "\n",
    "Total LLM Calls: 1 + N + 1 = N + 2\n",
    "Total Latency: ~3 sequential stages (orchestrator â†’ workers â†’ synthesizer)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89516b",
   "metadata": {},
   "source": [
    "### Our Implementation: Orchestrator-Worker for AG News Classification\n",
    "\n",
    "For our AG News classification task, we'll implement the orchestrator-worker pattern with an LLM orchestrator, 4 category workers, and an LLM synthesizer.\n",
    "\n",
    "---\n",
    "\n",
    "#### Architecture Diagram\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           ORCHESTRATOR-WORKER FOR AG NEWS CLASSIFICATION                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  NEWS        â”‚\n",
    "â”‚  ARTICLE     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚\n",
    "       â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                 ğŸ¯ ORCHESTRATOR (gpt-5-mini)                     â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  â€¢ Analyzes the article content                                 â”‚\n",
    "â”‚  â€¢ Identifies key entities, topics, and signals                 â”‚\n",
    "â”‚  â€¢ Creates CUSTOMIZED hints for each worker                     â”‚\n",
    "â”‚  â€¢ Flags potential ambiguities                                  â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                               â”‚\n",
    "           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "           â”‚                   â”‚                   â”‚\n",
    "           â–¼                   â–¼                   â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ ğŸŒ WORLD        â”‚  â”‚ âš½ SPORTS       â”‚  â”‚ ğŸ’¼ BUSINESS     â”‚  â”‚ ğŸ”¬ SCI/TECH     â”‚\n",
    "â”‚    WORKER       â”‚  â”‚    WORKER       â”‚  â”‚    WORKER       â”‚  â”‚    WORKER       â”‚\n",
    "â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚\n",
    "â”‚ claude-haiku    â”‚  â”‚ claude-haiku    â”‚  â”‚ claude-haiku    â”‚  â”‚ claude-haiku    â”‚\n",
    "â”‚ -4-5-20251001   â”‚  â”‚ -4-5-20251001   â”‚  â”‚ -4-5-20251001   â”‚  â”‚ -4-5-20251001   â”‚\n",
    "â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚\n",
    "â”‚ Input:          â”‚  â”‚ Input:          â”‚  â”‚ Input:          â”‚  â”‚ Input:          â”‚\n",
    "â”‚ â€¢ Article       â”‚  â”‚ â€¢ Article       â”‚  â”‚ â€¢ Article       â”‚  â”‚ â€¢ Article       â”‚\n",
    "â”‚ â€¢ Custom hint   â”‚  â”‚ â€¢ Custom hint   â”‚  â”‚ â€¢ Custom hint   â”‚  â”‚ â€¢ Custom hint   â”‚\n",
    "â”‚   from orch.    â”‚  â”‚   from orch.    â”‚  â”‚   from orch.    â”‚  â”‚   from orch.    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚                    â”‚                    â”‚                    â”‚\n",
    "         â”‚              PARALLEL EXECUTION         â”‚                    â”‚\n",
    "         â”‚                    â”‚                    â”‚                    â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â”‚\n",
    "                              â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                   ğŸ”® SYNTHESIZER (gpt-5.1)                       â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  â€¢ Reviews orchestrator analysis                                â”‚\n",
    "â”‚  â€¢ Examines all 4 worker outputs                                â”‚\n",
    "â”‚  â€¢ Reasons through agreements/conflicts                         â”‚\n",
    "â”‚  â€¢ Makes final classification with explanation                  â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                               â”‚\n",
    "                               â–¼\n",
    "                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                        â”‚   FINAL      â”‚\n",
    "                        â”‚   CATEGORY   â”‚\n",
    "                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Models Used\n",
    "\n",
    "| Component | Model | Rationale |\n",
    "|-----------|-------|-----------|\n",
    "| Orchestrator | `gpt-5-mini` | Fast, good at analysis and instruction generation |\n",
    "| World Worker | `claude-haiku-4-5-20251001` | Fast, cost-effective for detection |\n",
    "| Sports Worker | `claude-haiku-4-5-20251001` | Fast, cost-effective for detection |\n",
    "| Business Worker | `claude-haiku-4-5-20251001` | Fast, cost-effective for detection |\n",
    "| Sci/Tech Worker | `claude-haiku-4-5-20251001` | Fast, cost-effective for detection |\n",
    "| Synthesizer | `gpt-5.1` | Powerful reasoning for conflict resolution |\n",
    "\n",
    "**Total LLM Calls per Article:** 6 (1 orchestrator + 4 workers + 1 synthesizer)\n",
    "\n",
    "---\n",
    "\n",
    "### Orchestrator (gpt-5-mini) ğŸ¯\n",
    "\n",
    "#### Input\n",
    "\n",
    "Raw news article text (same as other patterns).\n",
    "\n",
    "#### System Prompt\n",
    "\n",
    "```\n",
    "You are an intelligent orchestrator for a news classification system.\n",
    "\n",
    "Your task is to analyze a news article and prepare customized instructions for 4 specialized workers who will each evaluate whether the article belongs to their category:\n",
    "- World Worker: Evaluates World/Politics news\n",
    "- Sports Worker: Evaluates Sports news\n",
    "- Business Worker: Evaluates Business/Finance news\n",
    "- Sci/Tech Worker: Evaluates Science/Technology news\n",
    "\n",
    "Analyze the article and provide:\n",
    "1. A brief summary of the article's content\n",
    "2. Key entities mentioned (people, organizations, locations)\n",
    "3. Primary topics and themes\n",
    "4. Which categories seem most likely and why\n",
    "5. CUSTOMIZED hints for each worker - what specific aspects they should focus on\n",
    "\n",
    "Your hints should help workers make better decisions by:\n",
    "- Highlighting relevant evidence for their category\n",
    "- Warning about potential false positives (e.g., \"Apple\" could be tech OR business)\n",
    "- Pointing out ambiguities they should address\n",
    "\n",
    "Return your analysis as JSON.\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"summary\": \"Brief 1-2 sentence summary\",\n",
    "    \"key_entities\": [\"entity1\", \"entity2\", ...],\n",
    "    \"primary_topics\": [\"topic1\", \"topic2\", ...],\n",
    "    \"likely_categories\": [\"Category1\", \"Category2\"],\n",
    "    \"ambiguity_notes\": \"Any potential confusion between categories\",\n",
    "    \"worker_hints\": {\n",
    "        \"world\": \"Specific guidance for World worker\",\n",
    "        \"sports\": \"Specific guidance for Sports worker\",\n",
    "        \"business\": \"Specific guidance for Business worker\",\n",
    "        \"scitech\": \"Specific guidance for Sci/Tech worker\"\n",
    "    }\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Be concise but informative\n",
    "- Provide actionable hints, not just descriptions\n",
    "- Return ONLY valid JSON, no additional text\n",
    "```\n",
    "\n",
    "#### User Prompt Format\n",
    "\n",
    "```\n",
    "Analyze the following news article and prepare instructions for the classification workers:\n",
    "\n",
    "---\n",
    "[Article text]\n",
    "---\n",
    "```\n",
    "\n",
    "#### Output Format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"summary\": \"Apple announces new iPhone with advanced AI features at product launch event\",\n",
    "    \"key_entities\": [\"Apple\", \"iPhone\", \"Tim Cook\"],\n",
    "    \"primary_topics\": [\"product launch\", \"AI technology\", \"smartphones\"],\n",
    "    \"likely_categories\": [\"Sci/Tech\", \"Business\"],\n",
    "    \"ambiguity_notes\": \"Could be Sci/Tech (product features) or Business (company announcement). Focus on substance.\",\n",
    "    \"worker_hints\": {\n",
    "        \"world\": \"No political/government angle apparent. Quick assessment sufficient.\",\n",
    "        \"sports\": \"No sports connection. Quick negative assessment.\",\n",
    "        \"business\": \"Apple is a company, but check if focus is on stock/financials or product features. If product-focused, likely Sci/Tech.\",\n",
    "        \"scitech\": \"Primary candidate. Article describes technical features (AI, processor). Evaluate if tech substance dominates over business aspects.\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Workers (claude-haiku-4-5-20251001) ğŸŒâš½ğŸ’¼ğŸ”¬\n",
    "\n",
    "All 4 workers share the same structure but with category-specific system prompts.\n",
    "\n",
    "#### Input\n",
    "\n",
    "- Original article text\n",
    "- Orchestrator's customized hint for this worker\n",
    "\n",
    "#### System Prompt (World Worker Example)\n",
    "\n",
    "```\n",
    "You are a WORLD NEWS DETECTOR working as part of a classification team.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"World\" category.\n",
    "\n",
    "The \"World\" category includes:\n",
    "- International politics and diplomacy\n",
    "- Government policies, elections, and political events\n",
    "- Military conflicts, wars, and peacekeeping\n",
    "- Humanitarian crises and global health issues\n",
    "- International organizations (UN, NATO, EU, WHO, etc.)\n",
    "\n",
    "You will receive:\n",
    "1. The news article\n",
    "2. A hint from the orchestrator with specific guidance for your evaluation\n",
    "\n",
    "Use the orchestrator's hint to focus your analysis, but make your own independent judgment.\n",
    "\n",
    "Return your assessment as JSON.\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Your analysis explaining your decision\",\n",
    "    \"orchestrator_hint_addressed\": \"How you considered the orchestrator's guidance\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Make an independent judgment based on the article content\n",
    "- Use the orchestrator's hint as guidance, not as the answer\n",
    "- Return ONLY valid JSON, no additional text\n",
    "```\n",
    "\n",
    "#### User Prompt Format\n",
    "\n",
    "```\n",
    "Evaluate if this article belongs to the WORLD category.\n",
    "\n",
    "ORCHESTRATOR'S HINT FOR YOU:\n",
    "[Orchestrator's hint for this worker]\n",
    "\n",
    "ARTICLE:\n",
    "---\n",
    "[Article text]\n",
    "---\n",
    "```\n",
    "\n",
    "#### Output Format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"belongs_to_category\": false,\n",
    "    \"confidence\": 0.15,\n",
    "    \"reasoning\": \"Article focuses on Apple's product announcement with AI features. No political, diplomatic, or international affairs content present.\",\n",
    "    \"orchestrator_hint_addressed\": \"Orchestrator correctly identified no political angle. Confirmed with quick assessment.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Synthesizer (gpt-5.1) ğŸ”®\n",
    "\n",
    "#### Input\n",
    "\n",
    "- Original article text\n",
    "- Orchestrator's full analysis\n",
    "- All 4 worker outputs\n",
    "\n",
    "#### System Prompt\n",
    "\n",
    "```\n",
    "You are the final decision-maker in a news classification system.\n",
    "\n",
    "You will receive:\n",
    "1. The original news article\n",
    "2. The orchestrator's analysis (summary, key entities, likely categories, hints given)\n",
    "3. Outputs from 4 specialized workers (World, Sports, Business, Sci/Tech)\n",
    "\n",
    "Each worker has evaluated whether the article belongs to their category and provided:\n",
    "- belongs_to_category: true/false\n",
    "- confidence: 0.0-1.0\n",
    "- reasoning: their analysis\n",
    "\n",
    "Your task is to synthesize all this information and make the FINAL classification decision.\n",
    "\n",
    "Consider:\n",
    "- Which workers claimed the article and with what confidence?\n",
    "- Are there conflicts? If so, whose reasoning is more compelling?\n",
    "- Does the orchestrator's analysis align with worker assessments?\n",
    "- What is the PRIMARY focus of the article?\n",
    "\n",
    "You may OVERRIDE a worker's claim if their reasoning is flawed.\n",
    "\n",
    "Return your final decision as JSON.\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"classification\": \"World\" | \"Sports\" | \"Business\" | \"Sci/Tech\",\n",
    "    \"confidence\": \"high\" | \"medium\" | \"low\",\n",
    "    \"reasoning\": \"Detailed explanation of your decision\",\n",
    "    \"worker_agreement_summary\": \"Which workers agreed/disagreed and why\",\n",
    "    \"conflict_resolution\": \"If there were conflicts, how you resolved them\",\n",
    "    \"orchestrator_alignment\": \"Whether your decision aligns with orchestrator's prediction\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- You MUST choose exactly ONE category\n",
    "- Provide clear reasoning for your decision\n",
    "- If overriding a worker, explain why\n",
    "- Return ONLY valid JSON, no additional text\n",
    "```\n",
    "\n",
    "#### User Prompt Format\n",
    "\n",
    "```\n",
    "Make the final classification decision based on all available information.\n",
    "\n",
    "ORIGINAL ARTICLE:\n",
    "---\n",
    "[Article text]\n",
    "---\n",
    "\n",
    "ORCHESTRATOR ANALYSIS:\n",
    "[JSON of orchestrator output]\n",
    "\n",
    "WORKER OUTPUTS:\n",
    "\n",
    "WORLD WORKER:\n",
    "[JSON of world worker output]\n",
    "\n",
    "SPORTS WORKER:\n",
    "[JSON of sports worker output]\n",
    "\n",
    "BUSINESS WORKER:\n",
    "[JSON of business worker output]\n",
    "\n",
    "SCI/TECH WORKER:\n",
    "[JSON of scitech worker output]\n",
    "```\n",
    "\n",
    "#### Output Format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"classification\": \"Sci/Tech\",\n",
    "    \"confidence\": \"high\",\n",
    "    \"reasoning\": \"The article's primary focus is on technological features - AI capabilities, processor improvements, and product functionality. While Apple is a business entity, the substance of this article is about technology, not financials or corporate strategy.\",\n",
    "    \"worker_agreement_summary\": \"Sci/Tech worker (claimed, 0.92 confidence) and Business worker (claimed, 0.65 confidence) both identified relevant signals. Sports and World workers correctly declined.\",\n",
    "    \"conflict_resolution\": \"Both Sci/Tech and Business workers claimed the article. Sci/Tech worker's reasoning about technical features being the primary focus is more compelling than Business worker's reasoning about company announcement. The article describes WHAT the product does, not its financial implications.\",\n",
    "    \"orchestrator_alignment\": \"Aligned. Orchestrator identified Sci/Tech as primary candidate and correctly noted the tech-vs-business ambiguity.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Component | Model | Input | Output |\n",
    "|-----------|-------|-------|--------|\n",
    "| **Orchestrator** | `gpt-5-mini` | Article text | Analysis + worker hints |\n",
    "| **World Worker** | `claude-haiku-4-5-20251001` | Article + hint | Detection result |\n",
    "| **Sports Worker** | `claude-haiku-4-5-20251001` | Article + hint | Detection result |\n",
    "| **Business Worker** | `claude-haiku-4-5-20251001` | Article + hint | Detection result |\n",
    "| **Sci/Tech Worker** | `claude-haiku-4-5-20251001` | Article + hint | Detection result |\n",
    "| **Synthesizer** | `gpt-5.1` | Article + orchestrator + all workers | Final classification |\n",
    "\n",
    "**Execution Flow:**\n",
    "1. Orchestrator analyzes article â†’ produces hints (1 LLM call)\n",
    "2. 4 Workers evaluate in parallel â†’ produce assessments (4 LLM calls, parallel)\n",
    "3. Synthesizer makes final decision â†’ produces classification (1 LLM call)\n",
    "\n",
    "**Total: 6 LLM calls per article** (with workers running in parallel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "767d7b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ORCHESTRATOR-WORKER DESIGN PATTERN - Classification\n",
      "======================================================================\n",
      "\n",
      "Processing 100 samples using orchestrator-worker pattern...\n",
      "Pipeline: Orchestrator (gpt-5-mini) â†’ 4 Workers (Claude Haiku, parallel) â†’ Synthesizer (gpt-5.1)\n",
      "âš ï¸  Rate limiting enabled: ~5.3s delay between articles to stay under API limits.\n",
      "\n",
      "  âœ“ Processed 10/100 articles (10.0%)\n",
      "  âœ“ Processed 20/100 articles (20.0%)\n",
      "  âœ“ Processed 30/100 articles (30.0%)\n",
      "  âœ“ Processed 40/100 articles (40.0%)\n",
      "  âœ“ Processed 50/100 articles (50.0%)\n",
      "  âœ“ Processed 60/100 articles (60.0%)\n",
      "  âœ“ Processed 70/100 articles (70.0%)\n",
      "  âœ“ Processed 80/100 articles (80.0%)\n",
      "  âœ“ Processed 90/100 articles (90.0%)\n",
      "  âœ“ Processed 100/100 articles (100.0%)\n",
      "\n",
      "======================================================================\n",
      "ORCHESTRATOR-WORKER RESULTS (showing first 3 of 100)\n",
      "======================================================================\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 1\n",
      "Ground Truth: Business\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“‹ Orchestrator Analysis:\n",
      "   Summary: Unions representing workers at Turner & Newall say they are 'disappointed' after talks with the comp...\n",
      "   Likely Categories: ['Business', 'World/Politics']\n",
      "\n",
      "ğŸ‘· Worker Votes:\n",
      "   WORLD     : âœ— (conf: 0.85)\n",
      "   SCITECH   : âœ— (conf: 0.95)\n",
      "   SPORTS    : âœ— (conf: 0.98)\n",
      "   BUSINESS  : âœ“ (conf: 0.85)\n",
      "\n",
      "ğŸ”® Synthesizer Decision:\n",
      "   Classification: Business\n",
      "   Confidence: high\n",
      "   Result: âœ“ CORRECT\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 2\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“‹ Orchestrator Analysis:\n",
      "   Summary: ...\n",
      "   Likely Categories: []\n",
      "\n",
      "ğŸ‘· Worker Votes:\n",
      "   WORLD     : âœ— (conf: 0.95)\n",
      "   SCITECH   : âœ“ (conf: 0.95)\n",
      "   SPORTS    : âœ— (conf: 0.95)\n",
      "   BUSINESS  : âœ“ (conf: 0.72)\n",
      "\n",
      "ğŸ”® Synthesizer Decision:\n",
      "   Classification: Sci/Tech\n",
      "   Confidence: high\n",
      "   Result: âœ“ CORRECT\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 3\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“‹ Orchestrator Analysis:\n",
      "   Summary: A Kentucky company, founded by a chemistry researcher from the University of Louisville, received a ...\n",
      "   Likely Categories: ['Sci/Tech', 'Business']\n",
      "\n",
      "ğŸ‘· Worker Votes:\n",
      "   WORLD     : âœ— (conf: 0.95)\n",
      "   BUSINESS  : âœ— (conf: 0.75)\n",
      "   SCITECH   : âœ“ (conf: 0.92)\n",
      "   SPORTS    : âœ— (conf: 0.92)\n",
      "\n",
      "ğŸ”® Synthesizer Decision:\n",
      "   Classification: Sci/Tech\n",
      "   Confidence: high\n",
      "   Result: âœ“ CORRECT\n",
      "\n",
      "======================================================================\n",
      "Orchestrator-Worker complete. 100 results stored in 'orchestrator_worker_results'\n",
      "Ready for evaluation.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ORCHESTRATOR-WORKER DESIGN PATTERN IMPLEMENTATION\n",
    "# ============================================================\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# Rate limiting: 4 Anthropic calls per article (workers), 2 OpenAI calls (orchestrator + synthesizer)\n",
    "# Anthropic has 50 requests/minute limit\n",
    "# With 4 parallel Anthropic requests per article, we can process ~12 articles/minute\n",
    "REQUESTS_PER_ARTICLE_ANTHROPIC = 4\n",
    "RATE_LIMIT_PER_MINUTE = 50\n",
    "MIN_SECONDS_PER_ARTICLE = (REQUESTS_PER_ARTICLE_ANTHROPIC / RATE_LIMIT_PER_MINUTE) * 60 + 0.5  # ~5.3 seconds\n",
    "\n",
    "# ============================================================\n",
    "# ORCHESTRATOR (gpt-5-mini)\n",
    "# ============================================================\n",
    "\n",
    "ORCHESTRATOR_SYSTEM_PROMPT = \"\"\"You are an intelligent orchestrator for a news classification system.\n",
    "\n",
    "Your task is to analyze a news article and prepare customized instructions for 4 specialized workers who will each evaluate whether the article belongs to their category:\n",
    "- World Worker: Evaluates World/Politics news\n",
    "- Sports Worker: Evaluates Sports news\n",
    "- Business Worker: Evaluates Business/Finance news\n",
    "- Sci/Tech Worker: Evaluates Science/Technology news\n",
    "\n",
    "Analyze the article and provide:\n",
    "1. A brief summary of the article's content\n",
    "2. Key entities mentioned (people, organizations, locations)\n",
    "3. Primary topics and themes\n",
    "4. Which categories seem most likely and why\n",
    "5. CUSTOMIZED hints for each worker - what specific aspects they should focus on\n",
    "\n",
    "Your hints should help workers make better decisions by:\n",
    "- Highlighting relevant evidence for their category\n",
    "- Warning about potential false positives (e.g., \"Apple\" could be tech OR business)\n",
    "- Pointing out ambiguities they should address\n",
    "\n",
    "Return your analysis as JSON.\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"summary\": \"Brief 1-2 sentence summary\",\n",
    "    \"key_entities\": [\"entity1\", \"entity2\", ...],\n",
    "    \"primary_topics\": [\"topic1\", \"topic2\", ...],\n",
    "    \"likely_categories\": [\"Category1\", \"Category2\"],\n",
    "    \"ambiguity_notes\": \"Any potential confusion between categories\",\n",
    "    \"worker_hints\": {\n",
    "        \"world\": \"Specific guidance for World worker\",\n",
    "        \"sports\": \"Specific guidance for Sports worker\",\n",
    "        \"business\": \"Specific guidance for Business worker\",\n",
    "        \"scitech\": \"Specific guidance for Sci/Tech worker\"\n",
    "    }\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Be concise but informative\n",
    "- Provide actionable hints, not just descriptions\n",
    "- Return ONLY valid JSON, no additional text\"\"\"\n",
    "\n",
    "def run_orchestrator(article_text: str) -> dict:\n",
    "    \"\"\"Run the orchestrator to analyze article and generate worker hints.\"\"\"\n",
    "    user_prompt = f\"\"\"Analyze the following news article and prepare instructions for the classification workers:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        max_completion_tokens=2048,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": ORCHESTRATOR_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    response_text = response.choices[0].message.content\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"error\": \"Failed to parse orchestrator response\",\n",
    "            \"raw_response\": response_text,\n",
    "            \"summary\": \"\",\n",
    "            \"key_entities\": [],\n",
    "            \"primary_topics\": [],\n",
    "            \"likely_categories\": [],\n",
    "            \"ambiguity_notes\": \"\",\n",
    "            \"worker_hints\": {\n",
    "                \"world\": \"Evaluate if this is World news.\",\n",
    "                \"sports\": \"Evaluate if this is Sports news.\",\n",
    "                \"business\": \"Evaluate if this is Business news.\",\n",
    "                \"scitech\": \"Evaluate if this is Sci/Tech news.\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "# ============================================================\n",
    "# WORLD WORKER (claude-haiku-4-5-20251001)\n",
    "# ============================================================\n",
    "\n",
    "WORLD_WORKER_SYSTEM_PROMPT = \"\"\"You are a WORLD NEWS DETECTOR working as part of a classification team.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"World\" category.\n",
    "\n",
    "The \"World\" category includes:\n",
    "- International politics and diplomacy\n",
    "- Government policies, elections, and political events\n",
    "- Military conflicts, wars, and peacekeeping\n",
    "- Humanitarian crises and global health issues\n",
    "- International organizations (UN, NATO, EU, WHO, etc.)\n",
    "\n",
    "You will receive:\n",
    "1. The news article\n",
    "2. A hint from the orchestrator with specific guidance for your evaluation\n",
    "\n",
    "Use the orchestrator's hint to focus your analysis, but make your own independent judgment.\n",
    "\n",
    "Return your assessment as JSON.\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Your analysis explaining your decision\",\n",
    "    \"orchestrator_hint_addressed\": \"How you considered the orchestrator's guidance\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Make an independent judgment based on the article content\n",
    "- Use the orchestrator's hint as guidance, not as the answer\n",
    "- Return ONLY valid JSON, no additional text\"\"\"\n",
    "\n",
    "def run_world_worker(article_text: str, orchestrator_hint: str) -> dict:\n",
    "    \"\"\"World worker: Detect if article belongs to World category.\"\"\"\n",
    "    user_prompt = f\"\"\"Evaluate if this article belongs to the WORLD category.\n",
    "\n",
    "ORCHESTRATOR'S HINT FOR YOU:\n",
    "{orchestrator_hint}\n",
    "\n",
    "ARTICLE:\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        max_tokens=512,\n",
    "        system=WORLD_WORKER_SYSTEM_PROMPT,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    \n",
    "    response_text = response.content[0].text\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(cleaned)\n",
    "        result['category'] = 'World'\n",
    "        return result\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"belongs_to_category\": False, \"confidence\": 0, \"reasoning\": \"Parse error\", \n",
    "                \"orchestrator_hint_addressed\": \"N/A\", \"category\": \"World\"}\n",
    "\n",
    "# ============================================================\n",
    "# SPORTS WORKER (claude-haiku-4-5-20251001)\n",
    "# ============================================================\n",
    "\n",
    "SPORTS_WORKER_SYSTEM_PROMPT = \"\"\"You are a SPORTS NEWS DETECTOR working as part of a classification team.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"Sports\" category.\n",
    "\n",
    "The \"Sports\" category includes:\n",
    "- Professional and amateur athletic competitions\n",
    "- Sports teams, players, coaches, and athletes\n",
    "- Game results, scores, standings, and statistics\n",
    "- Sports leagues (NFL, NBA, MLB, NHL, FIFA, etc.)\n",
    "- Olympic games and international sports competitions\n",
    "- Sports trades, contracts, and team management\n",
    "\n",
    "You will receive:\n",
    "1. The news article\n",
    "2. A hint from the orchestrator with specific guidance for your evaluation\n",
    "\n",
    "Use the orchestrator's hint to focus your analysis, but make your own independent judgment.\n",
    "\n",
    "Return your assessment as JSON.\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Your analysis explaining your decision\",\n",
    "    \"orchestrator_hint_addressed\": \"How you considered the orchestrator's guidance\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Make an independent judgment based on the article content\n",
    "- Use the orchestrator's hint as guidance, not as the answer\n",
    "- Return ONLY valid JSON, no additional text\"\"\"\n",
    "\n",
    "def run_sports_worker(article_text: str, orchestrator_hint: str) -> dict:\n",
    "    \"\"\"Sports worker: Detect if article belongs to Sports category.\"\"\"\n",
    "    user_prompt = f\"\"\"Evaluate if this article belongs to the SPORTS category.\n",
    "\n",
    "ORCHESTRATOR'S HINT FOR YOU:\n",
    "{orchestrator_hint}\n",
    "\n",
    "ARTICLE:\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        max_tokens=512,\n",
    "        system=SPORTS_WORKER_SYSTEM_PROMPT,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    \n",
    "    response_text = response.content[0].text\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(cleaned)\n",
    "        result['category'] = 'Sports'\n",
    "        return result\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"belongs_to_category\": False, \"confidence\": 0, \"reasoning\": \"Parse error\", \n",
    "                \"orchestrator_hint_addressed\": \"N/A\", \"category\": \"Sports\"}\n",
    "\n",
    "# ============================================================\n",
    "# BUSINESS WORKER (claude-haiku-4-5-20251001)\n",
    "# ============================================================\n",
    "\n",
    "BUSINESS_WORKER_SYSTEM_PROMPT = \"\"\"You are a BUSINESS NEWS DETECTOR working as part of a classification team.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"Business\" category.\n",
    "\n",
    "The \"Business\" category includes:\n",
    "- Stock markets, trading, and investments\n",
    "- Company earnings, revenue, and financial reports\n",
    "- Mergers, acquisitions, and corporate restructuring\n",
    "- Economic indicators (GDP, inflation, employment)\n",
    "- Corporate leadership and executive changes\n",
    "- Industry analysis and market trends\n",
    "- Banking, finance, and monetary policy\n",
    "\n",
    "You will receive:\n",
    "1. The news article\n",
    "2. A hint from the orchestrator with specific guidance for your evaluation\n",
    "\n",
    "Use the orchestrator's hint to focus your analysis, but make your own independent judgment.\n",
    "\n",
    "Return your assessment as JSON.\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Your analysis explaining your decision\",\n",
    "    \"orchestrator_hint_addressed\": \"How you considered the orchestrator's guidance\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Make an independent judgment based on the article content\n",
    "- Use the orchestrator's hint as guidance, not as the answer\n",
    "- Return ONLY valid JSON, no additional text\"\"\"\n",
    "\n",
    "def run_business_worker(article_text: str, orchestrator_hint: str) -> dict:\n",
    "    \"\"\"Business worker: Detect if article belongs to Business category.\"\"\"\n",
    "    user_prompt = f\"\"\"Evaluate if this article belongs to the BUSINESS category.\n",
    "\n",
    "ORCHESTRATOR'S HINT FOR YOU:\n",
    "{orchestrator_hint}\n",
    "\n",
    "ARTICLE:\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        max_tokens=512,\n",
    "        system=BUSINESS_WORKER_SYSTEM_PROMPT,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    \n",
    "    response_text = response.content[0].text\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(cleaned)\n",
    "        result['category'] = 'Business'\n",
    "        return result\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"belongs_to_category\": False, \"confidence\": 0, \"reasoning\": \"Parse error\", \n",
    "                \"orchestrator_hint_addressed\": \"N/A\", \"category\": \"Business\"}\n",
    "\n",
    "# ============================================================\n",
    "# SCI/TECH WORKER (claude-haiku-4-5-20251001)\n",
    "# ============================================================\n",
    "\n",
    "SCITECH_WORKER_SYSTEM_PROMPT = \"\"\"You are a SCIENCE & TECHNOLOGY NEWS DETECTOR working as part of a classification team.\n",
    "\n",
    "Your task is to determine if a news article belongs to the \"Sci/Tech\" category.\n",
    "\n",
    "The \"Sci/Tech\" category includes:\n",
    "- Technology products, software, and hardware\n",
    "- Scientific research and discoveries\n",
    "- Internet, social media, and digital platforms\n",
    "- AI, machine learning, and emerging technologies\n",
    "- Space exploration and astronomy\n",
    "- Medical and health research breakthroughs\n",
    "- Environmental science and climate research\n",
    "- Consumer electronics and gadgets\n",
    "\n",
    "You will receive:\n",
    "1. The news article\n",
    "2. A hint from the orchestrator with specific guidance for your evaluation\n",
    "\n",
    "Use the orchestrator's hint to focus your analysis, but make your own independent judgment.\n",
    "\n",
    "Return your assessment as JSON.\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"belongs_to_category\": true | false,\n",
    "    \"confidence\": 0.0 to 1.0,\n",
    "    \"reasoning\": \"Your analysis explaining your decision\",\n",
    "    \"orchestrator_hint_addressed\": \"How you considered the orchestrator's guidance\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Make an independent judgment based on the article content\n",
    "- Use the orchestrator's hint as guidance, not as the answer\n",
    "- Return ONLY valid JSON, no additional text\"\"\"\n",
    "\n",
    "def run_scitech_worker(article_text: str, orchestrator_hint: str) -> dict:\n",
    "    \"\"\"Sci/Tech worker: Detect if article belongs to Sci/Tech category.\"\"\"\n",
    "    user_prompt = f\"\"\"Evaluate if this article belongs to the SCI/TECH category.\n",
    "\n",
    "ORCHESTRATOR'S HINT FOR YOU:\n",
    "{orchestrator_hint}\n",
    "\n",
    "ARTICLE:\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        max_tokens=512,\n",
    "        system=SCITECH_WORKER_SYSTEM_PROMPT,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    \n",
    "    response_text = response.content[0].text\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(cleaned)\n",
    "        result['category'] = 'Sci/Tech'\n",
    "        return result\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"belongs_to_category\": False, \"confidence\": 0, \"reasoning\": \"Parse error\", \n",
    "                \"orchestrator_hint_addressed\": \"N/A\", \"category\": \"Sci/Tech\"}\n",
    "\n",
    "# ============================================================\n",
    "# SYNTHESIZER (gpt-5.1)\n",
    "# ============================================================\n",
    "\n",
    "SYNTHESIZER_SYSTEM_PROMPT = \"\"\"You are the final decision-maker in a news classification system.\n",
    "\n",
    "You will receive:\n",
    "1. The original news article\n",
    "2. The orchestrator's analysis (summary, key entities, likely categories, hints given)\n",
    "3. Outputs from 4 specialized workers (World, Sports, Business, Sci/Tech)\n",
    "\n",
    "Each worker has evaluated whether the article belongs to their category and provided:\n",
    "- belongs_to_category: true/false\n",
    "- confidence: 0.0-1.0\n",
    "- reasoning: their analysis\n",
    "\n",
    "Your task is to synthesize all this information and make the FINAL classification decision.\n",
    "\n",
    "Consider:\n",
    "- Which workers claimed the article and with what confidence?\n",
    "- Are there conflicts? If so, whose reasoning is more compelling?\n",
    "- Does the orchestrator's analysis align with worker assessments?\n",
    "- What is the PRIMARY focus of the article?\n",
    "\n",
    "You may OVERRIDE a worker's claim if their reasoning is flawed.\n",
    "\n",
    "Return your final decision as JSON.\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"classification\": \"World\" | \"Sports\" | \"Business\" | \"Sci/Tech\",\n",
    "    \"confidence\": \"high\" | \"medium\" | \"low\",\n",
    "    \"reasoning\": \"Detailed explanation of your decision\",\n",
    "    \"worker_agreement_summary\": \"Which workers agreed/disagreed and why\",\n",
    "    \"conflict_resolution\": \"If there were conflicts, how you resolved them\",\n",
    "    \"orchestrator_alignment\": \"Whether your decision aligns with orchestrator's prediction\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- You MUST choose exactly ONE category\n",
    "- Provide clear reasoning for your decision\n",
    "- If overriding a worker, explain why\n",
    "- Return ONLY valid JSON, no additional text\"\"\"\n",
    "\n",
    "def run_synthesizer(article_text: str, orchestrator_output: dict, worker_outputs: dict) -> dict:\n",
    "    \"\"\"Synthesizer: Make final classification decision based on all outputs.\"\"\"\n",
    "    user_prompt = f\"\"\"Make the final classification decision based on all available information.\n",
    "\n",
    "ORIGINAL ARTICLE:\n",
    "---\n",
    "{article_text}\n",
    "---\n",
    "\n",
    "ORCHESTRATOR ANALYSIS:\n",
    "{json.dumps(orchestrator_output, indent=2)}\n",
    "\n",
    "WORKER OUTPUTS:\n",
    "\n",
    "WORLD WORKER:\n",
    "{json.dumps(worker_outputs['world'], indent=2)}\n",
    "\n",
    "SPORTS WORKER:\n",
    "{json.dumps(worker_outputs['sports'], indent=2)}\n",
    "\n",
    "BUSINESS WORKER:\n",
    "{json.dumps(worker_outputs['business'], indent=2)}\n",
    "\n",
    "SCI/TECH WORKER:\n",
    "{json.dumps(worker_outputs['scitech'], indent=2)}\"\"\"\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-5.1\",\n",
    "        max_completion_tokens=1024,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYNTHESIZER_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    response_text = response.choices[0].message.content\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"error\": \"Failed to parse synthesizer response\",\n",
    "            \"raw_response\": response_text,\n",
    "            \"classification\": \"Unknown\",\n",
    "            \"confidence\": \"low\",\n",
    "            \"reasoning\": \"Parse error\",\n",
    "            \"worker_agreement_summary\": \"N/A\",\n",
    "            \"conflict_resolution\": \"N/A\",\n",
    "            \"orchestrator_alignment\": \"N/A\"\n",
    "        }\n",
    "\n",
    "# ============================================================\n",
    "# ORCHESTRATOR-WORKER PIPELINE\n",
    "# ============================================================\n",
    "\n",
    "def orchestrator_worker_classify(article_text: str) -> dict:\n",
    "    \"\"\"Full orchestrator-worker pipeline: orchestrator â†’ workers (parallel) â†’ synthesizer.\"\"\"\n",
    "    \n",
    "    # Stage 1: Orchestrator analyzes article and generates hints\n",
    "    orchestrator_output = run_orchestrator(article_text)\n",
    "    \n",
    "    # Extract hints for each worker (with fallbacks)\n",
    "    worker_hints = orchestrator_output.get('worker_hints', {})\n",
    "    world_hint = worker_hints.get('world', 'Evaluate if this is World news.')\n",
    "    sports_hint = worker_hints.get('sports', 'Evaluate if this is Sports news.')\n",
    "    business_hint = worker_hints.get('business', 'Evaluate if this is Business news.')\n",
    "    scitech_hint = worker_hints.get('scitech', 'Evaluate if this is Sci/Tech news.')\n",
    "    \n",
    "    # Stage 2: Run all 4 workers in parallel\n",
    "    worker_outputs = {}\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        # Submit all worker tasks\n",
    "        futures = {\n",
    "            executor.submit(run_world_worker, article_text, world_hint): \"world\",\n",
    "            executor.submit(run_sports_worker, article_text, sports_hint): \"sports\",\n",
    "            executor.submit(run_business_worker, article_text, business_hint): \"business\",\n",
    "            executor.submit(run_scitech_worker, article_text, scitech_hint): \"scitech\"\n",
    "        }\n",
    "        \n",
    "        # Collect results\n",
    "        for future in as_completed(futures):\n",
    "            worker_name = futures[future]\n",
    "            worker_outputs[worker_name] = future.result()\n",
    "    \n",
    "    # Stage 3: Synthesizer makes final decision\n",
    "    synthesizer_output = run_synthesizer(article_text, orchestrator_output, worker_outputs)\n",
    "    \n",
    "    return {\n",
    "        \"orchestrator_output\": orchestrator_output,\n",
    "        \"worker_outputs\": worker_outputs,\n",
    "        \"synthesizer_output\": synthesizer_output\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# PROCESS ALL TEST DATA\n",
    "# ============================================================\n",
    "\n",
    "# Store orchestrator-worker results\n",
    "orchestrator_worker_results = []\n",
    "\n",
    "# Number of results to print\n",
    "NUM_TO_PRINT = 3\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ORCHESTRATOR-WORKER DESIGN PATTERN - Classification\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nProcessing {NUM_SAMPLES} samples using orchestrator-worker pattern...\")\n",
    "print(f\"Pipeline: Orchestrator (gpt-5-mini) â†’ 4 Workers (Claude Haiku, parallel) â†’ Synthesizer (gpt-5.1)\")\n",
    "print(f\"âš ï¸  Rate limiting enabled: ~{MIN_SECONDS_PER_ARTICLE:.1f}s delay between articles to stay under API limits.\\n\")\n",
    "\n",
    "# Progress tracking\n",
    "PROGRESS_INTERVAL = 10\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sample = test_data[i]\n",
    "    article_text = sample['text']\n",
    "    ground_truth_label = sample['label']\n",
    "    \n",
    "    # Run the orchestrator-worker pipeline\n",
    "    result = orchestrator_worker_classify(article_text)\n",
    "    \n",
    "    # Store result with metadata\n",
    "    orchestrator_worker_results.append({\n",
    "        \"index\": i,\n",
    "        \"original_text\": article_text,\n",
    "        \"ground_truth_label\": ground_truth_label,\n",
    "        \"ground_truth_name\": label_names[ground_truth_label],\n",
    "        \"orchestrator_output\": result[\"orchestrator_output\"],\n",
    "        \"worker_outputs\": result[\"worker_outputs\"],\n",
    "        \"synthesizer_output\": result[\"synthesizer_output\"]\n",
    "    })\n",
    "    \n",
    "    # Print progress\n",
    "    if (i + 1) % PROGRESS_INTERVAL == 0 or (i + 1) == NUM_SAMPLES:\n",
    "        print(f\"  âœ“ Processed {i + 1}/{NUM_SAMPLES} articles ({(i + 1) / NUM_SAMPLES * 100:.1f}%)\")\n",
    "    \n",
    "    # Rate limiting: ensure minimum time between articles\n",
    "    elapsed = time.time() - start_time\n",
    "    if elapsed < MIN_SECONDS_PER_ARTICLE and i < NUM_SAMPLES - 1:\n",
    "        sleep_time = MIN_SECONDS_PER_ARTICLE - elapsed\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "# ============================================================\n",
    "# PRINT SAMPLE RESULTS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"ORCHESTRATOR-WORKER RESULTS (showing first {NUM_TO_PRINT} of {len(orchestrator_worker_results)})\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i in range(min(NUM_TO_PRINT, len(orchestrator_worker_results))):\n",
    "    result = orchestrator_worker_results[i]\n",
    "    synth = result['synthesizer_output']\n",
    "    orch = result['orchestrator_output']\n",
    "    \n",
    "    print(\"â”€\" * 70)\n",
    "    print(f\"Article {i + 1}\")\n",
    "    print(f\"Ground Truth: {result['ground_truth_name']}\")\n",
    "    print(\"â”€\" * 70)\n",
    "    \n",
    "    # Orchestrator summary\n",
    "    print(f\"\\nğŸ“‹ Orchestrator Analysis:\")\n",
    "    print(f\"   Summary: {orch.get('summary', 'N/A')[:100]}...\")\n",
    "    print(f\"   Likely Categories: {orch.get('likely_categories', [])}\")\n",
    "    \n",
    "    # Worker votes\n",
    "    print(f\"\\nğŸ‘· Worker Votes:\")\n",
    "    for worker_name, worker_result in result['worker_outputs'].items():\n",
    "        claimed = \"âœ“\" if worker_result.get('belongs_to_category', False) else \"âœ—\"\n",
    "        conf = worker_result.get('confidence', 0)\n",
    "        print(f\"   {worker_name.upper():10}: {claimed} (conf: {conf:.2f})\")\n",
    "    \n",
    "    # Synthesizer decision\n",
    "    predicted = synth.get('classification', 'N/A')\n",
    "    confidence = synth.get('confidence', 'N/A')\n",
    "    is_correct = predicted == result['ground_truth_name']\n",
    "    status = \"âœ“ CORRECT\" if is_correct else \"âœ— INCORRECT\"\n",
    "    \n",
    "    print(f\"\\nğŸ”® Synthesizer Decision:\")\n",
    "    print(f\"   Classification: {predicted}\")\n",
    "    print(f\"   Confidence: {confidence}\")\n",
    "    print(f\"   Result: {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Orchestrator-Worker complete. {len(orchestrator_worker_results)} results stored in 'orchestrator_worker_results'\")\n",
    "print(\"Ready for evaluation.\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4900315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ORCHESTRATOR-WORKER DESIGN PATTERN - EVALUATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "OVERALL METRICS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Total Samples:     100\n",
      "  Valid Predictions: 100\n",
      "  Error Rate:        0.0%\n",
      "\n",
      "  ğŸ“Š Accuracy:        0.8000  (80.0%)\n",
      "\n",
      "  Macro Averages (treats all classes equally):\n",
      "     Precision:      0.8134\n",
      "     Recall:         0.8550\n",
      "     F1 Score:       0.7924\n",
      "\n",
      "  Weighted Averages (accounts for class imbalance):\n",
      "     Precision:      0.8842\n",
      "     Recall:         0.8000\n",
      "     F1 Score:       0.8071\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "PER-CLASS METRICS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.90      0.90      0.90        30\n",
      "      Sports       0.91      0.95      0.93        21\n",
      "    Business       0.44      1.00      0.62        12\n",
      "    Sci/Tech       1.00      0.57      0.72        37\n",
      "\n",
      "    accuracy                           0.80       100\n",
      "   macro avg       0.81      0.85      0.79       100\n",
      "weighted avg       0.88      0.80      0.81       100\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CONFUSION MATRIX\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Predicted â†’     World    Sports  Business  Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Actual â†“\n",
      "          World        27         2         1         0\n",
      "         Sports         1        20         0         0\n",
      "       Business         0         0        12         0\n",
      "       Sci/Tech         2         0        14        21\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DISTRIBUTION ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Category        Ground Truth       Predicted   Difference\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "World                     30              30            0\n",
      "Sports                    21              22           +1\n",
      "Business                  12              27          +15\n",
      "Sci/Tech                  37              21          -16\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ORCHESTRATOR ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Orchestrator Prediction Accuracy:\n",
      "    Ground truth in likely_categories: 64/98 (65.3%)\n",
      "    First choice correct:              51/98 (52.0%)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "WORKER ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Number of Workers Claiming Article:\n",
      "      Claims      Count   Percentage\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "           0         14        14.0%\n",
      "           1         79        79.0%\n",
      "           2          7         7.0%\n",
      "\n",
      "  Per-Worker Claim Statistics:\n",
      "  Worker          Claimed    Correct     Accuracy\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  WORLD                23         19       82.6%\n",
      "  SPORTS               22         20       90.9%\n",
      "  BUSINESS             30         12       40.0%\n",
      "  SCITECH              18         18      100.0%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "SYNTHESIZER ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Synthesizer-Orchestrator Alignment:\n",
      "    Agreed with orchestrator's 1st choice: 61/98 (62.2%)\n",
      "\n",
      "  Synthesizer Override Rate:\n",
      "    Overrode workers (picked unclaimed category): 0/100 (0.0%)\n",
      "\n",
      "  Synthesizer Confidence Distribution:\n",
      "  Confidence           Count   Percentage\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  high                    84        84.0%\n",
      "  medium                  14        14.0%\n",
      "  low                      2         2.0%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CONFIDENCE VS ACCURACY ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Confidence           Count    Correct     Accuracy\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "high                    84         68       81.0%\n",
      "medium                  14         11       78.6%\n",
      "low                      2          1       50.0%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "END-TO-END PIPELINE ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Pipeline Error Analysis:\n",
      "  Scenario                                      Count   Percentage\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Orchestrator âœ“ â†’ Synthesizer âœ“                   50        50.0%\n",
      "  Orchestrator âœ“ â†’ Synthesizer âœ— (error introduced)         14        14.0%\n",
      "  Orchestrator âœ— â†’ Synthesizer âœ“ (error corrected)         30        30.0%\n",
      "  Orchestrator âœ— â†’ Synthesizer âœ—                    6         6.0%\n",
      "\n",
      "======================================================================\n",
      "ORCHESTRATOR-WORKER PATTERN EVALUATION COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EVALUATION: Orchestrator-Worker Design Pattern Performance\n",
    "# ============================================================\n",
    "\n",
    "# Extract predictions and ground truth from orchestrator-worker results\n",
    "ow_predictions = []\n",
    "ow_ground_truths = []\n",
    "ow_errors = []\n",
    "\n",
    "for result in orchestrator_worker_results:\n",
    "    ground_truth = result['ground_truth_name']\n",
    "    ow_ground_truths.append(ground_truth)\n",
    "    \n",
    "    # Get prediction from synthesizer_output\n",
    "    synth = result['synthesizer_output']\n",
    "    \n",
    "    if 'classification' in synth and synth['classification'] in CATEGORIES:\n",
    "        predicted = synth['classification']\n",
    "        ow_predictions.append(predicted)\n",
    "    else:\n",
    "        # Handle errors\n",
    "        ow_predictions.append(\"ERROR\")\n",
    "        ow_errors.append(result['index'])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ORCHESTRATOR-WORKER DESIGN PATTERN - EVALUATION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for errors\n",
    "if ow_errors:\n",
    "    print(f\"\\nâš ï¸  Warning: {len(ow_errors)} samples had errors (indices: {ow_errors[:10]}{'...' if len(ow_errors) > 10 else ''})\")\n",
    "    print(f\"   These are excluded from metrics calculation.\\n\")\n",
    "    \n",
    "    valid_ow_predictions = [p for p in ow_predictions if p != \"ERROR\"]\n",
    "    valid_ow_ground_truths = [g for p, g in zip(ow_predictions, ow_ground_truths) if p != \"ERROR\"]\n",
    "else:\n",
    "    valid_ow_predictions = ow_predictions\n",
    "    valid_ow_ground_truths = ow_ground_truths\n",
    "\n",
    "# ============================================================\n",
    "# Basic Metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"OVERALL METRICS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "ow_accuracy = accuracy_score(valid_ow_ground_truths, valid_ow_predictions)\n",
    "ow_precision_macro = precision_score(valid_ow_ground_truths, valid_ow_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "ow_recall_macro = recall_score(valid_ow_ground_truths, valid_ow_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "ow_f1_macro = f1_score(valid_ow_ground_truths, valid_ow_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "\n",
    "ow_precision_weighted = precision_score(valid_ow_ground_truths, valid_ow_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "ow_recall_weighted = recall_score(valid_ow_ground_truths, valid_ow_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "ow_f1_weighted = f1_score(valid_ow_ground_truths, valid_ow_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\n  Total Samples:     {len(orchestrator_worker_results)}\")\n",
    "print(f\"  Valid Predictions: {len(valid_ow_predictions)}\")\n",
    "print(f\"  Error Rate:        {len(ow_errors) / len(orchestrator_worker_results) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n  ğŸ“Š Accuracy:        {ow_accuracy:.4f}  ({ow_accuracy * 100:.1f}%)\")\n",
    "print(f\"\\n  Macro Averages (treats all classes equally):\")\n",
    "print(f\"     Precision:      {ow_precision_macro:.4f}\")\n",
    "print(f\"     Recall:         {ow_recall_macro:.4f}\")\n",
    "print(f\"     F1 Score:       {ow_f1_macro:.4f}\")\n",
    "\n",
    "print(f\"\\n  Weighted Averages (accounts for class imbalance):\")\n",
    "print(f\"     Precision:      {ow_precision_weighted:.4f}\")\n",
    "print(f\"     Recall:         {ow_recall_weighted:.4f}\")\n",
    "print(f\"     F1 Score:       {ow_f1_weighted:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Per-Class Metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"PER-CLASS METRICS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "print(\"\\n\" + classification_report(valid_ow_ground_truths, valid_ow_predictions, labels=CATEGORIES, zero_division=0))\n",
    "\n",
    "# ============================================================\n",
    "# Confusion Matrix\n",
    "# ============================================================\n",
    "\n",
    "print(\"â”€\" * 70)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "ow_cm = confusion_matrix(valid_ow_ground_truths, valid_ow_predictions, labels=CATEGORIES)\n",
    "\n",
    "print(f\"\\n{'Predicted â†’':>15}\", end=\"\")\n",
    "for cat in CATEGORIES:\n",
    "    print(f\"{cat:>10}\", end=\"\")\n",
    "print(\"\\n\" + \"â”€\" * 55)\n",
    "\n",
    "print(\"Actual â†“\")\n",
    "for i, cat in enumerate(CATEGORIES):\n",
    "    print(f\"{cat:>15}\", end=\"\")\n",
    "    for j in range(len(CATEGORIES)):\n",
    "        print(f\"{ow_cm[i][j]:>10}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "# ============================================================\n",
    "# Distribution Analysis\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"DISTRIBUTION ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "ow_gt_dist = Counter(valid_ow_ground_truths)\n",
    "ow_pred_dist = Counter(valid_ow_predictions)\n",
    "\n",
    "print(f\"\\n{'Category':<12} {'Ground Truth':>15} {'Predicted':>15} {'Difference':>12}\")\n",
    "print(\"â”€\" * 55)\n",
    "for cat in CATEGORIES:\n",
    "    gt_count = ow_gt_dist.get(cat, 0)\n",
    "    pred_count = ow_pred_dist.get(cat, 0)\n",
    "    diff = pred_count - gt_count\n",
    "    diff_str = f\"+{diff}\" if diff > 0 else str(diff)\n",
    "    print(f\"{cat:<12} {gt_count:>15} {pred_count:>15} {diff_str:>12}\")\n",
    "\n",
    "# ============================================================\n",
    "# Orchestrator Analysis (Unique to Orchestrator-Worker)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"ORCHESTRATOR ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# How often was the orchestrator's likely_categories prediction correct?\n",
    "orch_correct_predictions = 0\n",
    "orch_first_choice_correct = 0\n",
    "orch_total_with_predictions = 0\n",
    "\n",
    "for result in orchestrator_worker_results:\n",
    "    orch = result['orchestrator_output']\n",
    "    ground_truth = result['ground_truth_name']\n",
    "    likely_cats = orch.get('likely_categories', [])\n",
    "    \n",
    "    if likely_cats:\n",
    "        orch_total_with_predictions += 1\n",
    "        # Check if ground truth is in likely categories\n",
    "        if ground_truth in likely_cats:\n",
    "            orch_correct_predictions += 1\n",
    "        # Check if first choice is correct\n",
    "        if likely_cats[0] == ground_truth:\n",
    "            orch_first_choice_correct += 1\n",
    "\n",
    "print(f\"\\n  Orchestrator Prediction Accuracy:\")\n",
    "if orch_total_with_predictions > 0:\n",
    "    print(f\"    Ground truth in likely_categories: {orch_correct_predictions}/{orch_total_with_predictions} ({orch_correct_predictions/orch_total_with_predictions*100:.1f}%)\")\n",
    "    print(f\"    First choice correct:              {orch_first_choice_correct}/{orch_total_with_predictions} ({orch_first_choice_correct/orch_total_with_predictions*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"    No orchestrator predictions available\")\n",
    "\n",
    "# ============================================================\n",
    "# Worker Analysis (Similar to Parallelization)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"WORKER ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Count how many workers claimed each article\n",
    "worker_claim_counts = Counter()\n",
    "for result in orchestrator_worker_results:\n",
    "    claims = sum(1 for worker_result in result['worker_outputs'].values() \n",
    "                 if worker_result.get('belongs_to_category', False))\n",
    "    worker_claim_counts[claims] += 1\n",
    "\n",
    "print(f\"\\n  Number of Workers Claiming Article:\")\n",
    "print(f\"  {'Claims':>10} {'Count':>10} {'Percentage':>12}\")\n",
    "print(\"  \" + \"â”€\" * 35)\n",
    "for num_claims in sorted(worker_claim_counts.keys()):\n",
    "    count = worker_claim_counts[num_claims]\n",
    "    pct = count / len(orchestrator_worker_results) * 100\n",
    "    print(f\"  {num_claims:>10} {count:>10} {pct:>11.1f}%\")\n",
    "\n",
    "# Per-worker accuracy (when that worker claimed and was correct)\n",
    "print(f\"\\n  Per-Worker Claim Statistics:\")\n",
    "print(f\"  {'Worker':<12} {'Claimed':>10} {'Correct':>10} {'Accuracy':>12}\")\n",
    "print(\"  \" + \"â”€\" * 47)\n",
    "\n",
    "worker_stats = {\n",
    "    'world': {'claimed': 0, 'correct': 0},\n",
    "    'sports': {'claimed': 0, 'correct': 0},\n",
    "    'business': {'claimed': 0, 'correct': 0},\n",
    "    'scitech': {'claimed': 0, 'correct': 0}\n",
    "}\n",
    "category_map = {'world': 'World', 'sports': 'Sports', 'business': 'Business', 'scitech': 'Sci/Tech'}\n",
    "\n",
    "for result in orchestrator_worker_results:\n",
    "    for worker_name, worker_result in result['worker_outputs'].items():\n",
    "        if worker_result.get('belongs_to_category', False):\n",
    "            worker_stats[worker_name]['claimed'] += 1\n",
    "            if category_map[worker_name] == result['ground_truth_name']:\n",
    "                worker_stats[worker_name]['correct'] += 1\n",
    "\n",
    "for worker_name in ['world', 'sports', 'business', 'scitech']:\n",
    "    claimed = worker_stats[worker_name]['claimed']\n",
    "    correct = worker_stats[worker_name]['correct']\n",
    "    acc = correct / claimed if claimed > 0 else 0\n",
    "    print(f\"  {worker_name.upper():<12} {claimed:>10} {correct:>10} {acc:>11.1%}\")\n",
    "\n",
    "# ============================================================\n",
    "# Synthesizer Analysis (Unique to Orchestrator-Worker)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"SYNTHESIZER ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# How often did synthesizer agree with orchestrator's first choice?\n",
    "synth_orch_agreement = 0\n",
    "synth_orch_total = 0\n",
    "\n",
    "# How often did synthesizer override workers (pick category no worker claimed)?\n",
    "synth_override_count = 0\n",
    "\n",
    "# Synthesizer confidence distribution\n",
    "synth_confidence_dist = Counter()\n",
    "\n",
    "for result in orchestrator_worker_results:\n",
    "    orch = result['orchestrator_output']\n",
    "    synth = result['synthesizer_output']\n",
    "    workers = result['worker_outputs']\n",
    "    \n",
    "    synth_classification = synth.get('classification', '')\n",
    "    synth_confidence = synth.get('confidence', 'unknown')\n",
    "    synth_confidence_dist[synth_confidence] += 1\n",
    "    \n",
    "    # Check orchestrator-synthesizer alignment\n",
    "    likely_cats = orch.get('likely_categories', [])\n",
    "    if likely_cats:\n",
    "        synth_orch_total += 1\n",
    "        if synth_classification == likely_cats[0]:\n",
    "            synth_orch_agreement += 1\n",
    "    \n",
    "    # Check if synthesizer overrode workers\n",
    "    claimed_categories = set()\n",
    "    for worker_name, worker_result in workers.items():\n",
    "        if worker_result.get('belongs_to_category', False):\n",
    "            claimed_categories.add(category_map.get(worker_name, ''))\n",
    "    \n",
    "    if synth_classification and synth_classification not in claimed_categories and claimed_categories:\n",
    "        synth_override_count += 1\n",
    "\n",
    "print(f\"\\n  Synthesizer-Orchestrator Alignment:\")\n",
    "if synth_orch_total > 0:\n",
    "    print(f\"    Agreed with orchestrator's 1st choice: {synth_orch_agreement}/{synth_orch_total} ({synth_orch_agreement/synth_orch_total*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"    No orchestrator predictions to compare\")\n",
    "\n",
    "print(f\"\\n  Synthesizer Override Rate:\")\n",
    "print(f\"    Overrode workers (picked unclaimed category): {synth_override_count}/{len(orchestrator_worker_results)} ({synth_override_count/len(orchestrator_worker_results)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n  Synthesizer Confidence Distribution:\")\n",
    "print(f\"  {'Confidence':<15} {'Count':>10} {'Percentage':>12}\")\n",
    "print(\"  \" + \"â”€\" * 40)\n",
    "for conf_level in ['high', 'medium', 'low', 'unknown']:\n",
    "    count = synth_confidence_dist.get(conf_level, 0)\n",
    "    if count > 0:\n",
    "        pct = count / len(orchestrator_worker_results) * 100\n",
    "        print(f\"  {conf_level:<15} {count:>10} {pct:>11.1f}%\")\n",
    "\n",
    "# ============================================================\n",
    "# Confidence vs Accuracy Analysis\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"CONFIDENCE VS ACCURACY ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Group by synthesizer confidence and calculate accuracy\n",
    "confidence_accuracy = {\"high\": [0, 0], \"medium\": [0, 0], \"low\": [0, 0]}\n",
    "\n",
    "for result in orchestrator_worker_results:\n",
    "    synth = result['synthesizer_output']\n",
    "    conf = synth.get('confidence', 'unknown')\n",
    "    predicted = synth.get('classification', '')\n",
    "    is_correct = predicted == result['ground_truth_name']\n",
    "    \n",
    "    if conf in confidence_accuracy:\n",
    "        confidence_accuracy[conf][1] += 1\n",
    "        if is_correct:\n",
    "            confidence_accuracy[conf][0] += 1\n",
    "\n",
    "print(f\"\\n{'Confidence':<15} {'Count':>10} {'Correct':>10} {'Accuracy':>12}\")\n",
    "print(\"â”€\" * 50)\n",
    "for conf_level in ['high', 'medium', 'low']:\n",
    "    correct, total = confidence_accuracy[conf_level]\n",
    "    if total > 0:\n",
    "        acc = correct / total\n",
    "        print(f\"{conf_level:<15} {total:>10} {correct:>10} {acc:>11.1%}\")\n",
    "    else:\n",
    "        print(f\"{conf_level:<15} {0:>10} {0:>10} {'N/A':>12}\")\n",
    "\n",
    "# ============================================================\n",
    "# End-to-End Pipeline Analysis\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"END-TO-END PIPELINE ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# When orchestrator predicted correctly AND synthesizer got it right\n",
    "orch_correct_synth_correct = 0\n",
    "orch_correct_synth_wrong = 0\n",
    "orch_wrong_synth_correct = 0\n",
    "orch_wrong_synth_wrong = 0\n",
    "\n",
    "for result in orchestrator_worker_results:\n",
    "    orch = result['orchestrator_output']\n",
    "    synth = result['synthesizer_output']\n",
    "    ground_truth = result['ground_truth_name']\n",
    "    \n",
    "    likely_cats = orch.get('likely_categories', [])\n",
    "    synth_classification = synth.get('classification', '')\n",
    "    \n",
    "    orch_correct = ground_truth in likely_cats if likely_cats else False\n",
    "    synth_correct = synth_classification == ground_truth\n",
    "    \n",
    "    if orch_correct and synth_correct:\n",
    "        orch_correct_synth_correct += 1\n",
    "    elif orch_correct and not synth_correct:\n",
    "        orch_correct_synth_wrong += 1\n",
    "    elif not orch_correct and synth_correct:\n",
    "        orch_wrong_synth_correct += 1\n",
    "    else:\n",
    "        orch_wrong_synth_wrong += 1\n",
    "\n",
    "total = len(orchestrator_worker_results)\n",
    "print(f\"\\n  Pipeline Error Analysis:\")\n",
    "print(f\"  {'Scenario':<40} {'Count':>10} {'Percentage':>12}\")\n",
    "print(\"  \" + \"â”€\" * 65)\n",
    "print(f\"  {'Orchestrator âœ“ â†’ Synthesizer âœ“':<40} {orch_correct_synth_correct:>10} {orch_correct_synth_correct/total*100:>11.1f}%\")\n",
    "print(f\"  {'Orchestrator âœ“ â†’ Synthesizer âœ— (error introduced)':<40} {orch_correct_synth_wrong:>10} {orch_correct_synth_wrong/total*100:>11.1f}%\")\n",
    "print(f\"  {'Orchestrator âœ— â†’ Synthesizer âœ“ (error corrected)':<40} {orch_wrong_synth_correct:>10} {orch_wrong_synth_correct/total*100:>11.1f}%\")\n",
    "print(f\"  {'Orchestrator âœ— â†’ Synthesizer âœ—':<40} {orch_wrong_synth_wrong:>10} {orch_wrong_synth_wrong/total*100:>11.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ORCHESTRATOR-WORKER PATTERN EVALUATION COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e04f11a",
   "metadata": {},
   "source": [
    "## 5. Evaluator-Optimizer Design Pattern\n",
    "\n",
    "### What is Evaluator-Optimizer?\n",
    "\n",
    "**Evaluator-Optimizer** (also called Generator-Critic or Self-Refinement) is an agentic workflow pattern where an LLM generator produces an output, and an LLM evaluator critically assesses it. If the output doesn't meet quality criteria, feedback is sent back to the generator for refinement. This iterative loop continues until the output is approved or maximum iterations are reached.\n",
    "\n",
    "This pattern is particularly useful when:\n",
    "- Tasks benefit from iterative refinement\n",
    "- Initial outputs may have subtle errors that can be caught through critical review\n",
    "- Quality is more important than speed\n",
    "- The system needs self-correction capability\n",
    "- Ambiguous inputs require careful consideration\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Generator (LLM)**: Produces output with explicit reasoning\n",
    "2. **Evaluator (LLM)**: Critically assesses the output and provides feedback\n",
    "3. **Feedback Loop**: Mechanism to send evaluator's critique back to generator\n",
    "4. **Termination Condition**: When to stop iterating (approval or max iterations)\n",
    "\n",
    "### How It Differs from Other Patterns\n",
    "\n",
    "| Pattern | Approach | Key Feature |\n",
    "|---------|----------|-------------|\n",
    "| **Prompt Chaining** | Sequential steps | Fixed pipeline, no backtracking |\n",
    "| **Routing** | Expert selection | One-shot classification |\n",
    "| **Parallelization** | Multiple perspectives | Consensus from parallel views |\n",
    "| **Orchestrator-Worker** | Coordinated workers | LLM coordination and synthesis |\n",
    "| **Evaluator-Optimizer** | Iterative refinement | **Self-correction through feedback** |\n",
    "\n",
    "---\n",
    "\n",
    "### Generic Evaluator-Optimizer Workflow Diagram\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                   EVALUATOR-OPTIMIZER DESIGN PATTERN                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              â”‚\n",
    "â”‚    INPUT     â”‚\n",
    "â”‚              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚\n",
    "       â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      ğŸ“ GENERATOR (LLM)                          â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  Responsibilities:                                               â”‚\n",
    "â”‚  â€¢ Analyze the input                                            â”‚\n",
    "â”‚  â€¢ Produce output with explicit reasoning                       â”‚\n",
    "â”‚  â€¢ Cite evidence supporting the output                          â”‚\n",
    "â”‚  â€¢ Consider alternatives                                        â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  Output: Result + Detailed Reasoning + Evidence                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                               â”‚\n",
    "                               â”‚ Output + Reasoning\n",
    "                               â”‚\n",
    "                               â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      ğŸ” EVALUATOR (LLM)                          â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  Responsibilities:                                               â”‚\n",
    "â”‚  â€¢ Re-examine the original input                                â”‚\n",
    "â”‚  â€¢ Critically assess generator's reasoning                      â”‚\n",
    "â”‚  â€¢ Check for logical consistency                                â”‚\n",
    "â”‚  â€¢ Identify overlooked evidence                                 â”‚\n",
    "â”‚  â€¢ Consider alternative interpretations                         â”‚\n",
    "â”‚  â€¢ Decide: APPROVE or REJECT with actionable feedback           â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  Output: Decision (APPROVE/REJECT) + Feedback (if rejected)     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                               â”‚\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚                     â”‚\n",
    "                    â–¼                     â–¼\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚  APPROVED   â”‚       â”‚    REJECTED     â”‚\n",
    "            â”‚             â”‚       â”‚  + FEEDBACK     â”‚\n",
    "            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                   â”‚                       â”‚\n",
    "                   â”‚                       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                   â”‚                       â”‚ â”‚   FEEDBACK LOOP     â”‚\n",
    "                   â”‚                       â”‚ â”‚                     â”‚\n",
    "                   â”‚                       â”‚ â”‚ â€¢ Original input    â”‚\n",
    "                   â”‚                       â”‚ â”‚ â€¢ Previous output   â”‚\n",
    "                   â”‚                       â”‚ â”‚ â€¢ Evaluator feedbackâ”‚\n",
    "                   â”‚                       â”‚ â”‚ â€¢ Iteration count   â”‚\n",
    "                   â”‚                       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                   â”‚                       â”‚            â”‚\n",
    "                   â”‚                       â”‚            â–¼\n",
    "                   â”‚                       â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                   â”‚                       â””â”€â”€â–¶â”‚   GENERATOR   â”‚\n",
    "                   â”‚                           â”‚   (Retry)     â”‚\n",
    "                   â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                   â”‚                                   â”‚\n",
    "                   â”‚                           (Back to Evaluator)\n",
    "                   â”‚                                   â”‚\n",
    "                   â–¼                                   â”‚\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚\n",
    "            â”‚              â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            â”‚    OUTPUT    â”‚   (After approval or max iterations)\n",
    "            â”‚              â”‚\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Advantages of Evaluator-Optimizer\n",
    "\n",
    "| Aspect | Benefit |\n",
    "|--------|---------|\n",
    "| **Self-Correction** | System can catch and fix its own mistakes |\n",
    "| **Quality Assurance** | Built-in review before final output |\n",
    "| **Reasoning Verification** | Evaluator validates logical consistency |\n",
    "| **Iterative Improvement** | Each round addresses specific issues |\n",
    "| **Explainability** | Full audit trail of reasoning and refinements |\n",
    "\n",
    "### Trade-offs\n",
    "\n",
    "| Aspect | Consideration |\n",
    "|--------|---------------|\n",
    "| **Latency** | Multiple iterations increase response time |\n",
    "| **Cost** | More LLM calls per input |\n",
    "| **Complexity** | Feedback loop logic must be carefully designed |\n",
    "| **Convergence** | No guarantee of reaching approval |\n",
    "| **Diminishing Returns** | Later iterations may not improve quality |\n",
    "\n",
    "---\n",
    "\n",
    "### Execution Flow\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  INPUT  â”‚â”€â”€â”€â–¶â”‚ GENERATOR â”‚â”€â”€â”€â–¶â”‚ EVALUATOR â”‚â”€â”€â”€â–¶â”‚ APPROVED â”‚â”€â”€â”€â–¶ OUTPUT\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    â–²                 â”‚\n",
    "                    â”‚                 â”‚ REJECTED\n",
    "                    â”‚                 â–¼\n",
    "                    â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ FEEDBACK â”‚\n",
    "                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Iteration 1: Generator â†’ Evaluator (approve/reject)\n",
    "Iteration 2: Generator (with feedback) â†’ Evaluator (approve/reject)\n",
    "...\n",
    "Iteration N: Generator (with feedback) â†’ Evaluator â†’ Final Output\n",
    "\n",
    "Termination: Approved OR max_iterations reached\n",
    "```\n",
    "\n",
    "### LLM Calls per Input\n",
    "\n",
    "| Scenario | Generator Calls | Evaluator Calls | Total |\n",
    "|----------|-----------------|-----------------|-------|\n",
    "| Approved on 1st try | 1 | 1 | **2** |\n",
    "| Approved on 2nd try | 2 | 2 | **4** |\n",
    "| Approved on 3rd try | 3 | 3 | **6** |\n",
    "| Max iterations (3) reached | 3 | 3 | **6** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4b6926",
   "metadata": {},
   "source": [
    "### Our Implementation: Evaluator-Optimizer for AG News Classification\n",
    "\n",
    "For our AG News classification task, we'll implement the evaluator-optimizer pattern with iterative refinement until the evaluator approves or max iterations (3) are reached.\n",
    "\n",
    "---\n",
    "\n",
    "#### Architecture Diagram\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           EVALUATOR-OPTIMIZER FOR AG NEWS CLASSIFICATION                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  NEWS        â”‚\n",
    "â”‚  ARTICLE     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚\n",
    "       â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                 ğŸ“ GENERATOR (gpt-5.1)                           â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  â€¢ Analyzes the news article                                    â”‚\n",
    "â”‚  â€¢ Extracts key signals and evidence                            â”‚\n",
    "â”‚  â€¢ Makes classification decision                                â”‚\n",
    "â”‚  â€¢ Provides detailed, verifiable reasoning                      â”‚\n",
    "â”‚  â€¢ Considers alternative categories                             â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                               â”‚\n",
    "                               â”‚ Classification + Reasoning + Evidence\n",
    "                               â”‚\n",
    "                               â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚             ğŸ” EVALUATOR (claude-opus-4-5-20251101)              â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  â€¢ Re-reads the original article                                â”‚\n",
    "â”‚  â€¢ Critically examines generator's reasoning                    â”‚\n",
    "â”‚  â€¢ Checks logical consistency                                   â”‚\n",
    "â”‚  â€¢ Identifies overlooked evidence                               â”‚\n",
    "â”‚  â€¢ Considers if alternative was dismissed too quickly           â”‚\n",
    "â”‚  â€¢ Decision: APPROVE or REJECT + actionable feedback            â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                               â”‚\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚                     â”‚\n",
    "                    â–¼                     â–¼\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚  APPROVED   â”‚       â”‚    REJECTED     â”‚\n",
    "            â”‚  âœ“ Use      â”‚       â”‚  + FEEDBACK     â”‚\n",
    "            â”‚  result     â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                â”‚\n",
    "                   â”‚                       â”‚ Feedback Loop\n",
    "                   â”‚                       â–¼\n",
    "                   â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                   â”‚              â”‚  ğŸ”„ GENERATOR (Retry)           â”‚\n",
    "                   â”‚              â”‚  Input: Article + Previous +    â”‚\n",
    "                   â”‚              â”‚  Feedback + Iteration#          â”‚\n",
    "                   â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                   â”‚                               â”‚\n",
    "                   â”‚                        (Back to Evaluator)\n",
    "                   â–¼                               â”‚\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚\n",
    "            â”‚   FINAL      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            â”‚   CATEGORY   â”‚   (After approval or max 3 iterations)\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Models Used\n",
    "\n",
    "| Component | Model | Rationale |\n",
    "|-----------|-------|-----------|\n",
    "| Generator | `gpt-5.1` | Strong reasoning and evidence extraction |\n",
    "| Evaluator | `claude-opus-4-5-20251101` | Superior critical analysis and nuanced assessment |\n",
    "\n",
    "**Max Iterations:** 3 (balance between quality and cost)\n",
    "\n",
    "---\n",
    "\n",
    "### Generator (gpt-5.1) - Initial Classification ğŸ“\n",
    "\n",
    "#### Input\n",
    "\n",
    "Raw news article text.\n",
    "\n",
    "#### System Prompt\n",
    "\n",
    "```\n",
    "You are an expert news classifier. Your task is to classify a news article into exactly ONE of these four categories:\n",
    "- World: International affairs, politics, government, diplomacy, conflicts\n",
    "- Sports: Athletic events, teams, players, competitions, leagues\n",
    "- Business: Companies, markets, economy, finance, corporate news\n",
    "- Sci/Tech: Technology, science, software, research, innovation\n",
    "\n",
    "Analyze the article thoroughly and provide your classification with EXPLICIT, VERIFIABLE reasoning.\n",
    "\n",
    "Your response must include:\n",
    "1. Classification decision\n",
    "2. Confidence level (high/medium/low)\n",
    "3. Key signals extracted from the article (entities, topics, keywords)\n",
    "4. Detailed reasoning explaining WHY this category fits best\n",
    "5. Alternative category considered and why it was rejected\n",
    "6. Specific evidence from the article supporting your decision\n",
    "\n",
    "Rules:\n",
    "- Be thorough and precise in your analysis\n",
    "- Cite specific phrases or facts from the article as evidence\n",
    "- Consider edge cases (e.g., tech company financials could be Business OR Sci/Tech)\n",
    "- Your reasoning must be detailed enough for critical review\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"classification\": \"World\" | \"Sports\" | \"Business\" | \"Sci/Tech\",\n",
    "    \"confidence\": \"high\" | \"medium\" | \"low\",\n",
    "    \"key_signals\": {\n",
    "        \"entities\": [\"list of people, organizations, teams mentioned\"],\n",
    "        \"topics\": [\"main topics discussed\"],\n",
    "        \"domain_keywords\": [\"significant domain-specific terms\"]\n",
    "    },\n",
    "    \"reasoning\": \"Detailed explanation of why this classification is correct\",\n",
    "    \"alternative_considered\": {\n",
    "        \"category\": \"The alternative category you considered\",\n",
    "        \"why_rejected\": \"Specific reason this alternative does not fit as well\"\n",
    "    },\n",
    "    \"evidence\": [\"Direct quotes or specific facts from the article\"]\n",
    "}\n",
    "```\n",
    "\n",
    "#### User Prompt Format\n",
    "\n",
    "```\n",
    "Classify the following news article:\n",
    "\n",
    "---\n",
    "[Article text]\n",
    "---\n",
    "```\n",
    "\n",
    "#### Output Format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"classification\": \"Business\",\n",
    "    \"confidence\": \"high\",\n",
    "    \"key_signals\": {\n",
    "        \"entities\": [\"Apple\", \"Tim Cook\", \"Wall Street analysts\"],\n",
    "        \"topics\": [\"quarterly earnings\", \"revenue growth\", \"stock performance\"],\n",
    "        \"domain_keywords\": [\"earnings\", \"revenue\", \"profit margin\", \"stock price\"]\n",
    "    },\n",
    "    \"reasoning\": \"The article focuses on Apple's quarterly financial performance...\",\n",
    "    \"alternative_considered\": {\n",
    "        \"category\": \"Sci/Tech\",\n",
    "        \"why_rejected\": \"No discussion of products, technology, or innovation.\"\n",
    "    },\n",
    "    \"evidence\": [\"Apple reported quarterly revenue of $89.5 billion\", \"Stock rose 3%\"]\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluator (claude-opus-4-5-20251101) - Critical Assessment ğŸ”\n",
    "\n",
    "#### Input\n",
    "\n",
    "- Original news article\n",
    "- Generator's classification output\n",
    "\n",
    "#### System Prompt\n",
    "\n",
    "```\n",
    "You are a critical evaluator for a news classification system. Your job is to rigorously assess whether a classification decision is correct and well-reasoned.\n",
    "\n",
    "You will receive:\n",
    "1. The original news article\n",
    "2. A classification produced by a generator, including its reasoning and evidence\n",
    "\n",
    "Your task is to critically evaluate the classification by:\n",
    "1. Re-reading the original article independently\n",
    "2. Checking if the reasoning logically supports the conclusion\n",
    "3. Verifying that cited evidence is accurate and relevant\n",
    "4. Looking for overlooked evidence that might change the classification\n",
    "5. Considering if the alternative category was dismissed too quickly\n",
    "6. Assessing if the confidence level is appropriate\n",
    "\n",
    "Evaluation Criteria:\n",
    "- LOGICAL CONSISTENCY: Does the reasoning actually support the conclusion?\n",
    "- EVIDENCE ACCURACY: Did the generator correctly identify and interpret signals?\n",
    "- COMPLETENESS: Are there important signals the generator overlooked?\n",
    "- ALTERNATIVE ANALYSIS: Was the alternative category fairly considered?\n",
    "- CONFIDENCE CALIBRATION: Does the evidence strength match the confidence level?\n",
    "\n",
    "Decision Guidelines:\n",
    "- APPROVE if: Reasoning is sound, evidence is accurate, no significant oversights\n",
    "- REJECT if: Logical flaws, misinterpreted evidence, overlooked critical signals, or wrong classification\n",
    "\n",
    "If you REJECT, provide specific, actionable feedback telling the generator:\n",
    "- What specific issue you found\n",
    "- What evidence was overlooked or misinterpreted\n",
    "- What the generator should reconsider\n",
    "\n",
    "Rules:\n",
    "- Be rigorous but fair - do not reject for trivial issues\n",
    "- Your feedback must be specific and actionable\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"decision\": \"APPROVE\" | \"REJECT\",\n",
    "    \"evaluation\": {\n",
    "        \"logical_consistency\": \"Assessment of reasoning\",\n",
    "        \"evidence_accuracy\": \"Assessment of evidence interpretation\",\n",
    "        \"completeness\": \"Assessment of signal coverage\",\n",
    "        \"alternative_analysis\": \"Assessment of alternative consideration\",\n",
    "        \"confidence_calibration\": \"Assessment of confidence appropriateness\"\n",
    "    },\n",
    "    \"issues_found\": [\n",
    "        {\n",
    "            \"type\": \"overlooked_evidence | logical_flaw | misinterpreted_signal | weak_reasoning\",\n",
    "            \"description\": \"Specific description of the issue\"\n",
    "        }\n",
    "    ],\n",
    "    \"feedback\": \"Specific, actionable feedback for generator (if REJECT)\",\n",
    "    \"final_classification\": \"Classification to use (same as generator if APPROVE)\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### User Prompt Format\n",
    "\n",
    "```\n",
    "Evaluate the following news classification:\n",
    "\n",
    "ORIGINAL ARTICLE:\n",
    "---\n",
    "[Article text]\n",
    "---\n",
    "\n",
    "GENERATOR'S CLASSIFICATION:\n",
    "[JSON of generator's output]\n",
    "```\n",
    "\n",
    "#### Output Format (APPROVE)\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"decision\": \"APPROVE\",\n",
    "    \"evaluation\": {\n",
    "        \"logical_consistency\": \"Sound. Financial metrics correctly identified.\",\n",
    "        \"evidence_accuracy\": \"Accurate. Revenue and stock data correctly cited.\",\n",
    "        \"completeness\": \"Complete. No significant signals overlooked.\",\n",
    "        \"alternative_analysis\": \"Fair. Sci/Tech reasonably rejected.\",\n",
    "        \"confidence_calibration\": \"Appropriate. High confidence justified.\"\n",
    "    },\n",
    "    \"issues_found\": [],\n",
    "    \"feedback\": null,\n",
    "    \"final_classification\": \"Business\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output Format (REJECT)\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"decision\": \"REJECT\",\n",
    "    \"evaluation\": {\n",
    "        \"logical_consistency\": \"Weak. Conclusion does not follow from evidence.\",\n",
    "        \"evidence_accuracy\": \"Partial. Missed key technical content.\",\n",
    "        \"completeness\": \"Incomplete. Overlooked AI chip discussion.\",\n",
    "        \"alternative_analysis\": \"Insufficient. Sci/Tech dismissed too quickly.\",\n",
    "        \"confidence_calibration\": \"Overconfident given mixed signals.\"\n",
    "    },\n",
    "    \"issues_found\": [\n",
    "        {\n",
    "            \"type\": \"overlooked_evidence\",\n",
    "            \"description\": \"Article discusses AI chip architecture in technical detail\"\n",
    "        }\n",
    "    ],\n",
    "    \"feedback\": \"Reconsider classification. The PRIMARY content focuses on technology, not finances.\",\n",
    "    \"final_classification\": null\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Generator (gpt-5.1) - Retry with Feedback ğŸ”„\n",
    "\n",
    "When the evaluator rejects, the generator receives feedback and must reconsider.\n",
    "\n",
    "#### Input\n",
    "\n",
    "- Original news article\n",
    "- Previous classification attempt\n",
    "- Evaluator's feedback\n",
    "- Current iteration number\n",
    "\n",
    "#### System Prompt (Retry)\n",
    "\n",
    "```\n",
    "You are an expert news classifier revising a previous classification based on evaluator feedback.\n",
    "\n",
    "You previously classified a news article, but an evaluator found issues with your reasoning. You must now reconsider your classification while addressing the specific feedback provided.\n",
    "\n",
    "Your task:\n",
    "1. Re-read the original article carefully\n",
    "2. Consider the evaluator's feedback seriously\n",
    "3. Re-examine the evidence, especially areas highlighted in the feedback\n",
    "4. Either REVISE your classification or DEFEND your original decision with better reasoning\n",
    "\n",
    "Important:\n",
    "- You MUST address each issue raised in the feedback\n",
    "- If you change your classification, explain what new insight led to the change\n",
    "- If you maintain your original classification, provide stronger evidence and reasoning\n",
    "- Your confidence should reflect the difficulty of this classification\n",
    "\n",
    "Categories:\n",
    "- World: International affairs, politics, government, diplomacy, conflicts\n",
    "- Sports: Athletic events, teams, players, competitions, leagues\n",
    "- Business: Companies, markets, economy, finance, corporate news\n",
    "- Sci/Tech: Technology, science, software, research, innovation\n",
    "\n",
    "Rules:\n",
    "- Explicitly address each point in the evaluator's feedback\n",
    "- Provide even more detailed reasoning than before\n",
    "- Cite specific evidence from the article\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"classification\": \"World\" | \"Sports\" | \"Business\" | \"Sci/Tech\",\n",
    "    \"confidence\": \"high\" | \"medium\" | \"low\",\n",
    "    \"key_signals\": {\n",
    "        \"entities\": [\"list of entities\"],\n",
    "        \"topics\": [\"main topics\"],\n",
    "        \"domain_keywords\": [\"domain-specific terms\"]\n",
    "    },\n",
    "    \"reasoning\": \"Detailed explanation addressing evaluator concerns\",\n",
    "    \"feedback_addressed\": {\n",
    "        \"issue\": \"What the evaluator raised\",\n",
    "        \"response\": \"How you addressed it\"\n",
    "    },\n",
    "    \"changed_classification\": true | false,\n",
    "    \"change_explanation\": \"Why you changed or maintained your classification\",\n",
    "    \"evidence\": [\"Specific evidence from the article\"]\n",
    "}\n",
    "```\n",
    "\n",
    "#### User Prompt Format (Retry)\n",
    "\n",
    "```\n",
    "Revise your classification based on evaluator feedback.\n",
    "\n",
    "ORIGINAL ARTICLE:\n",
    "---\n",
    "[Article text]\n",
    "---\n",
    "\n",
    "YOUR PREVIOUS CLASSIFICATION:\n",
    "[JSON of previous generator output]\n",
    "\n",
    "EVALUATOR'S FEEDBACK:\n",
    "[Evaluator's feedback string]\n",
    "\n",
    "ITERATION: [2 or 3] of 3\n",
    "\n",
    "Please reconsider your classification, addressing the evaluator's concerns.\n",
    "```\n",
    "\n",
    "#### Output Format (Retry)\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"classification\": \"Sci/Tech\",\n",
    "    \"confidence\": \"high\",\n",
    "    \"key_signals\": {\n",
    "        \"entities\": [\"Apple\", \"Neural Engine\", \"A17 Pro chip\"],\n",
    "        \"topics\": [\"AI chip technology\", \"neural processing\"],\n",
    "        \"domain_keywords\": [\"neural engine\", \"transistors\", \"machine learning\"]\n",
    "    },\n",
    "    \"reasoning\": \"After re-examining with evaluator feedback, the article's PRIMARY content is technical...\",\n",
    "    \"feedback_addressed\": {\n",
    "        \"issue\": \"Overlooked AI chip technical discussion\",\n",
    "        \"response\": \"Re-examined and found detailed technical specifications as primary focus\"\n",
    "    },\n",
    "    \"changed_classification\": true,\n",
    "    \"change_explanation\": \"Changed from Business to Sci/Tech. Original focused on financial framing, but substance is technology.\",\n",
    "    \"evidence\": [\"New A17 Pro chip features 19 billion transistors\", \"16-core Neural Engine\"]\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Component | Model | When Used | Purpose |\n",
    "|-----------|-------|-----------|---------|\n",
    "| **Generator (Initial)** | `gpt-5.1` | First iteration | Initial classification with reasoning |\n",
    "| **Evaluator** | `claude-opus-4-5-20251101` | After each generation | Critical assessment and feedback |\n",
    "| **Generator (Retry)** | `gpt-5.1` | After rejection | Revised classification addressing feedback |\n",
    "\n",
    "**Execution Flow:**\n",
    "1. Generator produces initial classification (1 LLM call)\n",
    "2. Evaluator assesses: APPROVE or REJECT (1 LLM call)\n",
    "3. If REJECT: Generator retries with feedback (1 LLM call) â†’ back to step 2\n",
    "4. Loop until APPROVE or max iterations (3) reached\n",
    "\n",
    "**LLM Calls:** 2 (best case) to 6 (worst case, 3 iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f4ab31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EVALUATOR-OPTIMIZER DESIGN PATTERN - Classification\n",
      "======================================================================\n",
      "\n",
      "Processing 100 samples using evaluator-optimizer pattern...\n",
      "Pipeline: Generator (gpt-5.1) â†” Evaluator (Claude Opus 4.5)\n",
      "Max iterations: 3\n",
      "\n",
      "  âœ“ Processed 10/100 articles (10.0%) | Avg iterations: 1.30\n",
      "  âœ“ Processed 20/100 articles (20.0%) | Avg iterations: 1.15\n",
      "  âœ“ Processed 30/100 articles (30.0%) | Avg iterations: 1.10\n",
      "  âœ“ Processed 40/100 articles (40.0%) | Avg iterations: 1.18\n",
      "  âœ“ Processed 50/100 articles (50.0%) | Avg iterations: 1.18\n",
      "  âœ“ Processed 60/100 articles (60.0%) | Avg iterations: 1.17\n",
      "  âœ“ Processed 70/100 articles (70.0%) | Avg iterations: 1.19\n",
      "  âœ“ Processed 80/100 articles (80.0%) | Avg iterations: 1.19\n",
      "  âœ“ Processed 90/100 articles (90.0%) | Avg iterations: 1.18\n",
      "  âœ“ Processed 100/100 articles (100.0%) | Avg iterations: 1.16\n",
      "\n",
      "======================================================================\n",
      "EVALUATOR-OPTIMIZER RESULTS (showing first 3 of 100)\n",
      "======================================================================\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 1\n",
      "Ground Truth: Business\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ”„ Iterations: 1 | Approved: âœ“\n",
      "   Iter 1: Generator â†’ Business (high) | Evaluator â†’ APPROVE\n",
      "\n",
      "ğŸ“Š Final Classification: Business\n",
      "   Confidence: high\n",
      "   Result: âœ“ CORRECT\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 2\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ”„ Iterations: 1 | Approved: âœ“\n",
      "   Iter 1: Generator â†’ Sci/Tech (high) | Evaluator â†’ APPROVE\n",
      "\n",
      "ğŸ“Š Final Classification: Sci/Tech\n",
      "   Confidence: high\n",
      "   Result: âœ“ CORRECT\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Article 3\n",
      "Ground Truth: Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ”„ Iterations: 1 | Approved: âœ“\n",
      "   Iter 1: Generator â†’ Sci/Tech (high) | Evaluator â†’ APPROVE\n",
      "\n",
      "ğŸ“Š Final Classification: Sci/Tech\n",
      "   Confidence: high\n",
      "   Result: âœ“ CORRECT\n",
      "\n",
      "======================================================================\n",
      "ITERATION STATISTICS\n",
      "======================================================================\n",
      "\n",
      "  Approved on iteration 1: 90 (90.0%)\n",
      "  Approved on iteration 2: 4 (4.0%)\n",
      "  Approved on iteration 3: 1 (1.0%)\n",
      "  Not approved (max iter): 5 (5.0%)\n",
      "\n",
      "  Average iterations per article: 1.16\n",
      "  Total LLM calls: 232\n",
      "\n",
      "======================================================================\n",
      "Evaluator-Optimizer complete. 100 results stored in 'evaluator_optimizer_results'\n",
      "Ready for evaluation.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EVALUATOR-OPTIMIZER DESIGN PATTERN IMPLEMENTATION\n",
    "# ============================================================\n",
    "\n",
    "# Configuration\n",
    "MAX_ITERATIONS = 3\n",
    "\n",
    "# ============================================================\n",
    "# GENERATOR (gpt-5.1) - Initial Classification\n",
    "# ============================================================\n",
    "\n",
    "GENERATOR_SYSTEM_PROMPT = \"\"\"You are an expert news classifier. Your task is to classify a news article into exactly ONE of these four categories:\n",
    "- World: International affairs, politics, government, diplomacy, conflicts\n",
    "- Sports: Athletic events, teams, players, competitions, leagues\n",
    "- Business: Companies, markets, economy, finance, corporate news\n",
    "- Sci/Tech: Technology, science, software, research, innovation\n",
    "\n",
    "Analyze the article thoroughly and provide your classification with EXPLICIT, VERIFIABLE reasoning.\n",
    "\n",
    "Your response must include:\n",
    "1. Classification decision\n",
    "2. Confidence level (high/medium/low)\n",
    "3. Key signals extracted from the article (entities, topics, keywords)\n",
    "4. Detailed reasoning explaining WHY this category fits best\n",
    "5. Alternative category considered and why it was rejected\n",
    "6. Specific evidence from the article supporting your decision\n",
    "\n",
    "Rules:\n",
    "- Be thorough and precise in your analysis\n",
    "- Cite specific phrases or facts from the article as evidence\n",
    "- Consider edge cases (e.g., tech company financials could be Business OR Sci/Tech)\n",
    "- Your reasoning must be detailed enough for critical review\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"classification\": \"World\" | \"Sports\" | \"Business\" | \"Sci/Tech\",\n",
    "    \"confidence\": \"high\" | \"medium\" | \"low\",\n",
    "    \"key_signals\": {\n",
    "        \"entities\": [\"list of people, organizations, teams mentioned\"],\n",
    "        \"topics\": [\"main topics discussed\"],\n",
    "        \"domain_keywords\": [\"significant domain-specific terms\"]\n",
    "    },\n",
    "    \"reasoning\": \"Detailed explanation of why this classification is correct\",\n",
    "    \"alternative_considered\": {\n",
    "        \"category\": \"The alternative category you considered\",\n",
    "        \"why_rejected\": \"Specific reason this alternative does not fit as well\"\n",
    "    },\n",
    "    \"evidence\": [\"Direct quotes or specific facts from the article\"]\n",
    "}\"\"\"\n",
    "\n",
    "def run_generator_initial(article_text: str) -> dict:\n",
    "    \"\"\"Generator: Initial classification with detailed reasoning.\"\"\"\n",
    "    user_prompt = f\"\"\"Classify the following news article:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\"\"\"\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-5.1\",\n",
    "        max_completion_tokens=4096,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": GENERATOR_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    response_text = response.choices[0].message.content\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"error\": \"Failed to parse generator response\",\n",
    "            \"raw_response\": response_text,\n",
    "            \"classification\": \"Unknown\",\n",
    "            \"confidence\": \"low\",\n",
    "            \"reasoning\": \"Parse error\"\n",
    "        }\n",
    "\n",
    "# ============================================================\n",
    "# EVALUATOR (claude-opus-4-5-20251101) - Critical Assessment\n",
    "# ============================================================\n",
    "\n",
    "EVALUATOR_SYSTEM_PROMPT = \"\"\"You are a critical evaluator for a news classification system. Your job is to rigorously assess whether a classification decision is correct and well-reasoned.\n",
    "\n",
    "You will receive:\n",
    "1. The original news article\n",
    "2. A classification produced by a generator, including its reasoning and evidence\n",
    "\n",
    "Your task is to critically evaluate the classification by:\n",
    "1. Re-reading the original article independently\n",
    "2. Checking if the reasoning logically supports the conclusion\n",
    "3. Verifying that cited evidence is accurate and relevant\n",
    "4. Looking for overlooked evidence that might change the classification\n",
    "5. Considering if the alternative category was dismissed too quickly\n",
    "6. Assessing if the confidence level is appropriate\n",
    "\n",
    "Evaluation Criteria:\n",
    "- LOGICAL CONSISTENCY: Does the reasoning actually support the conclusion?\n",
    "- EVIDENCE ACCURACY: Did the generator correctly identify and interpret signals?\n",
    "- COMPLETENESS: Are there important signals the generator overlooked?\n",
    "- ALTERNATIVE ANALYSIS: Was the alternative category fairly considered?\n",
    "- CONFIDENCE CALIBRATION: Does the evidence strength match the confidence level?\n",
    "\n",
    "Decision Guidelines:\n",
    "- APPROVE if: Reasoning is sound, evidence is accurate, no significant oversights\n",
    "- REJECT if: Logical flaws, misinterpreted evidence, overlooked critical signals, or wrong classification\n",
    "\n",
    "If you REJECT, provide specific, actionable feedback telling the generator:\n",
    "- What specific issue you found\n",
    "- What evidence was overlooked or misinterpreted\n",
    "- What the generator should reconsider\n",
    "\n",
    "Rules:\n",
    "- Be rigorous but fair - do not reject for trivial issues\n",
    "- Your feedback must be specific and actionable\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"decision\": \"APPROVE\" | \"REJECT\",\n",
    "    \"evaluation\": {\n",
    "        \"logical_consistency\": \"Assessment of reasoning\",\n",
    "        \"evidence_accuracy\": \"Assessment of evidence interpretation\",\n",
    "        \"completeness\": \"Assessment of signal coverage\",\n",
    "        \"alternative_analysis\": \"Assessment of alternative consideration\",\n",
    "        \"confidence_calibration\": \"Assessment of confidence appropriateness\"\n",
    "    },\n",
    "    \"issues_found\": [\n",
    "        {\n",
    "            \"type\": \"overlooked_evidence | logical_flaw | misinterpreted_signal | weak_reasoning\",\n",
    "            \"description\": \"Specific description of the issue\"\n",
    "        }\n",
    "    ],\n",
    "    \"feedback\": \"Specific, actionable feedback for generator (if REJECT, null if APPROVE)\",\n",
    "    \"final_classification\": \"Classification to use (same as generator if APPROVE, null if REJECT)\"\n",
    "}\"\"\"\n",
    "\n",
    "def run_evaluator(article_text: str, generator_output: dict) -> dict:\n",
    "    \"\"\"Evaluator: Critically assess the generator's classification.\"\"\"\n",
    "    user_prompt = f\"\"\"Evaluate the following news classification:\n",
    "\n",
    "ORIGINAL ARTICLE:\n",
    "---\n",
    "{article_text}\n",
    "---\n",
    "\n",
    "GENERATOR'S CLASSIFICATION:\n",
    "{json.dumps(generator_output, indent=2)}\"\"\"\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-opus-4-5-20251101\",\n",
    "        max_tokens=4096,\n",
    "        system=EVALUATOR_SYSTEM_PROMPT,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    \n",
    "    response_text = response.content[0].text\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        # If parsing fails, assume approval to avoid infinite loops\n",
    "        return {\n",
    "            \"error\": \"Failed to parse evaluator response\",\n",
    "            \"raw_response\": response_text,\n",
    "            \"decision\": \"APPROVE\",\n",
    "            \"evaluation\": {\"note\": \"Parse error, defaulting to approve\"},\n",
    "            \"issues_found\": [],\n",
    "            \"feedback\": None,\n",
    "            \"final_classification\": generator_output.get(\"classification\", \"Unknown\")\n",
    "        }\n",
    "\n",
    "# ============================================================\n",
    "# GENERATOR (gpt-5.1) - Retry with Feedback\n",
    "# ============================================================\n",
    "\n",
    "GENERATOR_RETRY_SYSTEM_PROMPT = \"\"\"You are an expert news classifier revising a previous classification based on evaluator feedback.\n",
    "\n",
    "You previously classified a news article, but an evaluator found issues with your reasoning. You must now reconsider your classification while addressing the specific feedback provided.\n",
    "\n",
    "Your task:\n",
    "1. Re-read the original article carefully\n",
    "2. Consider the evaluator's feedback seriously\n",
    "3. Re-examine the evidence, especially areas highlighted in the feedback\n",
    "4. Either REVISE your classification or DEFEND your original decision with better reasoning\n",
    "\n",
    "Important:\n",
    "- You MUST address each issue raised in the feedback\n",
    "- If you change your classification, explain what new insight led to the change\n",
    "- If you maintain your original classification, provide stronger evidence and reasoning\n",
    "- Your confidence should reflect the difficulty of this classification\n",
    "\n",
    "Categories:\n",
    "- World: International affairs, politics, government, diplomacy, conflicts\n",
    "- Sports: Athletic events, teams, players, competitions, leagues\n",
    "- Business: Companies, markets, economy, finance, corporate news\n",
    "- Sci/Tech: Technology, science, software, research, innovation\n",
    "\n",
    "Rules:\n",
    "- Explicitly address each point in the evaluator's feedback\n",
    "- Provide even more detailed reasoning than before\n",
    "- Cite specific evidence from the article\n",
    "- Return ONLY valid JSON, no additional text\n",
    "\n",
    "Output format:\n",
    "{\n",
    "    \"classification\": \"World\" | \"Sports\" | \"Business\" | \"Sci/Tech\",\n",
    "    \"confidence\": \"high\" | \"medium\" | \"low\",\n",
    "    \"key_signals\": {\n",
    "        \"entities\": [\"list of entities\"],\n",
    "        \"topics\": [\"main topics\"],\n",
    "        \"domain_keywords\": [\"domain-specific terms\"]\n",
    "    },\n",
    "    \"reasoning\": \"Detailed explanation addressing evaluator concerns\",\n",
    "    \"feedback_addressed\": {\n",
    "        \"issue\": \"What the evaluator raised\",\n",
    "        \"response\": \"How you addressed it\"\n",
    "    },\n",
    "    \"changed_classification\": true | false,\n",
    "    \"change_explanation\": \"Why you changed or maintained your classification\",\n",
    "    \"evidence\": [\"Specific evidence from the article\"]\n",
    "}\"\"\"\n",
    "\n",
    "def run_generator_retry(article_text: str, previous_output: dict, feedback: str, iteration: int) -> dict:\n",
    "    \"\"\"Generator: Retry classification addressing evaluator feedback.\"\"\"\n",
    "    user_prompt = f\"\"\"Revise your classification based on evaluator feedback.\n",
    "\n",
    "ORIGINAL ARTICLE:\n",
    "---\n",
    "{article_text}\n",
    "---\n",
    "\n",
    "YOUR PREVIOUS CLASSIFICATION:\n",
    "{json.dumps(previous_output, indent=2)}\n",
    "\n",
    "EVALUATOR'S FEEDBACK:\n",
    "{feedback}\n",
    "\n",
    "ITERATION: {iteration} of {MAX_ITERATIONS}\n",
    "\n",
    "Please reconsider your classification, addressing the evaluator's concerns.\"\"\"\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-5.1\",\n",
    "        max_completion_tokens=2048,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": GENERATOR_RETRY_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    response_text = response.choices[0].message.content\n",
    "    cleaned = clean_json_response(response_text)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"error\": \"Failed to parse generator retry response\",\n",
    "            \"raw_response\": response_text,\n",
    "            \"classification\": previous_output.get(\"classification\", \"Unknown\"),\n",
    "            \"confidence\": \"low\",\n",
    "            \"reasoning\": \"Parse error, keeping previous classification\"\n",
    "        }\n",
    "\n",
    "# ============================================================\n",
    "# EVALUATOR-OPTIMIZER PIPELINE\n",
    "# ============================================================\n",
    "\n",
    "def evaluator_optimizer_classify(article_text: str) -> dict:\n",
    "    \"\"\"Full evaluator-optimizer pipeline with iterative refinement.\"\"\"\n",
    "    \n",
    "    iteration_history = []\n",
    "    \n",
    "    # Iteration 1: Initial classification\n",
    "    iteration = 1\n",
    "    generator_output = run_generator_initial(article_text)\n",
    "    \n",
    "    iteration_history.append({\n",
    "        \"iteration\": iteration,\n",
    "        \"generator_output\": generator_output,\n",
    "        \"evaluator_output\": None  # Will be filled below\n",
    "    })\n",
    "    \n",
    "    # Evaluation loop\n",
    "    while iteration <= MAX_ITERATIONS:\n",
    "        # Run evaluator\n",
    "        evaluator_output = run_evaluator(article_text, generator_output)\n",
    "        iteration_history[-1][\"evaluator_output\"] = evaluator_output\n",
    "        \n",
    "        # Check if approved\n",
    "        if evaluator_output.get(\"decision\") == \"APPROVE\":\n",
    "            final_classification = evaluator_output.get(\"final_classification\", \n",
    "                                                        generator_output.get(\"classification\", \"Unknown\"))\n",
    "            return {\n",
    "                \"final_classification\": final_classification,\n",
    "                \"final_confidence\": generator_output.get(\"confidence\", \"low\"),\n",
    "                \"iterations_used\": iteration,\n",
    "                \"approved\": True,\n",
    "                \"iteration_history\": iteration_history\n",
    "            }\n",
    "        \n",
    "        # If rejected and more iterations available, retry\n",
    "        iteration += 1\n",
    "        if iteration <= MAX_ITERATIONS:\n",
    "            feedback = evaluator_output.get(\"feedback\", \"Please reconsider your classification.\")\n",
    "            generator_output = run_generator_retry(article_text, generator_output, feedback, iteration)\n",
    "            \n",
    "            iteration_history.append({\n",
    "                \"iteration\": iteration,\n",
    "                \"generator_output\": generator_output,\n",
    "                \"evaluator_output\": None\n",
    "            })\n",
    "    \n",
    "    # Max iterations reached without approval\n",
    "    # Use the last generator's classification\n",
    "    final_classification = generator_output.get(\"classification\", \"Unknown\")\n",
    "    \n",
    "    return {\n",
    "        \"final_classification\": final_classification,\n",
    "        \"final_confidence\": generator_output.get(\"confidence\", \"low\"),\n",
    "        \"iterations_used\": MAX_ITERATIONS,\n",
    "        \"approved\": False,\n",
    "        \"iteration_history\": iteration_history\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# PROCESS ALL TEST DATA\n",
    "# ============================================================\n",
    "\n",
    "# Store evaluator-optimizer results\n",
    "evaluator_optimizer_results = []\n",
    "\n",
    "# Number of results to print\n",
    "NUM_TO_PRINT = 3\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EVALUATOR-OPTIMIZER DESIGN PATTERN - Classification\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nProcessing {NUM_SAMPLES} samples using evaluator-optimizer pattern...\")\n",
    "print(f\"Pipeline: Generator (gpt-5.1) â†” Evaluator (Claude Opus 4.5)\")\n",
    "print(f\"Max iterations: {MAX_ITERATIONS}\\n\")\n",
    "\n",
    "# Progress tracking\n",
    "PROGRESS_INTERVAL = 10\n",
    "\n",
    "# Track iteration statistics\n",
    "total_iterations = 0\n",
    "approval_counts = {1: 0, 2: 0, 3: 0, \"not_approved\": 0}\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample = test_data[i]\n",
    "    article_text = sample['text']\n",
    "    ground_truth_label = sample['label']\n",
    "    \n",
    "    # Run the evaluator-optimizer pipeline\n",
    "    result = evaluator_optimizer_classify(article_text)\n",
    "    \n",
    "    # Track statistics\n",
    "    total_iterations += result[\"iterations_used\"]\n",
    "    if result[\"approved\"]:\n",
    "        approval_counts[result[\"iterations_used\"]] += 1\n",
    "    else:\n",
    "        approval_counts[\"not_approved\"] += 1\n",
    "    \n",
    "    # Store result with metadata\n",
    "    evaluator_optimizer_results.append({\n",
    "        \"index\": i,\n",
    "        \"original_text\": article_text,\n",
    "        \"ground_truth_label\": ground_truth_label,\n",
    "        \"ground_truth_name\": label_names[ground_truth_label],\n",
    "        \"final_classification\": result[\"final_classification\"],\n",
    "        \"final_confidence\": result[\"final_confidence\"],\n",
    "        \"iterations_used\": result[\"iterations_used\"],\n",
    "        \"approved\": result[\"approved\"],\n",
    "        \"iteration_history\": result[\"iteration_history\"]\n",
    "    })\n",
    "    \n",
    "    # Print progress\n",
    "    if (i + 1) % PROGRESS_INTERVAL == 0 or (i + 1) == NUM_SAMPLES:\n",
    "        avg_iter = total_iterations / (i + 1)\n",
    "        print(f\"  âœ“ Processed {i + 1}/{NUM_SAMPLES} articles ({(i + 1) / NUM_SAMPLES * 100:.1f}%) | Avg iterations: {avg_iter:.2f}\")\n",
    "\n",
    "# ============================================================\n",
    "# PRINT SAMPLE RESULTS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"EVALUATOR-OPTIMIZER RESULTS (showing first {NUM_TO_PRINT} of {len(evaluator_optimizer_results)})\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i in range(min(NUM_TO_PRINT, len(evaluator_optimizer_results))):\n",
    "    result = evaluator_optimizer_results[i]\n",
    "    \n",
    "    print(\"â”€\" * 70)\n",
    "    print(f\"Article {i + 1}\")\n",
    "    print(f\"Ground Truth: {result['ground_truth_name']}\")\n",
    "    print(\"â”€\" * 70)\n",
    "    \n",
    "    # Iteration summary\n",
    "    print(f\"\\nğŸ”„ Iterations: {result['iterations_used']} | Approved: {'âœ“' if result['approved'] else 'âœ—'}\")\n",
    "    \n",
    "    # Show iteration history\n",
    "    for iter_info in result['iteration_history']:\n",
    "        iter_num = iter_info['iteration']\n",
    "        gen_out = iter_info['generator_output']\n",
    "        eval_out = iter_info['evaluator_output']\n",
    "        \n",
    "        gen_class = gen_out.get('classification', 'N/A')\n",
    "        gen_conf = gen_out.get('confidence', 'N/A')\n",
    "        \n",
    "        if eval_out:\n",
    "            eval_decision = eval_out.get('decision', 'N/A')\n",
    "            print(f\"   Iter {iter_num}: Generator â†’ {gen_class} ({gen_conf}) | Evaluator â†’ {eval_decision}\")\n",
    "        else:\n",
    "            print(f\"   Iter {iter_num}: Generator â†’ {gen_class} ({gen_conf}) | Evaluator â†’ pending\")\n",
    "    \n",
    "    # Final result\n",
    "    predicted = result['final_classification']\n",
    "    is_correct = predicted == result['ground_truth_name']\n",
    "    status = \"âœ“ CORRECT\" if is_correct else \"âœ— INCORRECT\"\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Final Classification: {predicted}\")\n",
    "    print(f\"   Confidence: {result['final_confidence']}\")\n",
    "    print(f\"   Result: {status}\")\n",
    "\n",
    "# Print iteration statistics\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ITERATION STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n  Approved on iteration 1: {approval_counts[1]} ({approval_counts[1]/NUM_SAMPLES*100:.1f}%)\")\n",
    "print(f\"  Approved on iteration 2: {approval_counts[2]} ({approval_counts[2]/NUM_SAMPLES*100:.1f}%)\")\n",
    "print(f\"  Approved on iteration 3: {approval_counts[3]} ({approval_counts[3]/NUM_SAMPLES*100:.1f}%)\")\n",
    "print(f\"  Not approved (max iter): {approval_counts['not_approved']} ({approval_counts['not_approved']/NUM_SAMPLES*100:.1f}%)\")\n",
    "print(f\"\\n  Average iterations per article: {total_iterations/NUM_SAMPLES:.2f}\")\n",
    "print(f\"  Total LLM calls: {sum(r['iterations_used'] * 2 for r in evaluator_optimizer_results)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Evaluator-Optimizer complete. {len(evaluator_optimizer_results)} results stored in 'evaluator_optimizer_results'\")\n",
    "print(\"Ready for evaluation.\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c4af9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EVALUATOR-OPTIMIZER DESIGN PATTERN - EVALUATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "OVERALL METRICS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Total Samples:     100\n",
      "  Valid Predictions: 100\n",
      "  Error Rate:        0.0%\n",
      "\n",
      "  ğŸ“Š Accuracy:        0.8100  (81.0%)\n",
      "\n",
      "  Macro Averages (treats all classes equally):\n",
      "     Precision:      0.8245\n",
      "     Recall:         0.8653\n",
      "     F1 Score:       0.8041\n",
      "\n",
      "  Weighted Averages (accounts for class imbalance):\n",
      "     Precision:      0.8971\n",
      "     Recall:         0.8100\n",
      "     F1 Score:       0.8224\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "PER-CLASS METRICS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       1.00      0.87      0.93        30\n",
      "      Sports       0.91      1.00      0.95        21\n",
      "    Business       0.43      1.00      0.60        12\n",
      "    Sci/Tech       0.96      0.59      0.73        37\n",
      "\n",
      "    accuracy                           0.81       100\n",
      "   macro avg       0.82      0.87      0.80       100\n",
      "weighted avg       0.90      0.81      0.82       100\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CONFUSION MATRIX\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Predicted â†’     World    Sports  Business  Sci/Tech\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Actual â†“\n",
      "          World        26         2         1         1\n",
      "         Sports         0        21         0         0\n",
      "       Business         0         0        12         0\n",
      "       Sci/Tech         0         0        15        22\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DISTRIBUTION ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Category        Ground Truth       Predicted   Difference\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "World                     30              26           -4\n",
      "Sports                    21              23           +2\n",
      "Business                  12              28          +16\n",
      "Sci/Tech                  37              23          -14\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ITERATION ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Iterations Distribution:\n",
      "    Iterations      Count   Percentage\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "             1         90        90.0%\n",
      "             2          4         4.0%\n",
      "             3          6         6.0%\n",
      "\n",
      "  Approval Status:\n",
      "    Approved:        95 (95.0%)\n",
      "    Not Approved:     5 (5.0%)\n",
      "\n",
      "  Average Iterations: 1.16\n",
      "  Total LLM Calls:    232\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ACCURACY BY ITERATION COUNT\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Iterations    Correct      Total     Accuracy\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "             1         73         90       81.1%\n",
      "             2          3          4       75.0%\n",
      "             3          5          6       83.3%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "APPROVAL VS ACCURACY ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Status                  Correct      Total     Accuracy\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Approved                     77         95       81.1%\n",
      "  Not Approved (max)            4          5       80.0%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "SELF-CORRECTION ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Articles requiring multiple iterations: 10\n",
      "  Classification changed during iterations: 3\n",
      "\n",
      "  When Classification Changed:\n",
      "    Improved (wrong â†’ correct):      1 (33.3%)\n",
      "    Worsened (correct â†’ wrong):      2 (66.7%)\n",
      "    No Effect (wrong â†’ wrong):       0 (0.0%)\n",
      "\n",
      "  Net Improvement from Changes: -1 articles\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "FIRST ITERATION VS FINAL ACCURACY\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  First Iteration Accuracy: 82/100 (82.0%)\n",
      "  Final Accuracy:           81/100 (81.0%)\n",
      "\n",
      "  Improvement from Iterations: -1 articles (-1.0%)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CONFIDENCE ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Confidence           Count    Correct     Accuracy\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "high                    89         73       82.0%\n",
      "medium                   9          7       77.8%\n",
      "low                      2          1       50.0%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "EVALUATOR EFFECTIVENESS ANALYSIS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Total Evaluations: 116\n",
      "  Total Approvals:   95\n",
      "  Total Rejections:  21\n",
      "\n",
      "  After Rejection (what happened next):\n",
      "    Improved (wrong â†’ correct):         4\n",
      "    Worsened (correct â†’ wrong):         5\n",
      "    Same (stayed correct):              7\n",
      "    Same (stayed wrong):                0\n",
      "\n",
      "  Rejection Effectiveness: 44.4%\n",
      "  (When rejection led to change, how often was it an improvement)\n",
      "\n",
      "======================================================================\n",
      "EVALUATOR-OPTIMIZER PATTERN EVALUATION COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EVALUATION: Evaluator-Optimizer Design Pattern Performance\n",
    "# ============================================================\n",
    "\n",
    "# Extract predictions and ground truth from evaluator-optimizer results\n",
    "eo_predictions = []\n",
    "eo_ground_truths = []\n",
    "eo_errors = []\n",
    "\n",
    "for result in evaluator_optimizer_results:\n",
    "    ground_truth = result['ground_truth_name']\n",
    "    eo_ground_truths.append(ground_truth)\n",
    "    \n",
    "    # Get final classification\n",
    "    predicted = result['final_classification']\n",
    "    \n",
    "    if predicted in CATEGORIES:\n",
    "        eo_predictions.append(predicted)\n",
    "    else:\n",
    "        eo_predictions.append(\"ERROR\")\n",
    "        eo_errors.append(result['index'])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EVALUATOR-OPTIMIZER DESIGN PATTERN - EVALUATION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for errors\n",
    "if eo_errors:\n",
    "    print(f\"\\nâš ï¸  Warning: {len(eo_errors)} samples had errors (indices: {eo_errors[:10]}{'...' if len(eo_errors) > 10 else ''})\")\n",
    "    print(f\"   These are excluded from metrics calculation.\\n\")\n",
    "    \n",
    "    valid_eo_predictions = [p for p in eo_predictions if p != \"ERROR\"]\n",
    "    valid_eo_ground_truths = [g for p, g in zip(eo_predictions, eo_ground_truths) if p != \"ERROR\"]\n",
    "else:\n",
    "    valid_eo_predictions = eo_predictions\n",
    "    valid_eo_ground_truths = eo_ground_truths\n",
    "\n",
    "# ============================================================\n",
    "# Basic Metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"OVERALL METRICS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "eo_accuracy = accuracy_score(valid_eo_ground_truths, valid_eo_predictions)\n",
    "eo_precision_macro = precision_score(valid_eo_ground_truths, valid_eo_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "eo_recall_macro = recall_score(valid_eo_ground_truths, valid_eo_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "eo_f1_macro = f1_score(valid_eo_ground_truths, valid_eo_predictions, labels=CATEGORIES, average='macro', zero_division=0)\n",
    "\n",
    "eo_precision_weighted = precision_score(valid_eo_ground_truths, valid_eo_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "eo_recall_weighted = recall_score(valid_eo_ground_truths, valid_eo_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "eo_f1_weighted = f1_score(valid_eo_ground_truths, valid_eo_predictions, labels=CATEGORIES, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\n  Total Samples:     {len(evaluator_optimizer_results)}\")\n",
    "print(f\"  Valid Predictions: {len(valid_eo_predictions)}\")\n",
    "print(f\"  Error Rate:        {len(eo_errors) / len(evaluator_optimizer_results) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n  ğŸ“Š Accuracy:        {eo_accuracy:.4f}  ({eo_accuracy * 100:.1f}%)\")\n",
    "print(f\"\\n  Macro Averages (treats all classes equally):\")\n",
    "print(f\"     Precision:      {eo_precision_macro:.4f}\")\n",
    "print(f\"     Recall:         {eo_recall_macro:.4f}\")\n",
    "print(f\"     F1 Score:       {eo_f1_macro:.4f}\")\n",
    "\n",
    "print(f\"\\n  Weighted Averages (accounts for class imbalance):\")\n",
    "print(f\"     Precision:      {eo_precision_weighted:.4f}\")\n",
    "print(f\"     Recall:         {eo_recall_weighted:.4f}\")\n",
    "print(f\"     F1 Score:       {eo_f1_weighted:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Per-Class Metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"PER-CLASS METRICS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "print(\"\\n\" + classification_report(valid_eo_ground_truths, valid_eo_predictions, labels=CATEGORIES, zero_division=0))\n",
    "\n",
    "# ============================================================\n",
    "# Confusion Matrix\n",
    "# ============================================================\n",
    "\n",
    "print(\"â”€\" * 70)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "eo_cm = confusion_matrix(valid_eo_ground_truths, valid_eo_predictions, labels=CATEGORIES)\n",
    "\n",
    "print(f\"\\n{'Predicted â†’':>15}\", end=\"\")\n",
    "for cat in CATEGORIES:\n",
    "    print(f\"{cat:>10}\", end=\"\")\n",
    "print(\"\\n\" + \"â”€\" * 55)\n",
    "\n",
    "print(\"Actual â†“\")\n",
    "for i, cat in enumerate(CATEGORIES):\n",
    "    print(f\"{cat:>15}\", end=\"\")\n",
    "    for j in range(len(CATEGORIES)):\n",
    "        print(f\"{eo_cm[i][j]:>10}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "# ============================================================\n",
    "# Distribution Analysis\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"DISTRIBUTION ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "eo_gt_dist = Counter(valid_eo_ground_truths)\n",
    "eo_pred_dist = Counter(valid_eo_predictions)\n",
    "\n",
    "print(f\"\\n{'Category':<12} {'Ground Truth':>15} {'Predicted':>15} {'Difference':>12}\")\n",
    "print(\"â”€\" * 55)\n",
    "for cat in CATEGORIES:\n",
    "    gt_count = eo_gt_dist.get(cat, 0)\n",
    "    pred_count = eo_pred_dist.get(cat, 0)\n",
    "    diff = pred_count - gt_count\n",
    "    diff_str = f\"+{diff}\" if diff > 0 else str(diff)\n",
    "    print(f\"{cat:<12} {gt_count:>15} {pred_count:>15} {diff_str:>12}\")\n",
    "\n",
    "# ============================================================\n",
    "# Iteration Analysis (Unique to Evaluator-Optimizer)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"ITERATION ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Count by iterations used\n",
    "iter_counts = Counter(r['iterations_used'] for r in evaluator_optimizer_results)\n",
    "approval_status = Counter(r['approved'] for r in evaluator_optimizer_results)\n",
    "\n",
    "print(f\"\\n  Iterations Distribution:\")\n",
    "print(f\"  {'Iterations':>12} {'Count':>10} {'Percentage':>12}\")\n",
    "print(\"  \" + \"â”€\" * 37)\n",
    "for num_iter in sorted(iter_counts.keys()):\n",
    "    count = iter_counts[num_iter]\n",
    "    pct = count / len(evaluator_optimizer_results) * 100\n",
    "    print(f\"  {num_iter:>12} {count:>10} {pct:>11.1f}%\")\n",
    "\n",
    "print(f\"\\n  Approval Status:\")\n",
    "print(f\"    Approved:     {approval_status[True]:>5} ({approval_status[True]/len(evaluator_optimizer_results)*100:.1f}%)\")\n",
    "print(f\"    Not Approved: {approval_status[False]:>5} ({approval_status[False]/len(evaluator_optimizer_results)*100:.1f}%)\")\n",
    "\n",
    "avg_iterations = sum(r['iterations_used'] for r in evaluator_optimizer_results) / len(evaluator_optimizer_results)\n",
    "print(f\"\\n  Average Iterations: {avg_iterations:.2f}\")\n",
    "print(f\"  Total LLM Calls:    {sum(r['iterations_used'] * 2 for r in evaluator_optimizer_results)}\")\n",
    "\n",
    "# ============================================================\n",
    "# Accuracy by Iteration (Unique to Evaluator-Optimizer)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"ACCURACY BY ITERATION COUNT\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Group results by iterations used and calculate accuracy for each group\n",
    "iter_accuracy = {}\n",
    "for num_iter in sorted(iter_counts.keys()):\n",
    "    iter_results = [r for r in evaluator_optimizer_results if r['iterations_used'] == num_iter]\n",
    "    correct = sum(1 for r in iter_results if r['final_classification'] == r['ground_truth_name'])\n",
    "    total = len(iter_results)\n",
    "    iter_accuracy[num_iter] = (correct, total)\n",
    "\n",
    "print(f\"\\n  {'Iterations':>12} {'Correct':>10} {'Total':>10} {'Accuracy':>12}\")\n",
    "print(\"  \" + \"â”€\" * 47)\n",
    "for num_iter in sorted(iter_accuracy.keys()):\n",
    "    correct, total = iter_accuracy[num_iter]\n",
    "    acc = correct / total if total > 0 else 0\n",
    "    print(f\"  {num_iter:>12} {correct:>10} {total:>10} {acc:>11.1%}\")\n",
    "\n",
    "# ============================================================\n",
    "# Approval vs Accuracy Analysis (Unique to Evaluator-Optimizer)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"APPROVAL VS ACCURACY ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Accuracy for approved vs not approved\n",
    "approved_results = [r for r in evaluator_optimizer_results if r['approved']]\n",
    "not_approved_results = [r for r in evaluator_optimizer_results if not r['approved']]\n",
    "\n",
    "approved_correct = sum(1 for r in approved_results if r['final_classification'] == r['ground_truth_name'])\n",
    "not_approved_correct = sum(1 for r in not_approved_results if r['final_classification'] == r['ground_truth_name'])\n",
    "\n",
    "print(f\"\\n  {'Status':<20} {'Correct':>10} {'Total':>10} {'Accuracy':>12}\")\n",
    "print(\"  \" + \"â”€\" * 55)\n",
    "if approved_results:\n",
    "    approved_acc = approved_correct / len(approved_results)\n",
    "    print(f\"  {'Approved':<20} {approved_correct:>10} {len(approved_results):>10} {approved_acc:>11.1%}\")\n",
    "if not_approved_results:\n",
    "    not_approved_acc = not_approved_correct / len(not_approved_results)\n",
    "    print(f\"  {'Not Approved (max)':<20} {not_approved_correct:>10} {len(not_approved_results):>10} {not_approved_acc:>11.1%}\")\n",
    "\n",
    "# ============================================================\n",
    "# Self-Correction Analysis (Unique to Evaluator-Optimizer)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"SELF-CORRECTION ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Analyze cases where classification changed during iterations\n",
    "changed_classification = 0\n",
    "change_improved = 0\n",
    "change_worsened = 0\n",
    "change_no_effect = 0\n",
    "\n",
    "for result in evaluator_optimizer_results:\n",
    "    if result['iterations_used'] > 1:\n",
    "        # Get first and last classification\n",
    "        first_iter = result['iteration_history'][0]\n",
    "        last_iter = result['iteration_history'][-1]\n",
    "        \n",
    "        first_class = first_iter['generator_output'].get('classification', '')\n",
    "        last_class = last_iter['generator_output'].get('classification', '')\n",
    "        ground_truth = result['ground_truth_name']\n",
    "        \n",
    "        if first_class != last_class:\n",
    "            changed_classification += 1\n",
    "            first_correct = first_class == ground_truth\n",
    "            last_correct = last_class == ground_truth\n",
    "            \n",
    "            if not first_correct and last_correct:\n",
    "                change_improved += 1\n",
    "            elif first_correct and not last_correct:\n",
    "                change_worsened += 1\n",
    "            else:\n",
    "                change_no_effect += 1\n",
    "\n",
    "multi_iter_count = sum(1 for r in evaluator_optimizer_results if r['iterations_used'] > 1)\n",
    "\n",
    "print(f\"\\n  Articles requiring multiple iterations: {multi_iter_count}\")\n",
    "print(f\"  Classification changed during iterations: {changed_classification}\")\n",
    "\n",
    "if changed_classification > 0:\n",
    "    print(f\"\\n  When Classification Changed:\")\n",
    "    print(f\"    Improved (wrong â†’ correct):  {change_improved:>5} ({change_improved/changed_classification*100:.1f}%)\")\n",
    "    print(f\"    Worsened (correct â†’ wrong):  {change_worsened:>5} ({change_worsened/changed_classification*100:.1f}%)\")\n",
    "    print(f\"    No Effect (wrong â†’ wrong):   {change_no_effect:>5} ({change_no_effect/changed_classification*100:.1f}%)\")\n",
    "    \n",
    "    net_improvement = change_improved - change_worsened\n",
    "    print(f\"\\n  Net Improvement from Changes: {'+' if net_improvement >= 0 else ''}{net_improvement} articles\")\n",
    "\n",
    "# ============================================================\n",
    "# First Iteration vs Final Accuracy (Unique to Evaluator-Optimizer)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"FIRST ITERATION VS FINAL ACCURACY\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "first_iter_correct = 0\n",
    "final_correct = 0\n",
    "\n",
    "for result in evaluator_optimizer_results:\n",
    "    ground_truth = result['ground_truth_name']\n",
    "    first_class = result['iteration_history'][0]['generator_output'].get('classification', '')\n",
    "    final_class = result['final_classification']\n",
    "    \n",
    "    if first_class == ground_truth:\n",
    "        first_iter_correct += 1\n",
    "    if final_class == ground_truth:\n",
    "        final_correct += 1\n",
    "\n",
    "total = len(evaluator_optimizer_results)\n",
    "print(f\"\\n  First Iteration Accuracy: {first_iter_correct}/{total} ({first_iter_correct/total*100:.1f}%)\")\n",
    "print(f\"  Final Accuracy:           {final_correct}/{total} ({final_correct/total*100:.1f}%)\")\n",
    "print(f\"\\n  Improvement from Iterations: {'+' if final_correct >= first_iter_correct else ''}{final_correct - first_iter_correct} articles ({(final_correct - first_iter_correct)/total*100:+.1f}%)\")\n",
    "\n",
    "# ============================================================\n",
    "# Confidence Analysis\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"CONFIDENCE ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Group by final confidence and calculate accuracy\n",
    "confidence_accuracy = {\"high\": [0, 0], \"medium\": [0, 0], \"low\": [0, 0]}\n",
    "\n",
    "for result in evaluator_optimizer_results:\n",
    "    conf = result['final_confidence']\n",
    "    predicted = result['final_classification']\n",
    "    is_correct = predicted == result['ground_truth_name']\n",
    "    \n",
    "    if conf in confidence_accuracy:\n",
    "        confidence_accuracy[conf][1] += 1\n",
    "        if is_correct:\n",
    "            confidence_accuracy[conf][0] += 1\n",
    "\n",
    "print(f\"\\n{'Confidence':<15} {'Count':>10} {'Correct':>10} {'Accuracy':>12}\")\n",
    "print(\"â”€\" * 50)\n",
    "for conf_level in ['high', 'medium', 'low']:\n",
    "    correct, total = confidence_accuracy[conf_level]\n",
    "    if total > 0:\n",
    "        acc = correct / total\n",
    "        print(f\"{conf_level:<15} {total:>10} {correct:>10} {acc:>11.1%}\")\n",
    "    else:\n",
    "        print(f\"{conf_level:<15} {0:>10} {0:>10} {'N/A':>12}\")\n",
    "\n",
    "# ============================================================\n",
    "# Evaluator Effectiveness Analysis (Unique to Evaluator-Optimizer)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"EVALUATOR EFFECTIVENESS ANALYSIS\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Analyze evaluator decisions\n",
    "total_evaluations = sum(r['iterations_used'] for r in evaluator_optimizer_results)\n",
    "total_approvals = sum(1 for r in evaluator_optimizer_results if r['approved'])\n",
    "total_rejections = total_evaluations - total_approvals\n",
    "\n",
    "# Was rejection followed by improvement?\n",
    "rejection_outcomes = {\"improved\": 0, \"worsened\": 0, \"same_correct\": 0, \"same_wrong\": 0}\n",
    "\n",
    "for result in evaluator_optimizer_results:\n",
    "    history = result['iteration_history']\n",
    "    for i in range(len(history) - 1):\n",
    "        current_iter = history[i]\n",
    "        next_iter = history[i + 1]\n",
    "        \n",
    "        if current_iter['evaluator_output'] and current_iter['evaluator_output'].get('decision') == 'REJECT':\n",
    "            current_class = current_iter['generator_output'].get('classification', '')\n",
    "            next_class = next_iter['generator_output'].get('classification', '')\n",
    "            ground_truth = result['ground_truth_name']\n",
    "            \n",
    "            current_correct = current_class == ground_truth\n",
    "            next_correct = next_class == ground_truth\n",
    "            \n",
    "            if not current_correct and next_correct:\n",
    "                rejection_outcomes[\"improved\"] += 1\n",
    "            elif current_correct and not next_correct:\n",
    "                rejection_outcomes[\"worsened\"] += 1\n",
    "            elif current_correct and next_correct:\n",
    "                rejection_outcomes[\"same_correct\"] += 1\n",
    "            else:\n",
    "                rejection_outcomes[\"same_wrong\"] += 1\n",
    "\n",
    "print(f\"\\n  Total Evaluations: {total_evaluations}\")\n",
    "print(f\"  Total Approvals:   {total_approvals}\")\n",
    "print(f\"  Total Rejections:  {total_rejections}\")\n",
    "\n",
    "if total_rejections > 0:\n",
    "    print(f\"\\n  After Rejection (what happened next):\")\n",
    "    print(f\"    Improved (wrong â†’ correct):     {rejection_outcomes['improved']:>5}\")\n",
    "    print(f\"    Worsened (correct â†’ wrong):     {rejection_outcomes['worsened']:>5}\")\n",
    "    print(f\"    Same (stayed correct):          {rejection_outcomes['same_correct']:>5}\")\n",
    "    print(f\"    Same (stayed wrong):            {rejection_outcomes['same_wrong']:>5}\")\n",
    "    \n",
    "    if rejection_outcomes['improved'] + rejection_outcomes['worsened'] > 0:\n",
    "        rejection_effectiveness = rejection_outcomes['improved'] / (rejection_outcomes['improved'] + rejection_outcomes['worsened'])\n",
    "        print(f\"\\n  Rejection Effectiveness: {rejection_effectiveness:.1%}\")\n",
    "        print(f\"  (When rejection led to change, how often was it an improvement)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EVALUATOR-OPTIMIZER PATTERN EVALUATION COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b36a6",
   "metadata": {},
   "source": [
    "## Summary: Comparison of Agentic Workflow Design Patterns\n",
    "\n",
    "### Overview\n",
    "\n",
    "We evaluated 5 different agentic workflow design patterns for classifying news articles from the AG News dataset into 4 categories: World, Sports, Business, and Sci/Tech.\n",
    "\n",
    "| # | Design Pattern | LLM Calls/Article | Models Used |\n",
    "|---|----------------|-------------------|-------------|\n",
    "| 1 | **Prompt Chaining** | 3 (sequential) | Claude Sonnet 4 â†’ GPT-5.1 â†’ Claude Haiku 4.5 |\n",
    "| 2 | **Routing** | 2 (router + expert) | GPT-5-mini (router) + 3 specialized experts |\n",
    "| 3 | **Parallelization** | 4 (parallel) | 4Ã— Claude Haiku 4.5 detectors + code aggregator |\n",
    "| 4 | **Orchestrator-Worker** | 6 (1+4+1) | GPT-5-mini + 4Ã— Claude Haiku 4.5 + GPT-5.1 |\n",
    "| 5 | **Evaluator-Optimizer** | 2-6 (iterative) | GPT-5.1 (generator) + Claude Opus 4.5 (evaluator) |\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Comparison\n",
    "\n",
    "#### Overall Metrics\n",
    "\n",
    "| Design Pattern | Accuracy | Precision (Macro) | Recall (Macro) | F1 (Macro) |\n",
    "|----------------|----------|-------------------|----------------|------------|\n",
    "| **1. Prompt Chaining** | **83.0%** | 0.827 | **0.879** | **0.822** |\n",
    "| 2. Routing | 82.0% | 0.809 | 0.844 | 0.806 |\n",
    "| 5. Evaluator-Optimizer | 81.0% | **0.825** | 0.865 | 0.804 |\n",
    "| 4. Orchestrator-Worker | 80.0% | 0.813 | 0.855 | 0.792 |\n",
    "| 3. Parallelization | 72.0% | 0.718 | 0.772 | 0.717 |\n",
    "\n",
    "#### Per-Class F1 Scores\n",
    "\n",
    "| Design Pattern | World | Sports | Business | Sci/Tech |\n",
    "|----------------|-------|--------|----------|----------|\n",
    "| **1. Prompt Chaining** | 0.88 | **0.95** | **0.67** | 0.79 |\n",
    "| 2. Routing | 0.89 | 0.88 | 0.65 | 0.81 |\n",
    "| 5. Evaluator-Optimizer | **0.93** | **0.95** | 0.60 | 0.73 |\n",
    "| 4. Orchestrator-Worker | 0.90 | 0.93 | 0.62 | 0.72 |\n",
    "| 3. Parallelization | 0.78 | 0.75 | **0.67** | 0.68 |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "#### 1. Common Challenge: Business vs Sci/Tech Confusion\n",
    "\n",
    "All 5 workflows struggle with the same classification boundary:\n",
    "\n",
    "| Pattern | Business Precision | Business Over-prediction | Sci/Tech Under-prediction |\n",
    "|---------|-------------------|--------------------------|---------------------------|\n",
    "| Prompt Chaining | 0.50 | +12 | -13 |\n",
    "| Routing | 0.50 | +10 | -10 |\n",
    "| Orchestrator-Worker | 0.44 | +15 | -16 |\n",
    "| Evaluator-Optimizer | 0.43 | +16 | -14 |\n",
    "| Parallelization | 0.52 | +9 | -12 |\n",
    "\n",
    "**Root Cause:** Many Sci/Tech articles discuss technology companies, which triggers \"Business\" signals. The models tend to classify tech company news as Business when the primary focus is actually on technology/products.\n",
    "\n",
    "#### 2. Workflow-Specific Insights\n",
    "\n",
    "**Prompt Chaining (83.0%)**\n",
    "- Sequential pipeline works well for structured analysis\n",
    "- Step 1 (extraction) + Step 2 (analysis) + Step 3 (classification) provides good decomposition\n",
    "- 97% high confidence predictions with 82.5% accuracy\n",
    "\n",
    "**Routing (82.0%)**\n",
    "- `science_world_expert` achieved **96.4% accuracy** - excellent for World/Sci/Tech\n",
    "- `business_expert` achieved only **50% accuracy** - the bottleneck\n",
    "- Router correctly identified domain 77-96% of the time\n",
    "\n",
    "**Parallelization (72.0%)**\n",
    "- Lowest accuracy due to 15% fallback rate (no detector claimed)\n",
    "- Individual detectors had high accuracy when they claimed (World: 100%, Sports: 90.5%, Sci/Tech: 95.7%)\n",
    "- Business detector only 50% accurate\n",
    "- Confidence voting aggregation struggled with ambiguous cases\n",
    "\n",
    "**Orchestrator-Worker (80.0%)**\n",
    "- Orchestrator's first choice was correct only **52%** of the time\n",
    "- Workers + Synthesizer corrected **30%** of orchestrator errors\n",
    "- But also introduced errors in **14%** of cases\n",
    "- Complex pipeline with marginal benefit over simpler approaches\n",
    "\n",
    "**Evaluator-Optimizer (81.0%)**\n",
    "- **90%** approved on first iteration - evaluator rarely rejected\n",
    "- Self-correction **hurt** performance: first iteration 82% â†’ final 81%\n",
    "- When classification changed, it worsened more often than improved (66.7% vs 33.3%)\n",
    "- Rejection effectiveness only 44.4%\n",
    "\n",
    "---\n",
    "\n",
    "### Cost-Efficiency Analysis\n",
    "\n",
    "| Design Pattern | LLM Calls (100 articles) | Accuracy | Calls per 1% Accuracy |\n",
    "|----------------|--------------------------|----------|----------------------|\n",
    "| **Routing** | 200 | 82.0% | **2.4** |\n",
    "| **Prompt Chaining** | 300 | 83.0% | 3.6 |\n",
    "| Parallelization | 400 | 72.0% | 5.6 |\n",
    "| Orchestrator-Worker | 600 | 80.0% | 7.5 |\n",
    "| Evaluator-Optimizer | 232 (avg) | 81.0% | 2.9 |\n",
    "\n",
    "---\n",
    "\n",
    "### Recommendation: Best Workflow for AG News Classification\n",
    "\n",
    "## ğŸ† Winner: **Prompt Chaining** (83.0% Accuracy)\n",
    "\n",
    "### Reasons for Selection:\n",
    "\n",
    "1. **Highest Overall Accuracy (83.0%)**\n",
    "   - Outperforms all other patterns by 1-11 percentage points\n",
    "   - Best macro F1 score (0.822)\n",
    "\n",
    "2. **Excellent Sports Classification (95% F1)**\n",
    "   - Perfect recall (1.00) for Sports category\n",
    "   - Only 2 misclassifications\n",
    "\n",
    "3. **Structured Decomposition Works Well**\n",
    "   - Step 1: Entity & Keyword Extraction (Claude Sonnet 4)\n",
    "   - Step 2: Domain Signal Analysis (GPT-5.1)\n",
    "   - Step 3: Final Classification (Claude Haiku 4.5)\n",
    "   - Each step builds on the previous, providing interpretable intermediate results\n",
    "\n",
    "4. **Consistent High Confidence**\n",
    "   - 97% of predictions were high confidence\n",
    "   - High confidence predictions were 82.5% accurate\n",
    "\n",
    "5. **Reasonable Cost**\n",
    "   - 3 LLM calls per article is moderate\n",
    "   - Better accuracy than patterns using more calls (Orchestrator-Worker: 6 calls, 80%)\n",
    "\n",
    "6. **Simplicity**\n",
    "   - Linear, predictable pipeline\n",
    "   - Easy to debug (can inspect each step's output)\n",
    "   - No complex coordination logic\n",
    "\n",
    "### Runner-Up: **Routing** (82.0% Accuracy)\n",
    "\n",
    "If cost is a primary concern, Routing is the most efficient:\n",
    "- Only 2 LLM calls per article\n",
    "- 82% accuracy\n",
    "- Best cost-efficiency ratio (2.4 calls per 1% accuracy)\n",
    "\n",
    "The `science_world_expert` (96.4% accuracy) demonstrates that specialized agents can excel in their domains.\n",
    "\n",
    "### What to Avoid for This Dataset\n",
    "\n",
    "**Parallelization** (72.0%) performed worst because:\n",
    "- 15% of articles had no detector claim them (fallback to uncertain prediction)\n",
    "- Simple confidence voting couldn't resolve ambiguous Business/Sci/Tech cases\n",
    "- Binary detection approach loses nuance in edge cases\n",
    "\n",
    "**Evaluator-Optimizer** showed that iterative refinement doesn't always help:\n",
    "- Self-correction actually decreased accuracy (-1%)\n",
    "- The evaluator rejected good classifications, leading to worse revisions\n",
    "- High computational cost (potentially 6 calls) with no accuracy benefit\n",
    "\n",
    "---\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "To address the Business/Sci/Tech confusion across all patterns:\n",
    "\n",
    "1. **Better prompting**: Explicitly instruct models that tech company news about products/features is Sci/Tech, not Business\n",
    "2. **Two-stage classification**: First classify Business vs Non-Business, then subdivide\n",
    "3. **Example-based few-shot**: Provide examples of Business (financials) vs Sci/Tech (products) for tech companies\n",
    "4. **Ensemble approach**: Combine Prompt Chaining with Routing for ambiguous cases\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
