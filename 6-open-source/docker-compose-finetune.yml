# =============================================================================
# Docker Compose for Fine-Tuning on DGX Spark
# =============================================================================
# Uses Unsloth's DGX Spark optimizations for maximum performance:
#
# Key Optimizations (built into the image):
# - Triton compiled from source for Blackwell (sm_121) support
# - xformers v0.0.33 compiled with TORCH_CUDA_ARCH_LIST="12.1"
# - Unsloth optimized kernels for 2x faster training
# - Flash Attention 2 for efficient attention
#
# Supported Methods:
# - Full Fine-Tuning: Update all model parameters
# - LoRA: Low-Rank Adaptation (16-bit base model)
# - QLoRA: Quantized LoRA (4-bit base model, even less memory)
#
# Usage:
#   ./start_docker.sh start finetune    # Build (first time) and start
#   ./start_docker.sh stop              # Stop container
#   ./start_docker.sh logs finetune     # View logs
#   ./start_docker.sh status            # Check status
#
# First-time build takes ~8-10 minutes (compiling Triton and xformers)
# Subsequent starts are fast (<10 seconds)
#
# Access Jupyter at: http://localhost:8888
# =============================================================================

services:
  finetune:
    container_name: pytorch-finetune
    
    # Build from DGX Spark optimized Dockerfile
    build:
      context: ./fine-tuning-dense
      dockerfile: Dockerfile.dgx-spark
    
    # Use built image (tag for caching)
    image: unsloth-dgx-spark:latest
    
    # GPU access
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # Network
    ports:
      - "8888:8888"    # Jupyter Lab
      - "6006:6006"    # TensorBoard (optional)
    
    # Volumes
    volumes:
      # Mount the workspace
      - ../:/workspace
      # Mount HuggingFace cache for model weights
      - ~/.cache/huggingface:/root/.cache/huggingface
      # Mount the fine-tuning directory
      - ./fine-tuning-dense:/fine-tuning
    
    # Working directory
    working_dir: /fine-tuning
    
    # Environment variables
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - HF_HOME=/root/.cache/huggingface
      - TRANSFORMERS_CACHE=/root/.cache/huggingface/hub
      # Optimize for DGX Spark unified memory
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      # Enable TF32 for better performance
      - NVIDIA_TF32_OVERRIDE=1
      # Disable tokenizers parallelism warning
      - TOKENIZERS_PARALLELISM=false
      # Unsloth optimizations
      - UNSLOTH_RETURN_LOGITS=1
    
    # Resource limits
    shm_size: '32gb'
    ulimits:
      memlock: -1
      stack: 67108864
    
    # Startup command
    command: >
      bash -c "
        echo '=============================================='
        echo '  Fine-Tuning on DGX Spark (Unsloth Optimized)'
        echo '=============================================='
        echo ''
        echo 'Optimizations (pre-built in image):'
        echo '  ✓ Triton compiled for Blackwell (sm_121)'
        echo '  ✓ xformers v0.0.33 compiled for sm_121'
        echo '  ✓ Unsloth optimized kernels (2x faster)'
        echo '  ✓ Flash Attention 2'
        echo '  ✓ bitsandbytes 4-bit quantization'
        echo ''
        echo 'GPU: '$(nvidia-smi --query-gpu=name --format=csv,noheader)
        echo 'CUDA: '$(nvcc --version | grep release | awk '{print $6}' || echo 'N/A')
        echo ''
        echo 'Supported Methods:'
        echo '  - Full Fine-Tuning: fine_tuning_full.ipynb or fine_tuning_full_unsloth.ipynb'
        echo '  - LoRA:             fine_tuning_lora.ipynb'
        echo '  - QLoRA:            fine_tuning_qlora.ipynb'
        echo ''
        echo 'Starting Jupyter Lab...'
        echo 'Access at: http://localhost:8888'
        echo ''
        jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token='' --NotebookApp.password=''
      "
    
    # Restart policy
    restart: unless-stopped
    
    # Labels for identification
    labels:
      - "com.nvidia.dgx-spark.purpose=fine-tuning"
      - "com.nvidia.dgx-spark.optimized=unsloth-dgx-spark"
      - "com.nvidia.dgx-spark.framework=unsloth"
